{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bdf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2 ‚Äî IMPORTS, ENV, CONFIG\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# your existing helper\n",
    "from mine_redis import get_files_gem  # def get_files_gem(REEL_URL, REEL_NO='0', task_id='default'):\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# ENVIRONMENT VARS\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not APIFY_API_KEY:\n",
    "    raise RuntimeError(\"Missing APIFY_API_KEY (set it in .env or env vars)\")\n",
    "\n",
    "apify = ApifyClient(APIFY_API_KEY)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# GLOBAL CONFIG\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "CREATOR_LIST = [\n",
    "    \"badassbrownbeauty\",\n",
    "    \"museumofsoum\",\n",
    "    \"mahiekasharma\",\n",
    "    \"riapalkar\",\n",
    "    \"nevaforevaa\",\n",
    "]\n",
    "\n",
    "MAX_REELS_PER_CREATOR = 10     # reels per creator\n",
    "MAX_FRAMES_PER_REEL   = 16     # sampled frames per reel\n",
    "DELETE_AFTER_PROCESS  = False    # delete .mp4 after analysis\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bc389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def cache_video_to_reel_cache(downloaded_path: str, cache_path: str) -> str:\n",
    "    Path(cache_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # If cache already exists and looks valid, use it\n",
    "    if os.path.exists(cache_path) and os.path.getsize(cache_path) > 0:\n",
    "        return cache_path\n",
    "\n",
    "    # Otherwise copy downloaded file into cache\n",
    "    shutil.copy2(downloaded_path, cache_path)\n",
    "    return cache_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbb0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def _manifest_path(cache_dir: str, handle: str) -> str:\n",
    "    safe_handle = (handle or \"unknown\").lstrip(\"@\").lower()\n",
    "    return str(Path(cache_dir) / safe_handle / \"manifest.jsonl\")\n",
    "\n",
    "def append_to_manifest(cache_dir: str, handle: str, record: dict):\n",
    "    Path(Path(cache_dir) / handle.lstrip(\"@\").lower()).mkdir(parents=True, exist_ok=True)\n",
    "    mp = _manifest_path(cache_dir, handle)\n",
    "    with open(mp, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def load_manifest_df(cache_dir: str, handle: str) -> pd.DataFrame:\n",
    "    mp = _manifest_path(cache_dir, handle)\n",
    "    if not os.path.exists(mp):\n",
    "        return pd.DataFrame()\n",
    "    rows = []\n",
    "    with open(mp, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except:\n",
    "                continue\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "428e68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers: stable reel_id + paths\n",
    "# ----------------------------\n",
    "_REEL_ID_PATTERNS = [\n",
    "    r\"instagram\\.com/reel/([^/?#]+)/?\",\n",
    "    r\"instagram\\.com/p/([^/?#]+)/?\",\n",
    "    r\"instagram\\.com/tv/([^/?#]+)/?\",\n",
    "]\n",
    "\n",
    "def extract_reel_id(reel_url: str) -> str:\n",
    "    \"\"\"Best-effort stable ID from Instagram URL (shortcode).\"\"\"\n",
    "    if not reel_url or not isinstance(reel_url, str):\n",
    "        return \"\"\n",
    "    for pat in _REEL_ID_PATTERNS:\n",
    "        m = re.search(pat, reel_url)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    # Fallback: hash the URL so cache still works\n",
    "    return hashlib.md5(reel_url.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "def video_path_for_reel(cache_dir: str, handle: str, reel_id: str) -> str:\n",
    "    # Store under handle to keep things tidy\n",
    "    safe_handle = (handle or \"unknown\").lstrip(\"@\").lower()\n",
    "    return str(Path(cache_dir) / safe_handle / f\"{reel_id}.mp4\")\n",
    "\n",
    "# ----------------------------\n",
    "# Your existing helpers\n",
    "# ----------------------------\n",
    "def flatten_comments(latest_comments, max_n=50):\n",
    "    \"\"\"Convert Apify comment objects ‚Üí simple text list.\"\"\"\n",
    "    if not isinstance(latest_comments, list):\n",
    "        return []\n",
    "    out = []\n",
    "    for c in latest_comments[:max_n]:\n",
    "        if isinstance(c, dict):\n",
    "            txt = c.get(\"text\") or c.get(\"body\") or \"\"\n",
    "            if txt.strip():\n",
    "                out.append(txt.strip())\n",
    "    return out\n",
    "\n",
    "\n",
    "def fetch_reels_from_apify_with_comments(\n",
    "    handle: str,\n",
    "    max_items: int = 8,\n",
    "    cache_dir: str = \"./reel_cache\",\n",
    "    use_local_cache_only: bool = False,   # ‚úÖ NEW FLAG\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch recent reel posts + basic metadata for a creator using an Apify actor.\n",
    "\n",
    "    If use_local_cache_only=True:\n",
    "      - DOES NOT call Apify\n",
    "      - Scans cache_dir/<handle>/*.mp4 and returns those as the reel list\n",
    "\n",
    "    Otherwise:\n",
    "      - Calls Apify and returns reel_url, caption, flat_comments plus:\n",
    "        reel_id, local_video_path, is_downloaded\n",
    "    \"\"\"\n",
    "    safe_handle = (handle or \"unknown\").lstrip(\"@\").lower()\n",
    "    handle_dir = Path(cache_dir) / safe_handle\n",
    "    handle_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ----------------------------\n",
    "    # LOCAL-ONLY MODE (NO APIFY CALLS)\n",
    "    # ----------------------------\n",
    "    if use_local_cache_only:\n",
    "        dfm = load_manifest_df(cache_dir, handle)\n",
    "\n",
    "        if dfm.empty:\n",
    "            # fallback: still try mp4 scan so you at least can run scoring\n",
    "            mp4s = [p for p in handle_dir.rglob(\"*.mp4\") if p.is_file() and p.stat().st_size > 0]\n",
    "            mp4s = sorted(mp4s, key=lambda p: p.stat().st_mtime, reverse=True)[:max_items]\n",
    "            rows = []\n",
    "            for p in mp4s:\n",
    "                rows.append({\n",
    "                    \"reel_url\": None,\n",
    "                    \"caption\": \"\",\n",
    "                    \"flat_comments\": [],\n",
    "                    \"reel_id\": p.stem,\n",
    "                    \"local_video_path\": str(p),\n",
    "                    \"is_downloaded\": True,\n",
    "                })\n",
    "            print(f\"\\nüìÅ Local-only mode: manifest missing; using {len(rows)} cached mp4s for @{safe_handle}\")\n",
    "            return pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "        # Normalize fields the pipeline expects\n",
    "        # (manifest row contains these keys if you store them as below)\n",
    "        dfm[\"is_downloaded\"] = dfm[\"local_video_path\"].apply(lambda p: os.path.exists(p) and os.path.getsize(p) > 0)\n",
    "\n",
    "        # Keep only downloaded reels, newest first if you stored timestamp\n",
    "        if \"downloaded_at\" in dfm.columns:\n",
    "            dfm = dfm.sort_values(\"downloaded_at\", ascending=False)\n",
    "        dfm = dfm[dfm[\"is_downloaded\"]].head(max_items)\n",
    "\n",
    "        out = dfm[[\"reel_url\", \"caption\", \"flat_comments\", \"reel_id\", \"local_video_path\", \"is_downloaded\"]].copy()\n",
    "\n",
    "        print(f\"\\nüìÅ Local-only mode: using {len(out)} cached reels for @{safe_handle} (Apify not called)\")\n",
    "        return out.reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------\n",
    "    # APIFY MODE (original behavior)\n",
    "    # ----------------------------\n",
    "    print(f\"\\nüì∏ Fetching reels for @{handle} via Apify...\")\n",
    "\n",
    "    try:\n",
    "        run_input = {\n",
    "            \"username\": [handle],     # MUST be array for this actor\n",
    "            \"resultsLimit\": max_items,\n",
    "        }\n",
    "\n",
    "        run = apify.actor(\"xMc5Ga1oCONPmWJIa\").call(run_input=run_input)\n",
    "        items = apify.dataset(run[\"defaultDatasetId\"]).list_items().items\n",
    "        \n",
    "                # Persist raw Apify output + derived fields (manifest)\n",
    "        for it in items:\n",
    "            # derive reel_url similarly to your DF logic\n",
    "            reel_url = it.get(\"url\") or it.get(\"postUrl\")\n",
    "            if (not reel_url) and it.get(\"shortCode\"):\n",
    "                reel_url = \"https://www.instagram.com/reel/\" + str(it[\"shortCode\"]) + \"/\"\n",
    "\n",
    "            if not reel_url:\n",
    "                continue\n",
    "\n",
    "            rid = extract_reel_id(reel_url)\n",
    "            local_path = video_path_for_reel(cache_dir, handle, rid)\n",
    "\n",
    "            record = {\n",
    "                \"downloaded_at\": time.time(),\n",
    "                \"handle\": handle,\n",
    "                \"reel_id\": rid,\n",
    "                \"reel_url\": reel_url,\n",
    "                \"caption\": it.get(\"caption\") or \"\",\n",
    "                \"flat_comments\": flatten_comments(it.get(\"latestComments\"), max_n=50),\n",
    "                \"local_video_path\": local_path,\n",
    "                \"apify_raw\": it,  # ‚úÖ store entire Apify object\n",
    "            }\n",
    "            append_to_manifest(cache_dir, handle, record)\n",
    "\n",
    "\n",
    "        if not items:\n",
    "            print(\"  ‚úó No items returned.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(items)\n",
    "        print(f\"  ‚úì Apify returned {len(df)} items. Columns: {list(df.columns)}\")\n",
    "\n",
    "        # URL column\n",
    "        if \"url\" in df.columns:\n",
    "            df[\"reel_url\"] = df[\"url\"]\n",
    "        elif \"postUrl\" in df.columns:\n",
    "            df[\"reel_url\"] = df[\"postUrl\"]\n",
    "        elif \"shortCode\" in df.columns:\n",
    "            df[\"reel_url\"] = \"https://www.instagram.com/reel/\" + df[\"shortCode\"].astype(str) + \"/\"\n",
    "        else:\n",
    "            df[\"reel_url\"] = None\n",
    "\n",
    "        # Caption\n",
    "        df[\"caption_norm\"] = df[\"caption\"] if \"caption\" in df.columns else \"\"\n",
    "\n",
    "        # Comments (shallow)\n",
    "        if \"latestComments\" in df.columns:\n",
    "            df[\"flat_comments\"] = df[\"latestComments\"].apply(lambda x: flatten_comments(x, max_n=50))\n",
    "        else:\n",
    "            df[\"flat_comments\"] = [[]]\n",
    "\n",
    "        # Filter valid reel URLs\n",
    "        mask = (\n",
    "            df[\"reel_url\"].notna()\n",
    "            & (df[\"reel_url\"].str.contains(\"/reel/\") | df[\"reel_url\"].str.contains(\"/p/\"))\n",
    "        )\n",
    "\n",
    "        out = df.loc[mask, [\"reel_url\", \"caption_norm\", \"flat_comments\"]].copy()\n",
    "        out = out.rename(columns={\"caption_norm\": \"caption\"})\n",
    "\n",
    "        # NEW: reel_id + local cache check\n",
    "        out[\"reel_id\"] = out[\"reel_url\"].apply(extract_reel_id)\n",
    "        out[\"local_video_path\"] = out[\"reel_id\"].apply(lambda rid: video_path_for_reel(cache_dir, handle, rid))\n",
    "\n",
    "        out[\"is_downloaded\"] = out[\"local_video_path\"].apply(lambda p: os.path.exists(p) and os.path.getsize(p) > 0)\n",
    "\n",
    "        print(f\"  ‚úì {len(out)} valid reels for @{handle} ({out['is_downloaded'].sum()} already downloaded)\")\n",
    "        return out.reset_index(drop=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Apify error for @{handle}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# OPTIONAL: run pipeline directly (skip downloads if present)\n",
    "# ----------------------------\n",
    "def ensure_download_and_score_reels(\n",
    "    df_reels: pd.DataFrame,\n",
    "    download_fn,   # function: (reel_url, out_path) -> out_path\n",
    "    score_fn,      # function: (video_path) -> dict (your compute_three_change_metrics_for_video)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each reel:\n",
    "      - If local_video_path exists ‚Üí skip download, score immediately\n",
    "      - Else download (if reel_url exists) ‚Üí then score\n",
    "    Returns df with added scoring columns.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for _, r in df_reels.iterrows():\n",
    "        reel_url = r.get(\"reel_url\")\n",
    "        video_path = r.get(\"local_video_path\")\n",
    "\n",
    "        if not video_path:\n",
    "            rows.append({**r.to_dict(), \"download_error\": \"Missing local_video_path\"})\n",
    "            continue\n",
    "\n",
    "        # Download only if missing AND we actually have a URL to download from\n",
    "        has_local = os.path.exists(video_path) and os.path.getsize(video_path) > 0\n",
    "        if not has_local:\n",
    "            if not reel_url:\n",
    "                rows.append({**r.to_dict(), \"download_error\": \"Video not cached and reel_url is None (local-only mode?)\"})\n",
    "                continue\n",
    "            try:\n",
    "                # ensure parent dir exists\n",
    "                Path(video_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                download_fn(reel_url, video_path)\n",
    "            except Exception as e:\n",
    "                rows.append({**r.to_dict(), \"download_error\": str(e)})\n",
    "                continue\n",
    "\n",
    "        # Score\n",
    "        try:\n",
    "            metrics = score_fn(video_path)\n",
    "            rows.append({**r.to_dict(), **metrics, \"download_error\": \"\"})\n",
    "        except Exception as e:\n",
    "            rows.append({**r.to_dict(), \"score_error\": str(e), \"download_error\": \"\"})\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d12438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4 ‚Äî FRAME SAMPLING FROM VIDEO\n",
    "# ============================================================================\n",
    "\n",
    "def sample_uniform_frames(video_path: str, max_frames: int = 32):\n",
    "    \"\"\"\n",
    "    Sample up to `max_frames` frames roughly uniformly across the video.\n",
    "    Returns: list of np.ndarray (BGR images)\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"    ‚úó Could not open video for frame sampling.\")\n",
    "        return frames\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Fallback if metadata is broken\n",
    "    if frame_count <= 0:\n",
    "        print(\"    ‚ö†Ô∏è CAP_PROP_FRAME_COUNT not available, reading sequentially.\")\n",
    "        i = 0\n",
    "        while i < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "            i += 1\n",
    "        cap.release()\n",
    "        print(f\"    ‚úì Sampled {len(frames)} frames (sequential fallback).\")\n",
    "        return frames\n",
    "\n",
    "    # Normal path: uniform indices\n",
    "    if frame_count <= max_frames:\n",
    "        indices = list(range(frame_count))\n",
    "    else:\n",
    "        indices = np.linspace(0, frame_count - 1, max_frames, dtype=int)\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"    ‚úì Sampled {len(frames)} frames (uniform across {frame_count} total).\")\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f31469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5 ‚Äî HISTOGRAM-BASED DISTANCE (METHOD #3 CORE PRIMITIVE)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_hist_distance(frame1, frame2, bins=32):\n",
    "    \"\"\"\n",
    "    Compute Bhattacharyya distance between color histograms of two frames.\n",
    "    Returns a float in [0, 1+] (0 = identical, larger = more different).\n",
    "    \"\"\"\n",
    "    # Convert to HSV or just use BGR; HSV can be more stable for lighting\n",
    "    f1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)\n",
    "    f2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h1 = cv2.calcHist([f1], [0, 1, 2], None, [bins, bins, bins], [0, 180, 0, 256, 0, 256])\n",
    "    h2 = cv2.calcHist([f2], [0, 1, 2], None, [bins, bins, bins], [0, 180, 0, 256, 0, 256])\n",
    "\n",
    "    h1 = h1.flatten().astype(\"float32\")\n",
    "    h2 = h2.flatten().astype(\"float32\")\n",
    "\n",
    "    h1 /= (h1.sum() + 1e-8)\n",
    "    h2 /= (h2.sum() + 1e-8)\n",
    "\n",
    "    dist = cv2.compareHist(h1, h2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "    return float(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f0d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6 ‚Äî CLIP SETUP (FOR METHOD #2)\n",
    "# ============================================================================\n",
    "\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def clip_embed_frame(frame_bgr):\n",
    "    \"\"\"\n",
    "    Compute CLIP embedding (L2-normalized) for a single frame (BGR).\n",
    "    Returns 1D numpy vector.\n",
    "    \"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(frame_rgb)\n",
    "\n",
    "    img = clip_preprocess(pil_img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = clip_model.encode_image(img)\n",
    "        emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return emb.cpu().numpy().flatten().astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d33e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7 ‚Äî THREE METRICS FOR ONE REEL\n",
    "#   1) Scene-change density (from histogram jumps)\n",
    "#   2) CLIP-embedding distance\n",
    "#   3) Histogram distance\n",
    "# ============================================================================\n",
    "\n",
    "def compute_three_change_metrics_for_video(video_path: str, max_frames: int = 32):\n",
    "    \"\"\"\n",
    "    For a given video:\n",
    "      - Sample frames\n",
    "      - Compute three frame-to-frame change metrics:\n",
    "          1) Scene-change density (hist-based threshold ‚Üí approx shot boundaries)\n",
    "          2) Mean CLIP embedding distance between consecutive frames\n",
    "          3) Mean histogram distance between consecutive frames\n",
    "      - Also returns normalized scores 0‚Äì10 for each metric.\n",
    "    \"\"\"\n",
    "    frames = sample_uniform_frames(video_path, max_frames=max_frames)\n",
    "    n_frames = len(frames)\n",
    "\n",
    "    if n_frames < 2:\n",
    "        return {\n",
    "            \"n_frames_used\": n_frames,\n",
    "            \"scene_change_count\": 0,\n",
    "            \"scene_change_density\": 0.0,\n",
    "            \"scene_score_0_10\": 0.0,\n",
    "            \"mean_clip_dist\": 0.0,\n",
    "            \"std_clip_dist\": 0.0,\n",
    "            \"clip_score_0_10\": 0.0,\n",
    "            \"mean_hist_dist\": 0.0,\n",
    "            \"std_hist_dist\": 0.0,\n",
    "            \"hist_score_0_10\": 0.0,\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # METHOD 3: Histogram diffs\n",
    "    # -------------------------\n",
    "    hist_dists = []\n",
    "    for i in range(1, n_frames):\n",
    "        d = compute_hist_distance(frames[i - 1], frames[i])\n",
    "        hist_dists.append(d)\n",
    "    hist_dists = np.array(hist_dists, dtype=np.float32)\n",
    "\n",
    "    mean_hist = float(hist_dists.mean())\n",
    "    std_hist = float(hist_dists.std())\n",
    "\n",
    "    # We'll assume typical Bhattacharyya distances are in [0, 1].\n",
    "    # Clip to [0,1] before mapping to 0‚Äì10\n",
    "    mean_hist_clipped = float(np.clip(mean_hist, 0.0, 1.0))\n",
    "    hist_score = round(mean_hist_clipped * 10.0, 2)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # METHOD 1: Scene-change density\n",
    "    #   - Use histogram jumps above a threshold to count \"scene changes\"\n",
    "    # -----------------------------------\n",
    "    # Heuristic threshold: tuneable\n",
    "    scene_thresh = 0.5\n",
    "    scene_changes = int((hist_dists > scene_thresh).sum())\n",
    "    scene_change_density = scene_changes / float(n_frames - 1)\n",
    "\n",
    "    # Normalize density (assuming >5 changes per 32 frames is already \"very high\")\n",
    "    scene_density_clipped = float(np.clip(scene_change_density * 5.0, 0.0, 1.0))\n",
    "    scene_score = round(scene_density_clipped * 10.0, 2)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # METHOD 2: CLIP embedding distances\n",
    "    # -----------------------------------\n",
    "    clip_embs = []\n",
    "    for f in frames:\n",
    "        e = clip_embed_frame(f)\n",
    "        clip_embs.append(e)\n",
    "    clip_embs = np.stack(clip_embs, axis=0)  # [n_frames, d]\n",
    "\n",
    "    # compute distances between consecutive embeddings\n",
    "    clip_dists = []\n",
    "    for i in range(1, n_frames):\n",
    "        v1 = clip_embs[i - 1]\n",
    "        v2 = clip_embs[i]\n",
    "        # Since vectors are normalized, 1 - cosine similarity ‚àà [0, 2]\n",
    "        cos_sim = float(np.dot(v1, v2))\n",
    "        d = 1.0 - cos_sim\n",
    "        clip_dists.append(d)\n",
    "    clip_dists = np.array(clip_dists, dtype=np.float32)\n",
    "\n",
    "    mean_clip = float(clip_dists.mean())\n",
    "    std_clip = float(clip_dists.std())\n",
    "\n",
    "    # Clip-sim distance is usually within [0, 1]; clip to [0,1]\n",
    "    mean_clip_clipped = float(np.clip(mean_clip, 0.0, 1.0))\n",
    "    clip_score = round(mean_clip_clipped * 10.0, 2)\n",
    "\n",
    "    return {\n",
    "        \"n_frames_used\": n_frames,\n",
    "        # scene-based\n",
    "        \"scene_change_count\": int(scene_changes),\n",
    "        \"scene_change_density\": float(scene_change_density),\n",
    "        \"scene_score_0_10\": scene_score,\n",
    "        # CLIP-based\n",
    "        \"mean_clip_dist\": mean_clip,\n",
    "        \"std_clip_dist\": std_clip,\n",
    "        \"clip_score_0_10\": clip_score,\n",
    "        # histogram-based\n",
    "        \"mean_hist_dist\": mean_hist,\n",
    "        \"std_hist_dist\": std_hist,\n",
    "        \"hist_score_0_10\": hist_score,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8416e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8 ‚Äî MAIN PIPELINE: CREATOR ‚Üí REELS ‚Üí DOWNLOAD/CACHE ‚Üí 3 SCORES\n",
    "# ============================================================================\n",
    "\n",
    "def run_change_metrics_pipeline_for_creators(\n",
    "    creator_list,\n",
    "    max_reels_per_creator: int = MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel: int = MAX_FRAMES_PER_REEL,\n",
    "    delete_after: bool = DELETE_AFTER_PROCESS,\n",
    "    use_local_cache_only: bool = True,\n",
    "    cache_dir: str = \"./reel_cache\",\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for creator in creator_list:\n",
    "        print(f\"\\n=== Processing creator (3 change metrics): {creator} ===\")\n",
    "\n",
    "        df_reels = fetch_reels_from_apify_with_comments(\n",
    "            handle=creator,\n",
    "            max_items=max_reels_per_creator,\n",
    "            cache_dir=cache_dir,\n",
    "            use_local_cache_only=use_local_cache_only,\n",
    "        )\n",
    "\n",
    "        if df_reels.empty:\n",
    "            print(f\"  ‚úó No reels found for {creator}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        for reel_idx, r in df_reels.iterrows():\n",
    "            reel_url = r.get(\"reel_url\")\n",
    "            caption  = r.get(\"caption\", \"\")\n",
    "\n",
    "            # ----------------------------\n",
    "            # Resolve video_path\n",
    "            # ----------------------------\n",
    "            video_path = None\n",
    "\n",
    "            if use_local_cache_only:\n",
    "                video_path = r.get(\"local_video_path\")\n",
    "                print(f\"\\n  ‚ñ∂ Reel {reel_idx} for {creator}: [LOCAL] {video_path}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"\\n  ‚ñ∂ Reel {reel_idx} for {creator}: {reel_url}\")\n",
    "\n",
    "                if not reel_url:\n",
    "                    print(\"    ‚úó Missing reel_url from Apify row, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Stable cache path (based on shortcode/hash)\n",
    "                reel_id    = extract_reel_id(reel_url)\n",
    "                cache_path = video_path_for_reel(cache_dir, creator, reel_id)\n",
    "\n",
    "                # If already cached, skip download\n",
    "                if os.path.exists(cache_path) and os.path.getsize(cache_path) > 0:\n",
    "                    video_path = cache_path\n",
    "                    print(f\"    ‚úÖ Using cached mp4: {video_path}\")\n",
    "                else:\n",
    "                    # Download via your helper\n",
    "                    task_id = f\"change3_{creator.replace('@', '')}\"\n",
    "                    downloaded_path = get_files_gem(reel_url, str(reel_idx), task_id)\n",
    "\n",
    "                    if (not downloaded_path) or (not os.path.exists(downloaded_path)):\n",
    "                        print(\"    ‚úó Download failed or path missing, skipping this reel.\")\n",
    "                        continue\n",
    "\n",
    "                    # Copy into cache so local-only mode works later\n",
    "                    video_path = cache_video_to_reel_cache(downloaded_path, cache_path)\n",
    "                    print(f\"    üíæ Cached video: {video_path}\")\n",
    "\n",
    "            if (not video_path) or (not os.path.exists(video_path)):\n",
    "                print(\"    ‚úó Video path missing / not found, skipping this reel.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"    üìÇ Local video path: {video_path}\")\n",
    "\n",
    "            # ----------------------------\n",
    "            # Compute metrics\n",
    "            # ----------------------------\n",
    "            try:\n",
    "                metrics = compute_three_change_metrics_for_video(\n",
    "                    video_path,\n",
    "                    max_frames=max_frames_per_reel,  # keep explicit\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚úó Error during change-metric computation: {repr(e)}\")\n",
    "                metrics = {\n",
    "                    \"n_frames_used\": 0,\n",
    "                    \"scene_change_count\": 0,\n",
    "                    \"scene_change_density\": 0.0,\n",
    "                    \"scene_score_0_10\": 0.0,\n",
    "                    \"mean_clip_dist\": 0.0,\n",
    "                    \"std_clip_dist\": 0.0,\n",
    "                    \"clip_score_0_10\": 0.0,\n",
    "                    \"mean_hist_dist\": 0.0,\n",
    "                    \"std_hist_dist\": 0.0,\n",
    "                    \"hist_score_0_10\": 0.0,\n",
    "                }\n",
    "\n",
    "            # ----------------------------\n",
    "            # Cleanup (ONLY for non-cache mode)\n",
    "            # ----------------------------\n",
    "            if delete_after and (not use_local_cache_only):\n",
    "                # NOTE: video_path might be cache_path; we should NEVER delete cache.\n",
    "                # Only delete the temporary download if it differs from cache_path.\n",
    "                try:\n",
    "                    # If we used cached, no delete. If we downloaded+copied, delete the downloaded file only.\n",
    "                    # We don't have downloaded_path in all branches, so do a safe check.\n",
    "                    if (not os.path.abspath(video_path).startswith(os.path.abspath(cache_dir))):\n",
    "                        os.remove(video_path)\n",
    "                        print(f\"    üßπ Deleted local video: {video_path}\")\n",
    "                    else:\n",
    "                        print(\"    üßπ Skipping delete (video is in cache_dir).\")\n",
    "                except OSError as e:\n",
    "                    print(f\"    ‚ö†Ô∏è Could not delete video: {e}\")\n",
    "\n",
    "            row = {\n",
    "                \"creator\": creator,\n",
    "                \"reel_idx\": int(reel_idx),\n",
    "                \"reel_url\": reel_url,\n",
    "                \"caption\": caption,\n",
    "            }\n",
    "            row.update(metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    df_reels_scores = pd.DataFrame(rows)\n",
    "    print(\"\\n=== 3-METRIC CHANGE PIPELINE DONE ===\")\n",
    "    print(\"Per-reel rows:\", len(df_reels_scores))\n",
    "\n",
    "    if not df_reels_scores.empty:\n",
    "        df_creator_agg = (\n",
    "            df_reels_scores\n",
    "            .groupby(\"creator\", as_index=False)\n",
    "            .agg(\n",
    "                n_reels=(\"reel_url\", \"count\"),\n",
    "                mean_scene_score=(\"scene_score_0_10\", \"mean\"),\n",
    "                mean_clip_score=(\"clip_score_0_10\", \"mean\"),\n",
    "                mean_hist_score=(\"hist_score_0_10\", \"mean\"),\n",
    "                max_scene_score=(\"scene_score_0_10\", \"max\"),\n",
    "                max_clip_score=(\"clip_score_0_10\", \"max\"),\n",
    "                max_hist_score=(\"hist_score_0_10\", \"max\"),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df_creator_agg = pd.DataFrame()\n",
    "\n",
    "    return df_reels_scores, df_creator_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7afea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing creator (3 change metrics): badassbrownbeauty ===\n",
      "\n",
      "üìÅ Local-only mode: using 10 cached reels for @badassbrownbeauty (Apify not called)\n",
      "\n",
      "  ‚ñ∂ Reel 0 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 3681 total).\n",
      "\n",
      "  ‚ñ∂ Reel 1 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1041 total).\n",
      "\n",
      "  ‚ñ∂ Reel 2 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2729 total).\n",
      "\n",
      "  ‚ñ∂ Reel 3 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1780 total).\n",
      "\n",
      "  ‚ñ∂ Reel 4 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2729 total).\n",
      "\n",
      "  ‚ñ∂ Reel 5 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1336 total).\n",
      "\n",
      "  ‚ñ∂ Reel 6 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2001 total).\n",
      "\n",
      "  ‚ñ∂ Reel 7 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2001 total).\n",
      "\n",
      "  ‚ñ∂ Reel 8 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1780 total).\n",
      "\n",
      "  ‚ñ∂ Reel 9 for badassbrownbeauty: [LOCAL] reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    üìÇ Local video path: reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1336 total).\n",
      "\n",
      "=== Processing creator (3 change metrics): museumofsoum ===\n",
      "\n",
      "üìÅ Local-only mode: using 7 cached reels for @museumofsoum (Apify not called)\n",
      "\n",
      "  ‚ñ∂ Reel 0 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\DPbcj8rjONK.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\DPbcj8rjONK.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 345 total).\n",
      "\n",
      "  ‚ñ∂ Reel 1 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\C_5FVUuql9u.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\C_5FVUuql9u.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1001 total).\n",
      "\n",
      "  ‚ñ∂ Reel 2 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4\n",
      "    ‚úì Sampled 4 frames (uniform across 1239 total).\n",
      "\n",
      "  ‚ñ∂ Reel 3 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 391 total).\n",
      "\n",
      "  ‚ñ∂ Reel 4 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 242 total).\n",
      "\n",
      "  ‚ñ∂ Reel 5 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\C3ucjNlpUvk.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\C3ucjNlpUvk.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 314 total).\n",
      "\n",
      "  ‚ñ∂ Reel 6 for museumofsoum: [LOCAL] reel_cache\\museumofsoum\\DOQVNa8k-wz.mp4\n",
      "    üìÇ Local video path: reel_cache\\museumofsoum\\DOQVNa8k-wz.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 684 total).\n",
      "\n",
      "=== Processing creator (3 change metrics): mahiekasharma ===\n",
      "\n",
      "üìÅ Local-only mode: using 10 cached reels for @mahiekasharma (Apify not called)\n",
      "\n",
      "  ‚ñ∂ Reel 0 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DQlkrImE020.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DQlkrImE020.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2712 total).\n",
      "\n",
      "  ‚ñ∂ Reel 1 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DOgeVxXjOQy.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DOgeVxXjOQy.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 5495 total).\n",
      "\n",
      "  ‚ñ∂ Reel 2 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DSNXxr0DEGR.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DSNXxr0DEGR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 940 total).\n",
      "\n",
      "  ‚ñ∂ Reel 3 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DOeSaKTgOKR.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DOeSaKTgOKR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1072 total).\n",
      "\n",
      "  ‚ñ∂ Reel 4 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DPIMMk6iAH9.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DPIMMk6iAH9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1373 total).\n",
      "\n",
      "  ‚ñ∂ Reel 5 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DQJfhfXE_-M.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DQJfhfXE_-M.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 4100 total).\n",
      "\n",
      "  ‚ñ∂ Reel 6 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DRmLHRZiFep.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DRmLHRZiFep.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2365 total).\n",
      "\n",
      "  ‚ñ∂ Reel 7 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DPHCyNqk3C2.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DPHCyNqk3C2.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1886 total).\n",
      "\n",
      "  ‚ñ∂ Reel 8 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\DHArsSBJPif.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\DHArsSBJPif.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 831 total).\n",
      "\n",
      "  ‚ñ∂ Reel 9 for mahiekasharma: [LOCAL] reel_cache\\mahiekasharma\\C7gyP8hJt8w.mp4\n",
      "    üìÇ Local video path: reel_cache\\mahiekasharma\\C7gyP8hJt8w.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 464 total).\n",
      "\n",
      "=== Processing creator (3 change metrics): riapalkar ===\n",
      "\n",
      "üìÅ Local-only mode: using 10 cached reels for @riapalkar (Apify not called)\n",
      "\n",
      "  ‚ñ∂ Reel 0 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DSHk9xHDHbZ.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DSHk9xHDHbZ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 946 total).\n",
      "\n",
      "  ‚ñ∂ Reel 1 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DJt0fUlN2i9.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DJt0fUlN2i9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1485 total).\n",
      "\n",
      "  ‚ñ∂ Reel 2 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DSCJUmeDPdk.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DSCJUmeDPdk.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 532 total).\n",
      "\n",
      "  ‚ñ∂ Reel 3 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DRhC6QwjAdi.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DRhC6QwjAdi.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 238 total).\n",
      "\n",
      "  ‚ñ∂ Reel 4 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DR9GraGDLmM.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DR9GraGDLmM.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 726 total).\n",
      "\n",
      "  ‚ñ∂ Reel 5 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DRkJ9kcjB5D.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DRkJ9kcjB5D.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1664 total).\n",
      "\n",
      "  ‚ñ∂ Reel 6 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DR4HqdZDPk8.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DR4HqdZDPk8.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1722 total).\n",
      "\n",
      "  ‚ñ∂ Reel 7 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DCUBdEoNrvH.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DCUBdEoNrvH.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 624 total).\n",
      "\n",
      "  ‚ñ∂ Reel 8 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DBOlZWXtrpn.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DBOlZWXtrpn.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 280 total).\n",
      "\n",
      "  ‚ñ∂ Reel 9 for riapalkar: [LOCAL] reel_cache\\riapalkar\\DSKtbhPjLEy.mp4\n",
      "    üìÇ Local video path: reel_cache\\riapalkar\\DSKtbhPjLEy.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 768 total).\n",
      "\n",
      "=== Processing creator (3 change metrics): nevaforevaa ===\n",
      "\n",
      "üìÅ Local-only mode: using 10 cached reels for @nevaforevaa (Apify not called)\n",
      "\n",
      "  ‚ñ∂ Reel 0 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DOleu4Uj3tA.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DOleu4Uj3tA.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 444 total).\n",
      "\n",
      "  ‚ñ∂ Reel 1 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DSKEKfgjzXK.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DSKEKfgjzXK.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 313 total).\n",
      "\n",
      "  ‚ñ∂ Reel 2 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DNn5ibjoCeJ.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DNn5ibjoCeJ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 261 total).\n",
      "\n",
      "  ‚ñ∂ Reel 3 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DRY52TBj8A1.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DRY52TBj8A1.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 152 total).\n",
      "\n",
      "  ‚ñ∂ Reel 4 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DJZPHsTP44X.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DJZPHsTP44X.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 180 total).\n",
      "\n",
      "  ‚ñ∂ Reel 5 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DSHFs7VD4yZ.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DSHFs7VD4yZ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 313 total).\n",
      "\n",
      "  ‚ñ∂ Reel 6 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DSIQabqj-Gz.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DSIQabqj-Gz.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 259 total).\n",
      "\n",
      "  ‚ñ∂ Reel 7 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DSCeC6BD2xg.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DSCeC6BD2xg.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 581 total).\n",
      "\n",
      "  ‚ñ∂ Reel 8 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DRyeYTvj8Q9.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DRyeYTvj8Q9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 259 total).\n",
      "\n",
      "  ‚ñ∂ Reel 9 for nevaforevaa: [LOCAL] reel_cache\\nevaforevaa\\DRd_HwYD_S0.mp4\n",
      "    üìÇ Local video path: reel_cache\\nevaforevaa\\DRd_HwYD_S0.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 459 total).\n",
      "\n",
      "=== 3-METRIC CHANGE PIPELINE DONE ===\n",
      "Per-reel rows: 47\n",
      "\n",
      "=== PER-REEL CHANGE SCORES (TOP 10 ROWS) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>reel_idx</th>\n",
       "      <th>reel_url</th>\n",
       "      <th>scene_score_0_10</th>\n",
       "      <th>clip_score_0_10</th>\n",
       "      <th>hist_score_0_10</th>\n",
       "      <th>scene_change_count</th>\n",
       "      <th>mean_clip_dist</th>\n",
       "      <th>mean_hist_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.instagram.com/p/DRxArMLDBOa/</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>0.184517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/DSFZKKMkaHP/</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.87</td>\n",
       "      <td>7</td>\n",
       "      <td>0.206956</td>\n",
       "      <td>0.386735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.instagram.com/p/DR4oT2ijOhC/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>0.083681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.instagram.com/p/DRo-zZAEf55/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050889</td>\n",
       "      <td>0.092220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.instagram.com/p/DR4oqOqDEUR/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026140</td>\n",
       "      <td>0.084284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.instagram.com/p/DR9Y07wkX8b/</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.73</td>\n",
       "      <td>7</td>\n",
       "      <td>0.169986</td>\n",
       "      <td>0.373392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.instagram.com/p/DSCzM7mDY95/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035469</td>\n",
       "      <td>0.061027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.instagram.com/p/DSCzayUjW1f/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033741</td>\n",
       "      <td>0.061275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.instagram.com/p/DRo_FVpEWjD/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>0.092152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.instagram.com/p/DR9Y07wkX8b/</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.73</td>\n",
       "      <td>7</td>\n",
       "      <td>0.169986</td>\n",
       "      <td>0.373392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  reel_idx                                  reel_url  \\\n",
       "0  badassbrownbeauty         0  https://www.instagram.com/p/DRxArMLDBOa/   \n",
       "1  badassbrownbeauty         1  https://www.instagram.com/p/DSFZKKMkaHP/   \n",
       "2  badassbrownbeauty         2  https://www.instagram.com/p/DR4oT2ijOhC/   \n",
       "3  badassbrownbeauty         3  https://www.instagram.com/p/DRo-zZAEf55/   \n",
       "4  badassbrownbeauty         4  https://www.instagram.com/p/DR4oqOqDEUR/   \n",
       "5  badassbrownbeauty         5  https://www.instagram.com/p/DR9Y07wkX8b/   \n",
       "6  badassbrownbeauty         6  https://www.instagram.com/p/DSCzM7mDY95/   \n",
       "7  badassbrownbeauty         7  https://www.instagram.com/p/DSCzayUjW1f/   \n",
       "8  badassbrownbeauty         8  https://www.instagram.com/p/DRo_FVpEWjD/   \n",
       "9  badassbrownbeauty         9  https://www.instagram.com/p/DR9Y07wkX8b/   \n",
       "\n",
       "   scene_score_0_10  clip_score_0_10  hist_score_0_10  scene_change_count  \\\n",
       "0              10.0             0.65             1.85                   4   \n",
       "1              10.0             2.07             3.87                   7   \n",
       "2               0.0             0.28             0.84                   0   \n",
       "3               0.0             0.51             0.92                   0   \n",
       "4               0.0             0.26             0.84                   0   \n",
       "5              10.0             1.70             3.73                   7   \n",
       "6               0.0             0.35             0.61                   0   \n",
       "7               0.0             0.34             0.61                   0   \n",
       "8               0.0             0.47             0.92                   0   \n",
       "9              10.0             1.70             3.73                   7   \n",
       "\n",
       "   mean_clip_dist  mean_hist_dist  \n",
       "0        0.065067        0.184517  \n",
       "1        0.206956        0.386735  \n",
       "2        0.027633        0.083681  \n",
       "3        0.050889        0.092220  \n",
       "4        0.026140        0.084284  \n",
       "5        0.169986        0.373392  \n",
       "6        0.035469        0.061027  \n",
       "7        0.033741        0.061275  \n",
       "8        0.047379        0.092152  \n",
       "9        0.169986        0.373392  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PER-CREATOR AVERAGE SCORES ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>n_reels</th>\n",
       "      <th>mean_scene_score</th>\n",
       "      <th>mean_clip_score</th>\n",
       "      <th>mean_hist_score</th>\n",
       "      <th>max_scene_score</th>\n",
       "      <th>max_clip_score</th>\n",
       "      <th>max_hist_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>10</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>1.792000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>10</td>\n",
       "      <td>6.334000</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>2.869000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>7</td>\n",
       "      <td>4.284286</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>3.817143</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>10</td>\n",
       "      <td>5.998000</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>3.806000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>10</td>\n",
       "      <td>8.333000</td>\n",
       "      <td>2.129000</td>\n",
       "      <td>4.762000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>8.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  n_reels  mean_scene_score  mean_clip_score  \\\n",
       "0  badassbrownbeauty       10          4.000000         0.833000   \n",
       "1      mahiekasharma       10          6.334000         0.942000   \n",
       "2       museumofsoum        7          4.284286         0.985714   \n",
       "3        nevaforevaa       10          5.998000         0.865000   \n",
       "4          riapalkar       10          8.333000         2.129000   \n",
       "\n",
       "   mean_hist_score  max_scene_score  max_clip_score  max_hist_score  \n",
       "0         1.792000             10.0            2.07            3.87  \n",
       "1         2.869000             10.0            1.89            6.15  \n",
       "2         3.817143             10.0            1.49            5.84  \n",
       "3         3.806000             10.0            1.17            5.70  \n",
       "4         4.762000             10.0            4.41            8.56  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 9 ‚Äî RUN PIPELINE & VIEW COMPARATIVE SCORES\n",
    "# ============================================================================\n",
    "\n",
    "df_reels_change, df_creator_change = run_change_metrics_pipeline_for_creators(\n",
    "    CREATOR_LIST,\n",
    "    max_reels_per_creator=MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel=MAX_FRAMES_PER_REEL,\n",
    "    delete_after=DELETE_AFTER_PROCESS,\n",
    "    use_local_cache_only = True\n",
    ")\n",
    "\n",
    "print(\"\\n=== PER-REEL CHANGE SCORES (TOP 10 ROWS) ===\")\n",
    "display(\n",
    "    df_reels_change[\n",
    "        [\n",
    "            \"creator\",\n",
    "            \"reel_idx\",\n",
    "            \"reel_url\",\n",
    "            \"scene_score_0_10\",\n",
    "            \"clip_score_0_10\",\n",
    "            \"hist_score_0_10\",\n",
    "            \"scene_change_count\",\n",
    "            \"mean_clip_dist\",\n",
    "            \"mean_hist_dist\",\n",
    "        ]\n",
    "    ].head(10)\n",
    ")\n",
    "\n",
    "print(\"\\n=== PER-CREATOR AVERAGE SCORES ===\")\n",
    "display(df_creator_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "184bf8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creators with labels: 78\n",
      "Creators with scene score: 5\n",
      "Creators matched: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool</td>\n",
       "      <td>mean_scene_score</td>\n",
       "      <td>5</td>\n",
       "      <td>0.511727</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aspirational</td>\n",
       "      <td>mean_scene_score</td>\n",
       "      <td>5</td>\n",
       "      <td>0.472109</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>communication</td>\n",
       "      <td>mean_scene_score</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.226413</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story_telling</td>\n",
       "      <td>mean_scene_score</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.390330</td>\n",
       "      <td>-0.153897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credible</td>\n",
       "      <td>mean_scene_score</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.640386</td>\n",
       "      <td>-0.666886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relatable</td>\n",
       "      <td>mean_scene_score</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.737641</td>\n",
       "      <td>-0.737865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label            metric  n   pearson  spearman\n",
       "0           cool  mean_scene_score  5  0.511727  0.600000\n",
       "1   aspirational  mean_scene_score  5  0.472109  0.600000\n",
       "4  communication  mean_scene_score  5 -0.226413 -0.200000\n",
       "5  story_telling  mean_scene_score  5 -0.390330 -0.153897\n",
       "3       credible  mean_scene_score  5 -0.640386 -0.666886\n",
       "2      relatable  mean_scene_score  5 -0.737641 -0.737865"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_norm</th>\n",
       "      <th>cool</th>\n",
       "      <th>aspirational</th>\n",
       "      <th>relatable</th>\n",
       "      <th>credible</th>\n",
       "      <th>communication</th>\n",
       "      <th>story_telling</th>\n",
       "      <th>mean_scene_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.334000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.284286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creator_norm  cool  aspirational  relatable  credible  communication  \\\n",
       "4          riapalkar   6.0           6.0        4.0       3.0            4.0   \n",
       "1      mahiekasharma   8.0           9.0        5.0       3.0            6.5   \n",
       "3        nevaforevaa   2.0           2.0        4.0       2.0            1.0   \n",
       "2       museumofsoum   4.0           4.0        5.0       4.0            2.0   \n",
       "0  badassbrownbeauty   3.0           3.0        7.0       9.0            9.0   \n",
       "\n",
       "   story_telling  mean_scene_score  \n",
       "4            4.0          8.333000  \n",
       "1            4.0          6.334000  \n",
       "3            1.0          5.998000  \n",
       "2            3.0          4.284286  \n",
       "0            9.0          4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ----------------------------\n",
    "# Load + normalize train_data.csv\n",
    "# ----------------------------\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "def norm_col(c):\n",
    "    c = str(c).replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    c = c.strip().lower()\n",
    "    c = re.sub(r\"\\s+\", \"_\", c)\n",
    "    c = re.sub(r\"_+\", \"_\", c)\n",
    "    return c\n",
    "\n",
    "df_train.columns = [norm_col(c) for c in df_train.columns]\n",
    "\n",
    "df_train[\"creator_norm\"] = df_train[\"creator\"].astype(str).str.strip().str.lstrip(\"@\").str.lower()\n",
    "\n",
    "traits = [\"cool\", \"aspirational\", \"relatable\", \"credible\", \"communication\", \"story_telling\"]\n",
    "\n",
    "# Ensure all trait columns exist (prints columns if not)\n",
    "missing = [t for t in traits if t not in df_train.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing trait cols {missing}. Available: {list(df_train.columns)}\")\n",
    "\n",
    "df_labels = (\n",
    "    df_train.groupby(\"creator_norm\", as_index=False)\n",
    "    .agg(**{t: (t, \"mean\") for t in traits})\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare metrics df (df_creator_change) + normalize creator\n",
    "# ----------------------------\n",
    "df_metrics = df_creator_change.copy()\n",
    "df_metrics[\"creator_norm\"] = df_metrics[\"creator\"].astype(str).str.strip().str.lstrip(\"@\").str.lower()\n",
    "\n",
    "if \"mean_scene_score\" not in df_metrics.columns:\n",
    "    raise ValueError(f\"mean_scene_score not found in df_creator_change. Columns: {list(df_metrics.columns)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Merge + correlate (mean_scene_score vs each trait)\n",
    "# ----------------------------\n",
    "df_m = df_labels.merge(\n",
    "    df_metrics[[\"creator_norm\", \"mean_scene_score\"]],\n",
    "    on=\"creator_norm\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "def corr(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    y = pd.to_numeric(y, errors=\"coerce\")\n",
    "    m = x.notna() & y.notna()\n",
    "    if m.sum() < 3:\n",
    "        return {\"n\": int(m.sum()), \"pearson\": np.nan, \"spearman\": np.nan}\n",
    "    return {\n",
    "        \"n\": int(m.sum()),\n",
    "        \"pearson\": float(x[m].corr(y[m], method=\"pearson\")),\n",
    "        \"spearman\": float(x[m].corr(y[m], method=\"spearman\")),\n",
    "    }\n",
    "\n",
    "out = pd.DataFrame([\n",
    "    {\"label\": t, \"metric\": \"mean_scene_score\", **corr(df_m[t], df_m[\"mean_scene_score\"])}\n",
    "    for t in traits\n",
    "]).sort_values(\"pearson\", ascending=False)\n",
    "\n",
    "print(\"Creators with labels:\", len(df_labels))\n",
    "print(\"Creators with scene score:\", df_metrics[\"mean_scene_score\"].notna().sum())\n",
    "print(\"Creators matched:\", len(df_m))\n",
    "\n",
    "display(out)\n",
    "display(df_m.sort_values(\"mean_scene_score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9de4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Face-density (LOCAL ONLY): badassbrownbeauty ===\n",
      "Found 9 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1336 total).\n",
      "  ‚ñ∂ 1: reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1780 total).\n",
      "  ‚ñ∂ 2: reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2729 total).\n",
      "  ‚ñ∂ 3: reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 3681 total).\n",
      "  ‚ñ∂ 4: reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1780 total).\n",
      "  ‚ñ∂ 5: reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2001 total).\n",
      "  ‚ñ∂ 6: reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2001 total).\n",
      "  ‚ñ∂ 7: reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2729 total).\n",
      "  ‚ñ∂ 8: reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1041 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): museumofsoum ===\n",
      "Found 7 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\museumofsoum\\DPbcj8rjONK.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 345 total).\n",
      "  ‚ñ∂ 1: reel_cache\\museumofsoum\\C_5FVUuql9u.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1001 total).\n",
      "  ‚ñ∂ 2: reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4\n",
      "    ‚úì Sampled 4 frames (uniform across 1239 total).\n",
      "  ‚ñ∂ 3: reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 391 total).\n",
      "  ‚ñ∂ 4: reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 242 total).\n",
      "  ‚ñ∂ 5: reel_cache\\museumofsoum\\C3ucjNlpUvk.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 314 total).\n",
      "  ‚ñ∂ 6: reel_cache\\museumofsoum\\DOQVNa8k-wz.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 684 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): mahiekasharma ===\n",
      "Found 10 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\mahiekasharma\\DQlkrImE020.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2712 total).\n",
      "  ‚ñ∂ 1: reel_cache\\mahiekasharma\\DOgeVxXjOQy.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 5495 total).\n",
      "  ‚ñ∂ 2: reel_cache\\mahiekasharma\\DSNXxr0DEGR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 940 total).\n",
      "  ‚ñ∂ 3: reel_cache\\mahiekasharma\\DOeSaKTgOKR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1072 total).\n",
      "  ‚ñ∂ 4: reel_cache\\mahiekasharma\\DPIMMk6iAH9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1373 total).\n",
      "  ‚ñ∂ 5: reel_cache\\mahiekasharma\\DQJfhfXE_-M.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 4100 total).\n",
      "  ‚ñ∂ 6: reel_cache\\mahiekasharma\\DRmLHRZiFep.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2365 total).\n",
      "  ‚ñ∂ 7: reel_cache\\mahiekasharma\\DPHCyNqk3C2.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1886 total).\n",
      "  ‚ñ∂ 8: reel_cache\\mahiekasharma\\DHArsSBJPif.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 831 total).\n",
      "  ‚ñ∂ 9: reel_cache\\mahiekasharma\\C7gyP8hJt8w.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 464 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): riapalkar ===\n",
      "Found 10 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\riapalkar\\DSHk9xHDHbZ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 946 total).\n",
      "  ‚ñ∂ 1: reel_cache\\riapalkar\\DJt0fUlN2i9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1485 total).\n",
      "  ‚ñ∂ 2: reel_cache\\riapalkar\\DSCJUmeDPdk.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 532 total).\n",
      "  ‚ñ∂ 3: reel_cache\\riapalkar\\DRhC6QwjAdi.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 238 total).\n",
      "  ‚ñ∂ 4: reel_cache\\riapalkar\\DR9GraGDLmM.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 726 total).\n",
      "  ‚ñ∂ 5: reel_cache\\riapalkar\\DRkJ9kcjB5D.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1664 total).\n",
      "  ‚ñ∂ 6: reel_cache\\riapalkar\\DR4HqdZDPk8.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1722 total).\n",
      "  ‚ñ∂ 7: reel_cache\\riapalkar\\DCUBdEoNrvH.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 624 total).\n",
      "  ‚ñ∂ 8: reel_cache\\riapalkar\\DBOlZWXtrpn.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 280 total).\n",
      "  ‚ñ∂ 9: reel_cache\\riapalkar\\DSKtbhPjLEy.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 768 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): nevaforevaa ===\n",
      "Found 10 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\nevaforevaa\\DOleu4Uj3tA.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 444 total).\n",
      "  ‚ñ∂ 1: reel_cache\\nevaforevaa\\DSKEKfgjzXK.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 313 total).\n",
      "  ‚ñ∂ 2: reel_cache\\nevaforevaa\\DNn5ibjoCeJ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 261 total).\n",
      "  ‚ñ∂ 3: reel_cache\\nevaforevaa\\DRY52TBj8A1.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 152 total).\n",
      "  ‚ñ∂ 4: reel_cache\\nevaforevaa\\DJZPHsTP44X.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 180 total).\n",
      "  ‚ñ∂ 5: reel_cache\\nevaforevaa\\DSHFs7VD4yZ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 313 total).\n",
      "  ‚ñ∂ 6: reel_cache\\nevaforevaa\\DSIQabqj-Gz.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 259 total).\n",
      "  ‚ñ∂ 7: reel_cache\\nevaforevaa\\DSCeC6BD2xg.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 581 total).\n",
      "  ‚ñ∂ 8: reel_cache\\nevaforevaa\\DRyeYTvj8Q9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 259 total).\n",
      "  ‚ñ∂ 9: reel_cache\\nevaforevaa\\DRd_HwYD_S0.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 459 total).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>reel_idx</th>\n",
       "      <th>video_path</th>\n",
       "      <th>n_frames_used</th>\n",
       "      <th>n_face_frames</th>\n",
       "      <th>face_frame_density</th>\n",
       "      <th>face_density_0_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>1</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>2</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>4</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>5</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>6</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>7</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>8</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>0</td>\n",
       "      <td>reel_cache\\museumofsoum\\DPbcj8rjONK.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  reel_idx                                    video_path  \\\n",
       "0  badassbrownbeauty         0  reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4   \n",
       "1  badassbrownbeauty         1  reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4   \n",
       "2  badassbrownbeauty         2  reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4   \n",
       "3  badassbrownbeauty         3  reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4   \n",
       "4  badassbrownbeauty         4  reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4   \n",
       "5  badassbrownbeauty         5  reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4   \n",
       "6  badassbrownbeauty         6  reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4   \n",
       "7  badassbrownbeauty         7  reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4   \n",
       "8  badassbrownbeauty         8  reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4   \n",
       "9       museumofsoum         0       reel_cache\\museumofsoum\\DPbcj8rjONK.mp4   \n",
       "\n",
       "   n_frames_used  n_face_frames  face_frame_density  face_density_0_10  \n",
       "0             16             16              1.0000              10.00  \n",
       "1             16             16              1.0000              10.00  \n",
       "2             16             16              1.0000              10.00  \n",
       "3             16             15              0.9375               9.38  \n",
       "4             16             16              1.0000              10.00  \n",
       "5             16             16              1.0000              10.00  \n",
       "6             16             16              1.0000              10.00  \n",
       "7             16             16              1.0000              10.00  \n",
       "8             16             16              1.0000              10.00  \n",
       "9             16             16              1.0000              10.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>n_reels</th>\n",
       "      <th>mean_face_density</th>\n",
       "      <th>mean_face_density_0_10</th>\n",
       "      <th>creator_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>9.931111</td>\n",
       "      <td>badassbrownbeauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>10</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>mahiekasharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741071</td>\n",
       "      <td>7.411429</td>\n",
       "      <td>museumofsoum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>6.939000</td>\n",
       "      <td>nevaforevaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>5.436000</td>\n",
       "      <td>riapalkar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  n_reels  mean_face_density  mean_face_density_0_10  \\\n",
       "0  badassbrownbeauty        9           0.993056                9.931111   \n",
       "1      mahiekasharma       10           0.587500                5.875000   \n",
       "2       museumofsoum        7           0.741071                7.411429   \n",
       "3        nevaforevaa       10           0.693750                6.939000   \n",
       "4          riapalkar       10           0.543750                5.436000   \n",
       "\n",
       "        creator_norm  \n",
       "0  badassbrownbeauty  \n",
       "1      mahiekasharma  \n",
       "2       museumofsoum  \n",
       "3        nevaforevaa  \n",
       "4          riapalkar  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# HAAR FACE HELPERS (self-contained)\n",
    "# ----------------------------\n",
    "_FACE_CASCADE = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\", \".mkv\", \".webm\"}\n",
    "\n",
    "def frame_has_face_haar(frame_bgr, min_face_width_frac=0.06):\n",
    "    if frame_bgr is None:\n",
    "        return False\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    if h == 0 or w == 0:\n",
    "        return False\n",
    "\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    min_w = max(24, int(w * min_face_width_frac))\n",
    "    faces = _FACE_CASCADE.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(min_w, min_w),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "    )\n",
    "    return len(faces) > 0\n",
    "\n",
    "def compute_face_density_for_frames(frames, min_face_width_frac=0.06):\n",
    "    if not frames:\n",
    "        return 0, 0.0\n",
    "    flags = [frame_has_face_haar(f, min_face_width_frac=min_face_width_frac) for f in frames]\n",
    "    n_face = int(np.sum(flags))\n",
    "    dens = float(n_face / len(frames))\n",
    "    return n_face, dens\n",
    "\n",
    "def compute_face_density_for_video(video_path: str, max_frames: int = 16, min_face_width_frac: float = 0.06):\n",
    "    frames = sample_uniform_frames(video_path, max_frames=max_frames)  # uses your existing sampler\n",
    "    n = len(frames)\n",
    "    if n == 0:\n",
    "        return {\"n_frames_used\": 0, \"n_face_frames\": 0, \"face_frame_density\": 0.0, \"face_density_0_10\": 0.0}\n",
    "\n",
    "    n_face, dens = compute_face_density_for_frames(frames, min_face_width_frac=min_face_width_frac)\n",
    "    return {\n",
    "        \"n_frames_used\": int(n),\n",
    "        \"n_face_frames\": int(n_face),\n",
    "        \"face_frame_density\": float(dens),\n",
    "        \"face_density_0_10\": round(float(np.clip(dens, 0.0, 1.0) * 10.0), 2),\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# LOCAL CACHE SCAN\n",
    "# ----------------------------\n",
    "def list_cached_videos_for_creator(cache_root: str, creator: str, max_items: int = 10):\n",
    "    creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "    root = Path(cache_root)\n",
    "\n",
    "    cand = []\n",
    "    # 1) reels_cache/<creator>/**/*\n",
    "    p1 = root / creator_norm\n",
    "    if p1.exists():\n",
    "        cand += [p for p in p1.rglob(\"*\") if p.is_file() and p.suffix.lower() in VIDEO_EXTS and p.stat().st_size > 0]\n",
    "\n",
    "    # 2) reels_cache/**/*<creator>*/*.*\n",
    "    if root.exists():\n",
    "        cand += [\n",
    "            p for p in root.rglob(\"*\")\n",
    "            if p.is_file()\n",
    "            and p.suffix.lower() in VIDEO_EXTS\n",
    "            and p.stat().st_size > 0\n",
    "            and (creator_norm in str(p.parent).lower() or creator_norm in str(p).lower())\n",
    "        ]\n",
    "\n",
    "    # dedupe + sort newest first\n",
    "    cand = list({str(p): p for p in cand}.values())\n",
    "    cand = sorted(cand, key=lambda p: p.stat().st_mtime, reverse=True)[:max_items]\n",
    "    return cand\n",
    "\n",
    "def run_face_density_pipeline_for_creators_local(\n",
    "    creator_list,\n",
    "    cache_dir: str = \"reels_cache\",\n",
    "    max_reels_per_creator: int = 5,\n",
    "    max_frames_per_reel: int = 16,\n",
    "    min_face_width_frac: float = 0.06,\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for creator in creator_list:\n",
    "        creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "        vids = list_cached_videos_for_creator(cache_dir, creator, max_items=max_reels_per_creator)\n",
    "\n",
    "        print(f\"\\n=== Face-density (LOCAL ONLY): {creator_norm} ===\")\n",
    "        print(f\"Found {len(vids)} cached videos in {cache_dir}\")\n",
    "\n",
    "        for i, p in enumerate(vids):\n",
    "            video_path = str(p)\n",
    "            print(f\"  ‚ñ∂ {i}: {video_path}\")\n",
    "\n",
    "            metrics = compute_face_density_for_video(\n",
    "                video_path,\n",
    "                max_frames=max_frames_per_reel,\n",
    "                min_face_width_frac=min_face_width_frac,\n",
    "            )\n",
    "\n",
    "            rows.append({\n",
    "                \"creator\": creator_norm,\n",
    "                \"reel_idx\": i,\n",
    "                \"video_path\": video_path,\n",
    "                **metrics,\n",
    "            })\n",
    "\n",
    "    df_reels_face = pd.DataFrame(rows)\n",
    "\n",
    "    if not df_reels_face.empty:\n",
    "        df_creator_face = (\n",
    "            df_reels_face\n",
    "            .groupby(\"creator\", as_index=False)\n",
    "            .agg(\n",
    "                n_reels=(\"reel_idx\", \"count\"),\n",
    "                mean_face_density=(\"face_frame_density\", \"mean\"),\n",
    "                mean_face_density_0_10=(\"face_density_0_10\", \"mean\"),\n",
    "            )\n",
    "        )\n",
    "        df_creator_face[\"creator_norm\"] = df_creator_face[\"creator\"]\n",
    "    else:\n",
    "        df_creator_face = pd.DataFrame(columns=[\n",
    "            \"creator\", \"n_reels\", \"mean_face_density\", \"mean_face_density_0_10\", \"creator_norm\"\n",
    "        ])\n",
    "\n",
    "    return df_reels_face, df_creator_face\n",
    "\n",
    "# ----------------------------\n",
    "# RUN (change cache_dir to your actual folder name)\n",
    "# ----------------------------\n",
    "df_reels_face, df_creator_face = run_face_density_pipeline_for_creators_local(\n",
    "    CREATOR_LIST,\n",
    "    cache_dir=\"reel_cache\",  # <-- you used this in your error; change if your folder is reels_cache\n",
    "    max_reels_per_creator=MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel=MAX_FRAMES_PER_REEL,\n",
    "    min_face_width_frac=0.06,\n",
    ")\n",
    "\n",
    "display(df_reels_face.head(10))\n",
    "display(df_creator_face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a8fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.635939</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aspirational</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.615553</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label             metric  n   pearson  spearman\n",
       "0          cool  mean_face_density  5 -0.635939      -0.6\n",
       "1  aspirational  mean_face_density  5 -0.615553      -0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_norm</th>\n",
       "      <th>cool</th>\n",
       "      <th>aspirational</th>\n",
       "      <th>mean_face_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.993056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.693750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.543750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creator_norm  cool  aspirational  mean_face_density\n",
       "0  badassbrownbeauty   3.0           3.0           0.993056\n",
       "2       museumofsoum   4.0           4.0           0.741071\n",
       "3        nevaforevaa   2.0           2.0           0.693750\n",
       "1      mahiekasharma   8.0           9.0           0.587500\n",
       "4          riapalkar   6.0           6.0           0.543750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_train.columns = [c.strip().lower() for c in df_train.columns]\n",
    "df_train[\"creator_norm\"] = df_train[\"creator\"].astype(str).str.strip().str.lstrip(\"@\").str.lower()\n",
    "\n",
    "traits = [\"cool\", \"aspirational\", \"relatable\", \"credible\", \"communication\", \"story_telling\"]\n",
    "\n",
    "df_labels = (\n",
    "    df_train.groupby(\"creator_norm\", as_index=False)\n",
    "    .agg(**{t: (t, \"mean\") for t in traits})\n",
    ")\n",
    "\n",
    "df_m = df_labels.merge(\n",
    "    df_creator_face[[\"creator_norm\", \"mean_face_density\"]],\n",
    "    on=\"creator_norm\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "def corr(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    y = pd.to_numeric(y, errors=\"coerce\")\n",
    "    m = x.notna() & y.notna()\n",
    "    if m.sum() < 3:\n",
    "        return {\"n\": int(m.sum()), \"pearson\": np.nan, \"spearman\": np.nan}\n",
    "    return {\n",
    "        \"n\": int(m.sum()),\n",
    "        \"pearson\": float(x[m].corr(y[m], method=\"pearson\")),\n",
    "        \"spearman\": float(x[m].corr(y[m], method=\"spearman\")),\n",
    "    }\n",
    "\n",
    "out_rows = []\n",
    "for t in traits:\n",
    "    out_rows.append({\n",
    "        \"label\": t,\n",
    "        \"metric\": \"mean_face_density\",\n",
    "        **corr(df_m[t], df_m[\"mean_face_density\"])\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(out_rows).sort_values(\"pearson\", ascending=False)\n",
    "\n",
    "display(out)\n",
    "display(df_m.sort_values(\"mean_face_density\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884687aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Face-density (LOCAL ONLY): badassbrownbeauty ===\n",
      "Found 9 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1336 total).\n",
      "  ‚ñ∂ 1: reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1780 total).\n",
      "  ‚ñ∂ 2: reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2729 total).\n",
      "  ‚ñ∂ 3: reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 3681 total).\n",
      "  ‚ñ∂ 4: reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1780 total).\n",
      "  ‚ñ∂ 5: reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2001 total).\n",
      "  ‚ñ∂ 6: reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2001 total).\n",
      "  ‚ñ∂ 7: reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2729 total).\n",
      "  ‚ñ∂ 8: reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1041 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): museumofsoum ===\n",
      "Found 7 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\museumofsoum\\DPbcj8rjONK.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 345 total).\n",
      "  ‚ñ∂ 1: reel_cache\\museumofsoum\\C_5FVUuql9u.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1001 total).\n",
      "  ‚ñ∂ 2: reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4\n",
      "    ‚úì Sampled 4 frames (uniform across 1239 total).\n",
      "  ‚ñ∂ 3: reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 391 total).\n",
      "  ‚ñ∂ 4: reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 242 total).\n",
      "  ‚ñ∂ 5: reel_cache\\museumofsoum\\C3ucjNlpUvk.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 314 total).\n",
      "  ‚ñ∂ 6: reel_cache\\museumofsoum\\DOQVNa8k-wz.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 684 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): mahiekasharma ===\n",
      "Found 10 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\mahiekasharma\\DQlkrImE020.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2712 total).\n",
      "  ‚ñ∂ 1: reel_cache\\mahiekasharma\\DOgeVxXjOQy.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 5495 total).\n",
      "  ‚ñ∂ 2: reel_cache\\mahiekasharma\\DSNXxr0DEGR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 940 total).\n",
      "  ‚ñ∂ 3: reel_cache\\mahiekasharma\\DOeSaKTgOKR.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1072 total).\n",
      "  ‚ñ∂ 4: reel_cache\\mahiekasharma\\DPIMMk6iAH9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1373 total).\n",
      "  ‚ñ∂ 5: reel_cache\\mahiekasharma\\DQJfhfXE_-M.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 4100 total).\n",
      "  ‚ñ∂ 6: reel_cache\\mahiekasharma\\DRmLHRZiFep.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 2365 total).\n",
      "  ‚ñ∂ 7: reel_cache\\mahiekasharma\\DPHCyNqk3C2.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1886 total).\n",
      "  ‚ñ∂ 8: reel_cache\\mahiekasharma\\DHArsSBJPif.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 831 total).\n",
      "  ‚ñ∂ 9: reel_cache\\mahiekasharma\\C7gyP8hJt8w.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 464 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): riapalkar ===\n",
      "Found 10 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\riapalkar\\DSHk9xHDHbZ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 946 total).\n",
      "  ‚ñ∂ 1: reel_cache\\riapalkar\\DJt0fUlN2i9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1485 total).\n",
      "  ‚ñ∂ 2: reel_cache\\riapalkar\\DSCJUmeDPdk.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 532 total).\n",
      "  ‚ñ∂ 3: reel_cache\\riapalkar\\DRhC6QwjAdi.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 238 total).\n",
      "  ‚ñ∂ 4: reel_cache\\riapalkar\\DR9GraGDLmM.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 726 total).\n",
      "  ‚ñ∂ 5: reel_cache\\riapalkar\\DRkJ9kcjB5D.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1664 total).\n",
      "  ‚ñ∂ 6: reel_cache\\riapalkar\\DR4HqdZDPk8.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 1722 total).\n",
      "  ‚ñ∂ 7: reel_cache\\riapalkar\\DCUBdEoNrvH.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 624 total).\n",
      "  ‚ñ∂ 8: reel_cache\\riapalkar\\DBOlZWXtrpn.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 280 total).\n",
      "  ‚ñ∂ 9: reel_cache\\riapalkar\\DSKtbhPjLEy.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 768 total).\n",
      "\n",
      "=== Face-density (LOCAL ONLY): nevaforevaa ===\n",
      "Found 10 cached videos in reel_cache\n",
      "  ‚ñ∂ 0: reel_cache\\nevaforevaa\\DOleu4Uj3tA.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 444 total).\n",
      "  ‚ñ∂ 1: reel_cache\\nevaforevaa\\DSKEKfgjzXK.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 313 total).\n",
      "  ‚ñ∂ 2: reel_cache\\nevaforevaa\\DNn5ibjoCeJ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 261 total).\n",
      "  ‚ñ∂ 3: reel_cache\\nevaforevaa\\DRY52TBj8A1.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 152 total).\n",
      "  ‚ñ∂ 4: reel_cache\\nevaforevaa\\DJZPHsTP44X.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 180 total).\n",
      "  ‚ñ∂ 5: reel_cache\\nevaforevaa\\DSHFs7VD4yZ.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 313 total).\n",
      "  ‚ñ∂ 6: reel_cache\\nevaforevaa\\DSIQabqj-Gz.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 259 total).\n",
      "  ‚ñ∂ 7: reel_cache\\nevaforevaa\\DSCeC6BD2xg.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 581 total).\n",
      "  ‚ñ∂ 8: reel_cache\\nevaforevaa\\DRyeYTvj8Q9.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 259 total).\n",
      "  ‚ñ∂ 9: reel_cache\\nevaforevaa\\DRd_HwYD_S0.mp4\n",
      "    ‚úì Sampled 16 frames (uniform across 459 total).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>reel_idx</th>\n",
       "      <th>video_path</th>\n",
       "      <th>n_frames_used</th>\n",
       "      <th>n_face_frames</th>\n",
       "      <th>face_frame_density</th>\n",
       "      <th>face_density_0_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>1</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>2</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>4</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>5</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>6</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>7</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>8</td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>0</td>\n",
       "      <td>reel_cache\\museumofsoum\\DPbcj8rjONK.mp4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  reel_idx                                    video_path  \\\n",
       "0  badassbrownbeauty         0  reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4   \n",
       "1  badassbrownbeauty         1  reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4   \n",
       "2  badassbrownbeauty         2  reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4   \n",
       "3  badassbrownbeauty         3  reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4   \n",
       "4  badassbrownbeauty         4  reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4   \n",
       "5  badassbrownbeauty         5  reel_cache\\badassbrownbeauty\\DSCzayUjW1f.mp4   \n",
       "6  badassbrownbeauty         6  reel_cache\\badassbrownbeauty\\DSCzM7mDY95.mp4   \n",
       "7  badassbrownbeauty         7  reel_cache\\badassbrownbeauty\\DR4oqOqDEUR.mp4   \n",
       "8  badassbrownbeauty         8  reel_cache\\badassbrownbeauty\\DSFZKKMkaHP.mp4   \n",
       "9       museumofsoum         0       reel_cache\\museumofsoum\\DPbcj8rjONK.mp4   \n",
       "\n",
       "   n_frames_used  n_face_frames  face_frame_density  face_density_0_10  \n",
       "0             16             16              1.0000              10.00  \n",
       "1             16             16              1.0000              10.00  \n",
       "2             16             16              1.0000              10.00  \n",
       "3             16             15              0.9375               9.38  \n",
       "4             16             16              1.0000              10.00  \n",
       "5             16             16              1.0000              10.00  \n",
       "6             16             16              1.0000              10.00  \n",
       "7             16             16              1.0000              10.00  \n",
       "8             16             16              1.0000              10.00  \n",
       "9             16             16              1.0000              10.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>n_reels</th>\n",
       "      <th>mean_face_density</th>\n",
       "      <th>mean_face_density_0_10</th>\n",
       "      <th>creator_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>9.931111</td>\n",
       "      <td>badassbrownbeauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>10</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>6.373000</td>\n",
       "      <td>mahiekasharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>7</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>8.392857</td>\n",
       "      <td>museumofsoum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>7.815000</td>\n",
       "      <td>nevaforevaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.999000</td>\n",
       "      <td>riapalkar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  n_reels  mean_face_density  mean_face_density_0_10  \\\n",
       "0  badassbrownbeauty        9           0.993056                9.931111   \n",
       "1      mahiekasharma       10           0.637500                6.373000   \n",
       "2       museumofsoum        7           0.839286                8.392857   \n",
       "3        nevaforevaa       10           0.781250                7.815000   \n",
       "4          riapalkar       10           0.700000                6.999000   \n",
       "\n",
       "        creator_norm  \n",
       "0  badassbrownbeauty  \n",
       "1      mahiekasharma  \n",
       "2       museumofsoum  \n",
       "3        nevaforevaa  \n",
       "4          riapalkar  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# HAAR FACE HELPERS (self-contained)\n",
    "# ----------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "_FRONTAL = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "_PROFILE = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_profileface.xml\")\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\", \".mkv\", \".webm\"}\n",
    "\n",
    "\n",
    "def _detect_any(cascade, gray, min_w):\n",
    "    faces = cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(min_w, min_w),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "    )\n",
    "    return len(faces) > 0\n",
    "\n",
    "def frame_has_face_haar(frame_bgr, min_face_width_frac=0.06, include_side=True):\n",
    "    \"\"\"\n",
    "    Returns True if a face is detected:\n",
    "      - frontal cascade (always)\n",
    "      - plus profile cascade (optional) on original + flipped frame\n",
    "    \"\"\"\n",
    "    if frame_bgr is None:\n",
    "        return False\n",
    "\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    if h == 0 or w == 0:\n",
    "        return False\n",
    "\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    min_w = max(24, int(w * min_face_width_frac))\n",
    "\n",
    "    # 1) frontal\n",
    "    if _detect_any(_FRONTAL, gray, min_w):\n",
    "        return True\n",
    "\n",
    "    if not include_side:\n",
    "        return False\n",
    "\n",
    "    # 2) side/profile (original)\n",
    "    if _detect_any(_PROFILE, gray, min_w):\n",
    "        return True\n",
    "\n",
    "    # 3) side/profile (flipped) to catch opposite direction\n",
    "    gray_flip = cv2.flip(gray, 1)\n",
    "    if _detect_any(_PROFILE, gray_flip, min_w):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def compute_face_density_for_frames(frames, min_face_width_frac=0.06):\n",
    "    if not frames:\n",
    "        return 0, 0.0\n",
    "    flags = [frame_has_face_haar(f, min_face_width_frac=min_face_width_frac) for f in frames]\n",
    "    n_face = int(np.sum(flags))\n",
    "    dens = float(n_face / len(frames))\n",
    "    return n_face, dens\n",
    "\n",
    "def compute_face_density_for_video(video_path: str, max_frames: int = 16, min_face_width_frac: float = 0.06):\n",
    "    frames = sample_uniform_frames(video_path, max_frames=max_frames)  # uses your existing sampler\n",
    "    n = len(frames)\n",
    "    if n == 0:\n",
    "        return {\"n_frames_used\": 0, \"n_face_frames\": 0, \"face_frame_density\": 0.0, \"face_density_0_10\": 0.0}\n",
    "\n",
    "    n_face, dens = compute_face_density_for_frames(frames, min_face_width_frac=min_face_width_frac)\n",
    "    return {\n",
    "        \"n_frames_used\": int(n),\n",
    "        \"n_face_frames\": int(n_face),\n",
    "        \"face_frame_density\": float(dens),\n",
    "        \"face_density_0_10\": round(float(np.clip(dens, 0.0, 1.0) * 10.0), 2),\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# LOCAL CACHE SCAN\n",
    "# ----------------------------\n",
    "def list_cached_videos_for_creator(cache_root: str, creator: str, max_items: int = 10):\n",
    "    creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "    root = Path(cache_root)\n",
    "\n",
    "    cand = []\n",
    "    # 1) reels_cache/<creator>/**/*\n",
    "    p1 = root / creator_norm\n",
    "    if p1.exists():\n",
    "        cand += [p for p in p1.rglob(\"*\") if p.is_file() and p.suffix.lower() in VIDEO_EXTS and p.stat().st_size > 0]\n",
    "\n",
    "    # 2) reels_cache/**/*<creator>*/*.*\n",
    "    if root.exists():\n",
    "        cand += [\n",
    "            p for p in root.rglob(\"*\")\n",
    "            if p.is_file()\n",
    "            and p.suffix.lower() in VIDEO_EXTS\n",
    "            and p.stat().st_size > 0\n",
    "            and (creator_norm in str(p.parent).lower() or creator_norm in str(p).lower())\n",
    "        ]\n",
    "\n",
    "    # dedupe + sort newest first\n",
    "    cand = list({str(p): p for p in cand}.values())\n",
    "    cand = sorted(cand, key=lambda p: p.stat().st_mtime, reverse=True)[:max_items]\n",
    "    return cand\n",
    "\n",
    "def run_face_density_pipeline_for_creators_local(\n",
    "    creator_list,\n",
    "    cache_dir: str = \"reels_cache\",\n",
    "    max_reels_per_creator: int = 5,\n",
    "    max_frames_per_reel: int = 16,\n",
    "    min_face_width_frac: float = 0.06,\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for creator in creator_list:\n",
    "        creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "        vids = list_cached_videos_for_creator(cache_dir, creator, max_items=max_reels_per_creator)\n",
    "\n",
    "        print(f\"\\n=== Face-density (LOCAL ONLY): {creator_norm} ===\")\n",
    "        print(f\"Found {len(vids)} cached videos in {cache_dir}\")\n",
    "\n",
    "        for i, p in enumerate(vids):\n",
    "            video_path = str(p)\n",
    "            print(f\"  ‚ñ∂ {i}: {video_path}\")\n",
    "\n",
    "            metrics = compute_face_density_for_video(\n",
    "                video_path,\n",
    "                max_frames=max_frames_per_reel,\n",
    "                min_face_width_frac=min_face_width_frac,\n",
    "            )\n",
    "\n",
    "            rows.append({\n",
    "                \"creator\": creator_norm,\n",
    "                \"reel_idx\": i,\n",
    "                \"video_path\": video_path,\n",
    "                **metrics,\n",
    "            })\n",
    "\n",
    "    df_reels_face = pd.DataFrame(rows)\n",
    "\n",
    "    if not df_reels_face.empty:\n",
    "        df_creator_face = (\n",
    "            df_reels_face\n",
    "            .groupby(\"creator\", as_index=False)\n",
    "            .agg(\n",
    "                n_reels=(\"reel_idx\", \"count\"),\n",
    "                mean_face_density=(\"face_frame_density\", \"mean\"),\n",
    "                mean_face_density_0_10=(\"face_density_0_10\", \"mean\"),\n",
    "            )\n",
    "        )\n",
    "        df_creator_face[\"creator_norm\"] = df_creator_face[\"creator\"]\n",
    "    else:\n",
    "        df_creator_face = pd.DataFrame(columns=[\n",
    "            \"creator\", \"n_reels\", \"mean_face_density\", \"mean_face_density_0_10\", \"creator_norm\"\n",
    "        ])\n",
    "\n",
    "    return df_reels_face, df_creator_face\n",
    "\n",
    "# ----------------------------\n",
    "# RUN (change cache_dir to your actual folder name)\n",
    "# ----------------------------\n",
    "df_reels_face, df_creator_face = run_face_density_pipeline_for_creators_local(\n",
    "    CREATOR_LIST,\n",
    "    cache_dir=\"reel_cache\",  # <-- you used this in your error; change if your folder is reels_cache\n",
    "    max_reels_per_creator=MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel=MAX_FRAMES_PER_REEL,\n",
    "    min_face_width_frac=0.06,\n",
    ")\n",
    "\n",
    "display(df_reels_face.head(10))\n",
    "display(df_creator_face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f573b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credible</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>0.838407</td>\n",
       "      <td>0.666886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relatable</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>0.752135</td>\n",
       "      <td>0.527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story_telling</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613666</td>\n",
       "      <td>0.153897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>communication</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312286</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.739604</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aspirational</td>\n",
       "      <td>mean_face_density</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.742319</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label             metric  n   pearson  spearman\n",
       "3       credible  mean_face_density  5  0.838407  0.666886\n",
       "2      relatable  mean_face_density  5  0.752135  0.527046\n",
       "5  story_telling  mean_face_density  5  0.613666  0.153897\n",
       "4  communication  mean_face_density  5  0.312286  0.100000\n",
       "0           cool  mean_face_density  5 -0.739604 -0.700000\n",
       "1   aspirational  mean_face_density  5 -0.742319 -0.700000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_norm</th>\n",
       "      <th>cool</th>\n",
       "      <th>aspirational</th>\n",
       "      <th>relatable</th>\n",
       "      <th>credible</th>\n",
       "      <th>communication</th>\n",
       "      <th>story_telling</th>\n",
       "      <th>mean_face_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.993056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.839286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creator_norm  cool  aspirational  relatable  credible  communication  \\\n",
       "0  badassbrownbeauty   3.0           3.0        7.0       9.0            9.0   \n",
       "2       museumofsoum   4.0           4.0        5.0       4.0            2.0   \n",
       "3        nevaforevaa   2.0           2.0        4.0       2.0            1.0   \n",
       "4          riapalkar   6.0           6.0        4.0       3.0            4.0   \n",
       "1      mahiekasharma   8.0           9.0        5.0       3.0            6.5   \n",
       "\n",
       "   story_telling  mean_face_density  \n",
       "0            9.0           0.993056  \n",
       "2            3.0           0.839286  \n",
       "3            1.0           0.781250  \n",
       "4            4.0           0.700000  \n",
       "1            4.0           0.637500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_train.columns = [c.strip().lower() for c in df_train.columns]\n",
    "df_train[\"creator_norm\"] = df_train[\"creator\"].astype(str).str.strip().str.lstrip(\"@\").str.lower()\n",
    "\n",
    "traits = [\"cool\", \"aspirational\", \"relatable\", \"credible\", \"communication\", \"story_telling\"]\n",
    "\n",
    "df_labels = (\n",
    "    df_train.groupby(\"creator_norm\", as_index=False)\n",
    "    .agg(**{t: (t, \"mean\") for t in traits})\n",
    ")\n",
    "\n",
    "df_m = df_labels.merge(\n",
    "    df_creator_face[[\"creator_norm\", \"mean_face_density\"]],\n",
    "    on=\"creator_norm\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "def corr(x, y):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    y = pd.to_numeric(y, errors=\"coerce\")\n",
    "    m = x.notna() & y.notna()\n",
    "    if m.sum() < 3:\n",
    "        return {\"n\": int(m.sum()), \"pearson\": np.nan, \"spearman\": np.nan}\n",
    "    return {\n",
    "        \"n\": int(m.sum()),\n",
    "        \"pearson\": float(x[m].corr(y[m], method=\"pearson\")),\n",
    "        \"spearman\": float(x[m].corr(y[m], method=\"spearman\")),\n",
    "    }\n",
    "\n",
    "out_rows = []\n",
    "for t in traits:\n",
    "    out_rows.append({\n",
    "        \"label\": t,\n",
    "        \"metric\": \"mean_face_density\",\n",
    "        **corr(df_m[t], df_m[\"mean_face_density\"])\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(out_rows).sort_values(\"pearson\", ascending=False)\n",
    "\n",
    "display(out)\n",
    "display(df_m.sort_values(\"mean_face_density\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "700320fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Normal fit on word_count: mu=43.107, sigma=50.016\n",
      "2œÉ thresholds: low<-56.926, high>143.139\n",
      "\n",
      "Top correlations (by smallest Pearson p-value):\n",
      "              metric     attribute  n  pearson_r  pearson_p  spearman_r  spearman_p\n",
      "   high_2sigma_ratio  aspirational 12   0.622368   0.030679    0.759897    0.004131\n",
      "outlier_2sigma_ratio  aspirational 12   0.622368   0.030679    0.759897    0.004131\n",
      "   high_2sigma_ratio communication 12   0.550194   0.063813    0.637756    0.025670\n",
      "outlier_2sigma_ratio communication 12   0.550194   0.063813    0.637756    0.025670\n",
      "   high_2sigma_ratio          cool 12   0.535226   0.072938    0.600134    0.039107\n",
      "outlier_2sigma_ratio          cool 12   0.535226   0.072938    0.600134    0.039107\n",
      "   high_2sigma_ratio story_telling 12   0.464869   0.127829    0.605543    0.036922\n",
      "outlier_2sigma_ratio story_telling 12   0.464869   0.127829    0.605543    0.036922\n",
      "outlier_2sigma_ratio     relatable 12   0.092279   0.775465    0.167428    0.602988\n",
      "   high_2sigma_ratio     relatable 12   0.092279   0.775465    0.167428    0.602988\n",
      "outlier_2sigma_ratio      credible 12   0.046549   0.885775    0.126724    0.694722\n",
      "   high_2sigma_ratio      credible 12   0.046549   0.885775    0.126724    0.694722\n",
      "    low_2sigma_ratio  aspirational 12        NaN        NaN         NaN         NaN\n",
      "    low_2sigma_ratio communication 12        NaN        NaN         NaN         NaN\n",
      "    low_2sigma_ratio          cool 12        NaN        NaN         NaN         NaN\n",
      "    low_2sigma_ratio      credible 12        NaN        NaN         NaN         NaN\n",
      "    low_2sigma_ratio     relatable 12        NaN        NaN         NaN         NaN\n",
      "    low_2sigma_ratio story_telling 12        NaN        NaN         NaN         NaN\n",
      "\n",
      "Pearson correlation matrix (metrics + attributes):\n",
      "                      low_2sigma_ratio  high_2sigma_ratio  outlier_2sigma_ratio      cool  aspirational  relatable  credible  communication  story_telling\n",
      "low_2sigma_ratio                   NaN                NaN                   NaN       NaN           NaN        NaN       NaN            NaN            NaN\n",
      "high_2sigma_ratio                  NaN           1.000000              1.000000  0.535226      0.622368   0.092279  0.046549       0.550194       0.464869\n",
      "outlier_2sigma_ratio               NaN           1.000000              1.000000  0.535226      0.622368   0.092279  0.046549       0.550194       0.464869\n",
      "cool                               NaN           0.535226              0.535226  1.000000      0.623163   0.328561  0.077953       0.337813       0.520326\n",
      "aspirational                       NaN           0.622368              0.622368  0.623163      1.000000   0.015890  0.187404       0.349543       0.327568\n",
      "relatable                          NaN           0.092279              0.092279  0.328561      0.015890   1.000000  0.427245       0.585042       0.584593\n",
      "credible                           NaN           0.046549              0.046549  0.077953      0.187404   0.427245  1.000000       0.681895       0.419743\n",
      "communication                      NaN           0.550194              0.550194  0.337813      0.349543   0.585042  0.681895       1.000000       0.724266\n",
      "story_telling                      NaN           0.464869              0.464869  0.520326      0.327568   0.584593  0.419743       0.724266       1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:117: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, pp = pearsonr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:118: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, sp = spearmanr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:117: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, pp = pearsonr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:118: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, sp = spearmanr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:117: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, pp = pearsonr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:118: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, sp = spearmanr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:117: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, pp = pearsonr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:118: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, sp = spearmanr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:117: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, pp = pearsonr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:118: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, sp = spearmanr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:117: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pr, pp = pearsonr(x, y)\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_27996\\2304043331.py:118: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  sr, sp = spearmanr(x, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# Global word_count distribution + creator outlier ratios\n",
    "# + correlation vs train_data.csv attributes\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def norm_creator(x: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    return str(x).strip().lstrip(\"@\").lower()\n",
    "\n",
    "# ---- Paths (edit if needed) ----\n",
    "REELS_PATH = \"my_current_data.csv\"   # your uploaded \"spreadsheet\" CSV\n",
    "TRAIN_PATH = \"train_data.csv\"        # you said you have this file\n",
    "\n",
    "# ---- 1) Load reels + fit global distribution on word_count ----\n",
    "reels = pd.read_csv(REELS_PATH)\n",
    "\n",
    "if \"creator\" not in reels.columns or \"word_count\" not in reels.columns:\n",
    "    raise ValueError(f\"Expected columns ['creator','word_count'] in {REELS_PATH}. Found: {list(reels.columns)}\")\n",
    "\n",
    "reels[\"creator_norm\"] = reels[\"creator\"].map(norm_creator)\n",
    "reels[\"word_count\"] = pd.to_numeric(reels[\"word_count\"], errors=\"coerce\")\n",
    "\n",
    "wc = reels[\"word_count\"].dropna().astype(float)\n",
    "if len(wc) < 5:\n",
    "    raise ValueError(\"Not enough non-null word_count values to fit a distribution.\")\n",
    "\n",
    "# \"Fit a global distribution\" (Normal): for Normal, MLE mu/sigma are mean/std (ddof=0)\n",
    "mu = float(wc.mean())\n",
    "sigma = float(wc.std(ddof=0))\n",
    "\n",
    "low_thr  = mu - 2.0 * sigma\n",
    "high_thr = mu + 2.0 * sigma\n",
    "# low_thr  = mu - sigma\n",
    "# high_thr = mu + sigma\n",
    "\n",
    "print(f\"Global Normal fit on word_count: mu={mu:.3f}, sigma={sigma:.3f}\")\n",
    "print(f\"2œÉ thresholds: low<{low_thr:.3f}, high>{high_thr:.3f}\")\n",
    "\n",
    "# ---- 2) Per-creator ratios on either side of ¬±2œÉ ----\n",
    "tmp = reels.dropna(subset=[\"creator_norm\"]).copy()\n",
    "tmp[\"is_low_2sigma\"]  = tmp[\"word_count\"].lt(low_thr)\n",
    "tmp[\"is_high_2sigma\"] = tmp[\"word_count\"].gt(high_thr)\n",
    "\n",
    "creator_metrics = (\n",
    "    tmp.groupby(\"creator_norm\", as_index=False)\n",
    "       .agg(\n",
    "           n_posts=(\"word_count\", \"size\"),\n",
    "           n_wc_nonnull=(\"word_count\", lambda s: int(s.notna().sum())),\n",
    "           low_2sigma_count=(\"is_low_2sigma\", \"sum\"),\n",
    "           high_2sigma_count=(\"is_high_2sigma\", \"sum\"),\n",
    "       )\n",
    ")\n",
    "\n",
    "# ratios use ONLY non-null word_count rows (so NaNs don‚Äôt dilute ratios)\n",
    "den = creator_metrics[\"n_wc_nonnull\"].replace(0, np.nan)\n",
    "creator_metrics[\"low_2sigma_ratio\"]  = creator_metrics[\"low_2sigma_count\"]  / den\n",
    "creator_metrics[\"high_2sigma_ratio\"] = creator_metrics[\"high_2sigma_count\"] / den\n",
    "creator_metrics[\"outlier_2sigma_ratio\"] = (creator_metrics[\"low_2sigma_count\"] + creator_metrics[\"high_2sigma_count\"]) / den\n",
    "\n",
    "# ---- 3) Load train_data + correlations with attributes ----\n",
    "if not os.path.exists(TRAIN_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Couldn't find {TRAIN_PATH}. Put train_data.csv at that path (or change TRAIN_PATH).\"\n",
    "    )\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "# Assume train has a creator column; try common variants\n",
    "creator_col = None\n",
    "for c in [\"creator\", \"handle\", \"username\", \"creator_handle\", \"ig_handle\"]:\n",
    "    if c in train.columns:\n",
    "        creator_col = c\n",
    "        break\n",
    "if creator_col is None:\n",
    "    raise ValueError(f\"train_data.csv must have a creator identifier column. Found: {list(train.columns)}\")\n",
    "\n",
    "train[\"creator_norm\"] = train[creator_col].map(norm_creator)\n",
    "\n",
    "# Merge creator-level metrics into train\n",
    "merged = train.merge(creator_metrics, on=\"creator_norm\", how=\"left\")\n",
    "\n",
    "# Pick attribute columns that exist (assume these may be present)\n",
    "candidate_attrs = [\n",
    "    \"cool\", \"aspirational\", \"relatable\", \"credible\",\n",
    "    \"communication\", \"story_telling\", \"storytelling\"\n",
    "]\n",
    "attr_cols = [c for c in candidate_attrs if c in merged.columns]\n",
    "\n",
    "if not attr_cols:\n",
    "    raise ValueError(\n",
    "        f\"None of the expected attribute columns found in train_data.csv. \"\n",
    "        f\"Expected one of: {candidate_attrs}. Found: {list(merged.columns)}\"\n",
    "    )\n",
    "\n",
    "metric_cols = [\"low_2sigma_ratio\", \"high_2sigma_ratio\", \"outlier_2sigma_ratio\"]\n",
    "\n",
    "# Helper: compute Pearson + Spearman (with p-values)\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "rows = []\n",
    "for metric in metric_cols:\n",
    "    for attr in attr_cols:\n",
    "        sub = merged[[metric, attr]].dropna()\n",
    "        if len(sub) < 3:\n",
    "            continue\n",
    "        x = sub[metric].astype(float).values\n",
    "        y = pd.to_numeric(sub[attr], errors=\"coerce\").astype(float).values\n",
    "        mask = np.isfinite(x) & np.isfinite(y)\n",
    "        x, y = x[mask], y[mask]\n",
    "        if len(x) < 3:\n",
    "            continue\n",
    "\n",
    "        pr, pp = pearsonr(x, y)\n",
    "        sr, sp = spearmanr(x, y)\n",
    "\n",
    "        rows.append({\n",
    "            \"metric\": metric,\n",
    "            \"attribute\": attr,\n",
    "            \"n\": int(len(x)),\n",
    "            \"pearson_r\": float(pr),\n",
    "            \"pearson_p\": float(pp),\n",
    "            \"spearman_r\": float(sr),\n",
    "            \"spearman_p\": float(sp),\n",
    "        })\n",
    "\n",
    "corr_df = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"attribute\", \"metric\", \"pearson_p\"], ascending=[True, True, True]\n",
    ")\n",
    "\n",
    "print(\"\\nTop correlations (by smallest Pearson p-value):\")\n",
    "print(corr_df.sort_values(\"pearson_p\").head(20).to_string(index=False))\n",
    "\n",
    "# # Optional: save outputs\n",
    "# creator_metrics.to_csv(\"/mnt/data/creator_wordcount_outlier_metrics.csv\", index=False)\n",
    "# corr_df.to_csv(\"/mnt/data/wordcount_outlier_correlations.csv\", index=False)\n",
    "# print(\"\\nSaved:\")\n",
    "# print(\" - /mnt/data/creator_wordcount_outlier_metrics.csv\")\n",
    "# print(\" - /mnt/data/wordcount_outlier_correlations.csv\")\n",
    "\n",
    "# Optional: quick correlation matrix (Pearson) for the merged table\n",
    "# (only numeric columns among metrics + attributes)\n",
    "numeric_cols = metric_cols + attr_cols\n",
    "corr_mat = merged[numeric_cols].apply(pd.to_numeric, errors=\"coerce\").corr(method=\"pearson\")\n",
    "print(\"\\nPearson correlation matrix (metrics + attributes):\")\n",
    "print(corr_mat.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GEMINI MODULE ‚Äî call_gemini_for_reel\n",
    "# Target: per-reel `gemini_raw` (JSON string with numeric features)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "from typing import List, Optional\n",
    "\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ENV + CLIENT SETUP (matching notebook pattern)\n",
    "# -------------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"Missing GEMINI_API_KEY (set it in .env or env vars)\")\n",
    "\n",
    "# Use the same style of model name as in the notebook\n",
    "GEMINI_MODEL_NAME = \"models/gemini-2.0-flash-001\"\n",
    "\n",
    "_gemini_client: Optional[genai.Client] = None\n",
    "\n",
    "\n",
    "def get_gemini_client() -> genai.Client:\n",
    "    \"\"\"Singleton-style client initialisation (same pattern as notebook).\"\"\"\n",
    "    global _gemini_client\n",
    "    if _gemini_client is None:\n",
    "        _gemini_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "    return _gemini_client\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Prompt template (aligned with how you want gemini_raw to look)\n",
    "# -------------------------------------------------------------------------\n",
    "GEMINI_PROMPT_TEMPLATE = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    You are helping a beauty and personal-care brand evaluate Instagram creators\n",
    "    for potential collaborations.\n",
    "\n",
    "    You will receive ONLY text data for ONE reel in this format:\n",
    "\n",
    "    INSTAGRAM REEL TEXT DATA\n",
    "\n",
    "    --- CAPTION ---\n",
    "    {caption}\n",
    "\n",
    "    --- TRANSCRIPT (ASR) ---\n",
    "    {transcript}\n",
    "\n",
    "    --- COMMENTS (if any) ---\n",
    "    {comments_block}\n",
    "\n",
    "    Language may be English, Hinglish (Hindi in Latin script), or a mix.\n",
    "\n",
    "    Your job is to analyse this reel and return ONLY a compact JSON summary with\n",
    "    the following fields. Do NOT repeat the caption, transcript, or comments in\n",
    "    your output. Do NOT add extra text or explanations.\n",
    "\n",
    "    For each reel, infer:\n",
    "\n",
    "    1) genz_word_count (integer)\n",
    "       - Count how many Gen Z / internet slang terms are used in the TRANSCRIPT. \n",
    "       - The spellings in transcript may vary.\n",
    "       - Examples: \"lit\", \"low-key\", \"high-key\", \"slay\", \"vibe\", \"aesthetic\",\n",
    "         \"fr\", \"no cap\", \"cap\", \"on fleek\", \"serving\", \"ate\", \"mood\", \"delulu\",\n",
    "         \"rizz\", \"iykyk\", \"brooo\", \"lol\", \"lmao\", etc.\n",
    "       - Count total occurrences (if \"slay\" appears 3 times, that is 3).\n",
    "\n",
    "    2) is_marketing (0 or 1)\n",
    "       - 1 if the reel is doing ANY kind of marketing or promotion of beauty /\n",
    "         personal-care products, brands, or routines.\n",
    "       - This includes sponsored content, product mentions, recommendations,\n",
    "         discount codes, affiliate links, \"shop now\", \"use my code\", etc.\n",
    "       - Else 0.\n",
    "\n",
    "    3) is_educational (0 or 1)\n",
    "       - 1 if the reel is primarily educational or informative (beauty/hair/skin\n",
    "         tips, how-to steps, ingredient explanations, routines, \"do this / don't\n",
    "         do this\").\n",
    "       - Else 0.\n",
    "\n",
    "    4) is_vlog (0 or 1)\n",
    "       - 1 if the reel is a vlog-style snippet of the creator's life (day in the\n",
    "         life, GRWM, routine, \"come with me\", events narrated in first person).\n",
    "       - Else 0.\n",
    "\n",
    "    5) has_humour (0 or 1)\n",
    "       - Look at both TRANSCRIPT and COMMENTS.\n",
    "       - 1 if there is clear humour or playful/comedic tone, or comments react\n",
    "         with laughter (üòÇ, ü§£, \"I'm dead\", \"too funny\", etc.).\n",
    "       - Else 0.\n",
    "\n",
    "    6) comment_sentiment_counts (object)\n",
    "       - For each TOP COMMENT, classify it into exactly ONE of these buckets:\n",
    "         - \"questioning\"   ‚Üí asking questions, clarifications, doubts\n",
    "         - \"agreeing\"      ‚Üí agreeing or saying \"same\", \"relatable\", \"me too\"\n",
    "         - \"appreciating\"  ‚Üí compliments, praise, admiration\n",
    "         - \"negative\"      ‚Üí criticism, dislike, disagreement\n",
    "         - \"neutral\"       ‚Üí factual/unclear/irrelevant/any other not fitting above\n",
    "       - Then return only the aggregate counts of how many comments fall into each\n",
    "         bucket.\n",
    "\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    OUTPUT FORMAT (STRICT)\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    Return your answer as VALID JSON inside <res> ... </res> and nothing else.\n",
    "\n",
    "    <res>\n",
    "    {{\n",
    "      \"genz_word_count\": INTEGER,\n",
    "      \"is_marketing\": 0,\n",
    "      \"is_educational\": 0,\n",
    "      \"is_vlog\": 0,\n",
    "      \"has_humour\": 0,\n",
    "      \"comment_sentiment_counts\": {{\n",
    "        \"questioning\": INTEGER,\n",
    "        \"agreeing\": INTEGER,\n",
    "        \"appreciating\": INTEGER,\n",
    "        \"negative\": INTEGER,\n",
    "        \"neutral\": INTEGER\n",
    "      }}\n",
    "    }}\n",
    "    </res>\n",
    "\n",
    "    Rules:\n",
    "    - Do NOT include reasons, explanations, or any extra fields.\n",
    "    - Do NOT repeat or summarise the caption, transcript, or comments.\n",
    "    - Always fill every field with an integer (for counts) or 0/1 for binary flags.\n",
    "    \"\"\"\n",
    ").strip()\n",
    "\n",
    "\n",
    "\n",
    "def _build_gemini_prompt(caption: str, transcript: str, comments: List[str]) -> str:\n",
    "    \"\"\"Format the prompt with caption / transcript / comments.\"\"\"\n",
    "    caption = caption or \"\"\n",
    "    transcript = transcript or \"\"\n",
    "\n",
    "    # ‚îÄ‚îÄ NORMALISE COMMENTS TO A SIMPLE LIST OF STRINGS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # comments can be:\n",
    "    # - None\n",
    "    # - Python list/tuple of strings\n",
    "    # - numpy array / pandas Series\n",
    "    # - a single string\n",
    "    if comments is None:\n",
    "        comments_list = []\n",
    "    elif isinstance(comments, (list, tuple)):\n",
    "        comments_list = list(comments)\n",
    "    elif hasattr(comments, \"tolist\"):  # e.g. numpy array, pandas Series\n",
    "        comments_list = comments.tolist()\n",
    "    else:\n",
    "        # single scalar (string or something else) ‚Üí wrap in a list\n",
    "        comments_list = [comments]\n",
    "\n",
    "    # Ensure everything is a stripped string and non-empty\n",
    "    cleaned_comments = []\n",
    "    for c in comments_list:\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if s:\n",
    "            cleaned_comments.append(s)\n",
    "\n",
    "    if cleaned_comments:\n",
    "        comments_block = \"\\n\".join(f\"- {c}\" for c in cleaned_comments[:20])\n",
    "    else:\n",
    "        comments_block = \"None\"\n",
    "\n",
    "    return GEMINI_PROMPT_TEMPLATE.format(\n",
    "        caption=caption,\n",
    "        transcript=transcript,\n",
    "        comments_block=comments_block,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _extract_json_object(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Try to extract a JSON object substring from the model output.\n",
    "    Returns the substring if it parses as JSON, else raises ValueError.\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    # Fast path: whole string is JSON\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return text\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try to find first '{' and last '}' and parse that substring\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        raise ValueError(\"No JSON object found in Gemini output.\")\n",
    "\n",
    "    candidate = text[start : end + 1]\n",
    "    json.loads(candidate)  # will raise if invalid\n",
    "    return candidate\n",
    "\n",
    "\n",
    "def call_gemini_for_reel(\n",
    "    caption: str,\n",
    "    transcript: str,\n",
    "    comments: List[str],\n",
    "    temperature: float = 0.1,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call Gemini on a single reel's text information and return a JSON string.\n",
    "\n",
    "    Inputs:\n",
    "        caption    - reel caption (string, can be empty)\n",
    "        transcript - Whisper transcript (string, can be empty)\n",
    "        comments   - list of comment strings (can be empty)\n",
    "\n",
    "    Output:\n",
    "        gemini_raw (str): a JSON string representing a dict of numeric features.\n",
    "                          This is what you store in your dataframe column 'gemini_raw'.\n",
    "    \"\"\"\n",
    "    prompt = _build_gemini_prompt(caption, transcript, comments)\n",
    "    client = get_gemini_client()\n",
    "\n",
    "    try:\n",
    "        resp = client.models.generate_content(\n",
    "            model=GEMINI_MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config={\"temperature\": temperature},\n",
    "        )\n",
    "        # New google-genai client: text is on resp.text\n",
    "        raw_text = (getattr(resp, \"text\", None) or \"\").strip()\n",
    "        if not raw_text:\n",
    "            print(\"    ‚úó Gemini returned empty text\")\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Gemini API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Try to extract a valid JSON object from the output\n",
    "    try:\n",
    "        json_str = _extract_json_object(raw_text)\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Could not extract JSON from Gemini output: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Final validation: ensure it loads and values are numeric\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Gemini JSON is not an object.\")\n",
    "        # Coerce numeric-looking strings into numbers\n",
    "        for k, v in list(data.items()):\n",
    "            if isinstance(v, str):\n",
    "                try:\n",
    "                    if \".\" in v:\n",
    "                        data[k] = float(v)\n",
    "                    else:\n",
    "                        data[k] = int(v)\n",
    "                except Exception:\n",
    "                    # leave non-numeric strings as-is; they'll be ignored with numeric_only=True\n",
    "                    pass\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Gemini JSON validation failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Return the cleaned JSON string\n",
    "    return json.dumps(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7969c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model: medium ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# 2) WHISPER TRANSCRIPTION (in-memory + disk cache)\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading Whisper model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWHISPER_MODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m _whisper_model = \u001b[43mwhisper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWHISPER_MODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWhisper model loaded.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m _transcript_cache: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\whisper\\__init__.py:137\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, device, download_root, in_memory)\u001b[39m\n\u001b[32m    134\u001b[39m     download_root = os.path.join(os.getenv(\u001b[33m\"\u001b[39m\u001b[33mXDG_CACHE_HOME\u001b[39m\u001b[33m\"\u001b[39m, default), \u001b[33m\"\u001b[39m\u001b[33mwhisper\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     checkpoint_file = \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     alignment_heads = _ALIGNMENT_HEADS[name]\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.isfile(name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\whisper\\__init__.py:66\u001b[39m, in \u001b[36m_download\u001b[39m\u001b[34m(url, root, in_memory)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(download_target, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     65\u001b[39m     model_bytes = f.read()\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhashlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43msha256\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_bytes\u001b[49m\u001b[43m)\u001b[49m.hexdigest() == expected_sha256:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_bytes \u001b[38;5;28;01mif\u001b[39;00m in_memory \u001b[38;5;28;01melse\u001b[39;00m download_target\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FULL LOCAL-ONLY PIPELINE: cached reels -> change metrics + whisper + gemini\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "CACHE_DIR = \"reel_cache\"          # <-- your cache folder root\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\", \".mkv\", \".webm\"}\n",
    "\n",
    "WHISPER_MODEL_NAME = \"medium\"      # \"tiny\" | \"base\" | \"small\" | \"medium\" | \"large\"\n",
    "WHISPER_LANGUAGE = None            # set \"en\" if you want force English; else None = auto\n",
    "MAX_TRANSCRIPT_CHARS = 12000       # keep prompt manageable\n",
    "\n",
    "# =============================================================================\n",
    "# 1) LOCAL CACHE DISCOVERY\n",
    "# =============================================================================\n",
    "\n",
    "def list_cached_videos_for_creator(cache_root: str, creator: str, max_items: int = 10):\n",
    "    \"\"\"\n",
    "    Local-only: find cached videos for creator under cache_root.\n",
    "    Supports common layouts:\n",
    "      - reels_cache/<creator>/**/*.mp4\n",
    "      - reels_cache/**/*<creator>*/*.mp4   (e.g. reels_cache/change3_<creator>/0.mp4)\n",
    "    Returns list[Path], newest first.\n",
    "    \"\"\"\n",
    "    creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "    root = Path(cache_root)\n",
    "\n",
    "    cand = []\n",
    "\n",
    "    # Layout 1: cache_root/<creator>/**\n",
    "    p1 = root / creator_norm\n",
    "    if p1.exists():\n",
    "        cand += [p for p in p1.rglob(\"*\")\n",
    "                 if p.is_file() and p.suffix.lower() in VIDEO_EXTS and p.stat().st_size > 0]\n",
    "\n",
    "    # Layout 2: anywhere containing creator in path\n",
    "    if root.exists():\n",
    "        cand += [\n",
    "            p for p in root.rglob(\"*\")\n",
    "            if p.is_file()\n",
    "            and p.suffix.lower() in VIDEO_EXTS\n",
    "            and p.stat().st_size > 0\n",
    "            and (creator_norm in str(p.parent).lower() or creator_norm in str(p).lower())\n",
    "        ]\n",
    "\n",
    "    # Dedup + newest first\n",
    "    cand = list({str(p): p for p in cand}.values())\n",
    "    cand = sorted(cand, key=lambda p: p.stat().st_mtime, reverse=True)[:max_items]\n",
    "    return cand\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) WHISPER TRANSCRIPTION (in-memory + disk cache)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Loading Whisper model: {WHISPER_MODEL_NAME} ...\")\n",
    "_whisper_model = whisper.load_model(WHISPER_MODEL_NAME)\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "_transcript_cache: dict[str, str] = {}\n",
    "\n",
    "def transcript_cache_path(video_path: str) -> str:\n",
    "    # store next to mp4\n",
    "    vp = Path(video_path)\n",
    "    return str(vp.with_suffix(vp.suffix + \".whisper.txt\"))\n",
    "\n",
    "def load_transcript_cache(video_path: str) -> str:\n",
    "    p = transcript_cache_path(video_path)\n",
    "    if os.path.exists(p) and os.path.getsize(p) > 0:\n",
    "        try:\n",
    "            return Path(p).read_text(encoding=\"utf-8\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    return \"\"\n",
    "\n",
    "def save_transcript_cache(video_path: str, text: str):\n",
    "    p = transcript_cache_path(video_path)\n",
    "    try:\n",
    "        Path(p).parent.mkdir(parents=True, exist_ok=True)\n",
    "        Path(p).write_text(text or \"\", encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Could not write transcript cache: {e}\")\n",
    "\n",
    "def transcribe_reel(video_path: str, reel_url: str | None = None, force: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Shared transcript helper.\n",
    "\n",
    "    - Takes local `video_path` (already cached).\n",
    "    - Optional `reel_url` is only used as a cache key.\n",
    "    - Returns a plain text transcript (\"\" on failure).\n",
    "    \"\"\"\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    ‚úó Video file not found for transcription:\", video_path)\n",
    "        return \"\"\n",
    "\n",
    "    cache_key = reel_url or video_path\n",
    "\n",
    "    # in-memory cache\n",
    "    if not force and cache_key in _transcript_cache:\n",
    "        return _transcript_cache[cache_key]\n",
    "\n",
    "    # disk cache\n",
    "    if not force:\n",
    "        disk = load_transcript_cache(video_path)\n",
    "        if disk:\n",
    "            _transcript_cache[cache_key] = disk\n",
    "            return disk\n",
    "\n",
    "    try:\n",
    "        print(\"    üéô Transcribing audio with Whisper ...\")\n",
    "        use_fp16 = torch.cuda.is_available()\n",
    "        result = _whisper_model.transcribe(\n",
    "            video_path,\n",
    "            fp16=use_fp16,\n",
    "            language=WHISPER_LANGUAGE,\n",
    "        )\n",
    "        text = (result.get(\"text\") or \"\").strip()\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Whisper transcription failed: {e}\")\n",
    "        text = \"\"\n",
    "\n",
    "    # truncate for prompt safety\n",
    "    if len(text) > MAX_TRANSCRIPT_CHARS:\n",
    "        text = text[:MAX_TRANSCRIPT_CHARS] + \" ...\"\n",
    "\n",
    "    _transcript_cache[cache_key] = text\n",
    "    save_transcript_cache(video_path, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) GEMINI CACHE (disk)\n",
    "# =============================================================================\n",
    "\n",
    "def gemini_cache_path_for_video(video_path: str) -> str:\n",
    "    # store next to mp4\n",
    "    vp = Path(video_path)\n",
    "    return str(vp.with_suffix(vp.suffix + \".gemini.json\"))\n",
    "\n",
    "def load_gemini_cache(video_path: str) -> str:\n",
    "    p = gemini_cache_path_for_video(video_path)\n",
    "    if os.path.exists(p) and os.path.getsize(p) > 0:\n",
    "        try:\n",
    "            return Path(p).read_text(encoding=\"utf-8\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    return \"\"\n",
    "\n",
    "def save_gemini_cache(video_path: str, gemini_raw: str):\n",
    "    p = gemini_cache_path_for_video(video_path)\n",
    "    try:\n",
    "        Path(p).parent.mkdir(parents=True, exist_ok=True)\n",
    "        Path(p).write_text(gemini_raw or \"\", encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Could not write Gemini cache: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) MAIN LOCAL-ONLY PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def run_local_cached_pipeline_for_creators(\n",
    "    creator_list,\n",
    "    cache_dir: str = CACHE_DIR,\n",
    "    max_reels_per_creator: int = 5,\n",
    "    max_frames_per_reel: int = 16,\n",
    "    run_whisper: bool = True,\n",
    "    force_whisper: bool = False,\n",
    "    run_gemini: bool = True,\n",
    "    force_gemini: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Local-only: NO Apify, NO downloads.\n",
    "    For each cached video:\n",
    "      - compute change metrics\n",
    "      - (optional) whisper transcript\n",
    "      - (optional) gemini features\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for creator in creator_list:\n",
    "        creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "        vids = list_cached_videos_for_creator(cache_dir, creator_norm, max_items=max_reels_per_creator)\n",
    "\n",
    "        print(f\"\\n=== LOCAL PIPELINE: {creator_norm} ===\")\n",
    "        print(f\"Found {len(vids)} cached videos under {cache_dir}\")\n",
    "\n",
    "        if not vids:\n",
    "            continue\n",
    "\n",
    "        for i, p in enumerate(vids):\n",
    "            video_path = str(p)\n",
    "            reel_url = None     # unknown in local-only mode\n",
    "            caption = \"\"        # optional: load from your own manifest if you have it\n",
    "            comments = []       # optional: load from manifest\n",
    "\n",
    "            print(f\"\\n  ‚ñ∂ Reel {i}: {video_path}\")\n",
    "\n",
    "            # --- change metrics ---\n",
    "            try:\n",
    "                change_metrics = compute_three_change_metrics_for_video(\n",
    "                    video_path,\n",
    "                    max_frames=max_frames_per_reel\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚úó Change metric failed: {e}\")\n",
    "                change_metrics = {\n",
    "                    \"n_frames_used\": 0,\n",
    "                    \"scene_change_count\": 0,\n",
    "                    \"scene_change_density\": 0.0,\n",
    "                    \"scene_score_0_10\": 0.0,\n",
    "                    \"mean_clip_dist\": 0.0,\n",
    "                    \"std_clip_dist\": 0.0,\n",
    "                    \"clip_score_0_10\": 0.0,\n",
    "                    \"mean_hist_dist\": 0.0,\n",
    "                    \"std_hist_dist\": 0.0,\n",
    "                    \"hist_score_0_10\": 0.0,\n",
    "                }\n",
    "\n",
    "            # --- transcript ---\n",
    "            transcript = \"\"\n",
    "            if run_whisper:\n",
    "                transcript = transcribe_reel(video_path, reel_url=reel_url, force=force_whisper)\n",
    "\n",
    "            # --- gemini ---\n",
    "            gemini_raw = \"\"\n",
    "            if run_gemini:\n",
    "                if not force_gemini:\n",
    "                    gemini_raw = load_gemini_cache(video_path)\n",
    "\n",
    "                if gemini_raw:\n",
    "                    print(\"    ‚úÖ Gemini cache hit\")\n",
    "                else:\n",
    "                    print(\"    ü§ñ Calling Gemini ...\")\n",
    "                    gemini_raw = call_gemini_for_reel(\n",
    "                        caption=caption,\n",
    "                        transcript=transcript,\n",
    "                        comments=comments,\n",
    "                        temperature=0.1,\n",
    "                    )\n",
    "                    save_gemini_cache(video_path, gemini_raw)\n",
    "                    print(\"    üíæ Saved Gemini cache\")\n",
    "\n",
    "            row = {\n",
    "                \"creator\": creator_norm,\n",
    "                \"reel_idx\": i,\n",
    "                \"reel_url\": reel_url,\n",
    "                \"caption\": caption,\n",
    "                \"video_path\": video_path,\n",
    "                \"transcript\": transcript,\n",
    "                \"gemini_raw\": gemini_raw,\n",
    "            }\n",
    "            row.update(change_metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    df_reels_all = pd.DataFrame(rows)\n",
    "\n",
    "    # per-creator aggregation\n",
    "    if not df_reels_all.empty:\n",
    "        df_creator_all = (\n",
    "            df_reels_all\n",
    "            .groupby(\"creator\", as_index=False)\n",
    "            .agg(\n",
    "                n_reels=(\"reel_idx\", \"count\"),\n",
    "                mean_scene_score=(\"scene_score_0_10\", \"mean\"),\n",
    "                mean_clip_score=(\"clip_score_0_10\", \"mean\"),\n",
    "                mean_hist_score=(\"hist_score_0_10\", \"mean\"),\n",
    "                max_scene_score=(\"scene_score_0_10\", \"max\"),\n",
    "                max_clip_score=(\"clip_score_0_10\", \"max\"),\n",
    "                max_hist_score=(\"hist_score_0_10\", \"max\"),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df_creator_all = pd.DataFrame()\n",
    "\n",
    "    return df_reels_all, df_creator_all\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) RUN\n",
    "# =============================================================================\n",
    "\n",
    "df_reels_all, df_creator_all = run_local_cached_pipeline_for_creators(\n",
    "    CREATOR_LIST,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    max_reels_per_creator=MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel=MAX_FRAMES_PER_REEL,\n",
    "    run_whisper=True,\n",
    "    run_gemini=True,\n",
    "    force_whisper=False,\n",
    "    force_gemini=False,\n",
    ")\n",
    "\n",
    "display(df_reels_all.head(10))\n",
    "display(df_creator_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5c582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model: medium ...\n",
      "Whisper model loaded.\n",
      "\n",
      "=== LOCAL PIPELINE: badassbrownbeauty ===\n",
      "Found 5 cached videos under reel_cache\n",
      "\n",
      "  ‚ñ∂ Reel 0: reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 1: reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 2: reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 3: reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 4: reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "=== LOCAL PIPELINE: museumofsoum ===\n",
      "Found 5 cached videos under reel_cache\n",
      "\n",
      "  ‚ñ∂ Reel 0: reel_cache\\museumofsoum\\DPbcj8rjONK.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 1: reel_cache\\museumofsoum\\C_5FVUuql9u.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 2: reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 3: reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "  ‚ñ∂ Reel 4: reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    ‚úÖ Gemini cache hit\n",
      "\n",
      "=== LOCAL PIPELINE: mahiekasharma ===\n",
      "Found 5 cached videos under reel_cache\n",
      "\n",
      "  ‚ñ∂ Reel 0: reel_cache\\mahiekasharma\\DQlkrImE020.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 1: reel_cache\\mahiekasharma\\DOgeVxXjOQy.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 2: reel_cache\\mahiekasharma\\DSNXxr0DEGR.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 3: reel_cache\\mahiekasharma\\DOeSaKTgOKR.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 4: reel_cache\\mahiekasharma\\DPIMMk6iAH9.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "=== LOCAL PIPELINE: riapalkar ===\n",
      "Found 5 cached videos under reel_cache\n",
      "\n",
      "  ‚ñ∂ Reel 0: reel_cache\\riapalkar\\DSHk9xHDHbZ.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 1: reel_cache\\riapalkar\\DJt0fUlN2i9.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 2: reel_cache\\riapalkar\\DSCJUmeDPdk.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 3: reel_cache\\riapalkar\\DRhC6QwjAdi.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 4: reel_cache\\riapalkar\\DR9GraGDLmM.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "=== LOCAL PIPELINE: nevaforevaa ===\n",
      "Found 5 cached videos under reel_cache\n",
      "\n",
      "  ‚ñ∂ Reel 0: reel_cache\\nevaforevaa\\DOleu4Uj3tA.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 1: reel_cache\\nevaforevaa\\DSKEKfgjzXK.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 2: reel_cache\\nevaforevaa\\DNn5ibjoCeJ.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 3: reel_cache\\nevaforevaa\\DRY52TBj8A1.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n",
      "\n",
      "  ‚ñ∂ Reel 4: reel_cache\\nevaforevaa\\DJZPHsTP44X.mp4\n",
      "    ‚úó Change metric failed: name 'compute_three_change_metrics_for_video' is not defined\n",
      "    üéô Transcribing audio with Whisper ...\n",
      "    ü§ñ Calling Gemini ...\n",
      "    üíæ Saved Gemini cache\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>reel_idx</th>\n",
       "      <th>reel_url</th>\n",
       "      <th>caption</th>\n",
       "      <th>video_path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>gemini_raw</th>\n",
       "      <th>n_frames_used</th>\n",
       "      <th>scene_change_count</th>\n",
       "      <th>scene_change_density</th>\n",
       "      <th>scene_score_0_10</th>\n",
       "      <th>mean_clip_dist</th>\n",
       "      <th>std_clip_dist</th>\n",
       "      <th>clip_score_0_10</th>\n",
       "      <th>mean_hist_dist</th>\n",
       "      <th>std_hist_dist</th>\n",
       "      <th>hist_score_0_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4</td>\n",
       "      <td>Imagine this being the vibe every time you tak...</td>\n",
       "      <td>{\"genz_word_count\": 1, \"is_marketing\": 1, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4</td>\n",
       "      <td>I'm just gonna come out and say it, I think th...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4</td>\n",
       "      <td>If you're as obsessed as I am with beautiful g...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4</td>\n",
       "      <td>Here's everything I bought from the NYCA Pink ...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4</td>\n",
       "      <td>I'm just gonna come out and say it, I think th...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\museumofsoum\\DPbcj8rjONK.mp4</td>\n",
       "      <td></td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\museumofsoum\\C_5FVUuql9u.mp4</td>\n",
       "      <td>[(The Andy Dre Ver.)</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4</td>\n",
       "      <td></td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4</td>\n",
       "      <td>Thanks for watching!</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4</td>\n",
       "      <td>Words don't affect me that much. I told you, C...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  reel_idx reel_url caption  \\\n",
       "0  badassbrownbeauty         0     None           \n",
       "1  badassbrownbeauty         1     None           \n",
       "2  badassbrownbeauty         2     None           \n",
       "3  badassbrownbeauty         3     None           \n",
       "4  badassbrownbeauty         4     None           \n",
       "5       museumofsoum         0     None           \n",
       "6       museumofsoum         1     None           \n",
       "7       museumofsoum         2     None           \n",
       "8       museumofsoum         3     None           \n",
       "9       museumofsoum         4     None           \n",
       "\n",
       "                                     video_path  \\\n",
       "0  reel_cache\\badassbrownbeauty\\DR9Y07wkX8b.mp4   \n",
       "1  reel_cache\\badassbrownbeauty\\DRo-zZAEf55.mp4   \n",
       "2  reel_cache\\badassbrownbeauty\\DR4oT2ijOhC.mp4   \n",
       "3  reel_cache\\badassbrownbeauty\\DRxArMLDBOa.mp4   \n",
       "4  reel_cache\\badassbrownbeauty\\DRo_FVpEWjD.mp4   \n",
       "5       reel_cache\\museumofsoum\\DPbcj8rjONK.mp4   \n",
       "6       reel_cache\\museumofsoum\\C_5FVUuql9u.mp4   \n",
       "7       reel_cache\\museumofsoum\\DOOlRBMk3Rj.mp4   \n",
       "8       reel_cache\\museumofsoum\\DPyJR1jkx3i.mp4   \n",
       "9       reel_cache\\museumofsoum\\DPbb36Ok0zb.mp4   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  Imagine this being the vibe every time you tak...   \n",
       "1  I'm just gonna come out and say it, I think th...   \n",
       "2  If you're as obsessed as I am with beautiful g...   \n",
       "3  Here's everything I bought from the NYCA Pink ...   \n",
       "4  I'm just gonna come out and say it, I think th...   \n",
       "5                                                      \n",
       "6                               [(The Andy Dre Ver.)   \n",
       "7                                                      \n",
       "8                               Thanks for watching!   \n",
       "9  Words don't affect me that much. I told you, C...   \n",
       "\n",
       "                                          gemini_raw  n_frames_used  \\\n",
       "0  {\"genz_word_count\": 1, \"is_marketing\": 1, \"is_...              0   \n",
       "1  {\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...              0   \n",
       "2  {\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...              0   \n",
       "3  {\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...              0   \n",
       "4  {\"genz_word_count\": 0, \"is_marketing\": 1, \"is_...              0   \n",
       "5  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...              0   \n",
       "6  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...              0   \n",
       "7  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...              0   \n",
       "8  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...              0   \n",
       "9  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...              0   \n",
       "\n",
       "   scene_change_count  scene_change_density  scene_score_0_10  mean_clip_dist  \\\n",
       "0                   0                   0.0               0.0             0.0   \n",
       "1                   0                   0.0               0.0             0.0   \n",
       "2                   0                   0.0               0.0             0.0   \n",
       "3                   0                   0.0               0.0             0.0   \n",
       "4                   0                   0.0               0.0             0.0   \n",
       "5                   0                   0.0               0.0             0.0   \n",
       "6                   0                   0.0               0.0             0.0   \n",
       "7                   0                   0.0               0.0             0.0   \n",
       "8                   0                   0.0               0.0             0.0   \n",
       "9                   0                   0.0               0.0             0.0   \n",
       "\n",
       "   std_clip_dist  clip_score_0_10  mean_hist_dist  std_hist_dist  \\\n",
       "0            0.0              0.0             0.0            0.0   \n",
       "1            0.0              0.0             0.0            0.0   \n",
       "2            0.0              0.0             0.0            0.0   \n",
       "3            0.0              0.0             0.0            0.0   \n",
       "4            0.0              0.0             0.0            0.0   \n",
       "5            0.0              0.0             0.0            0.0   \n",
       "6            0.0              0.0             0.0            0.0   \n",
       "7            0.0              0.0             0.0            0.0   \n",
       "8            0.0              0.0             0.0            0.0   \n",
       "9            0.0              0.0             0.0            0.0   \n",
       "\n",
       "   hist_score_0_10  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "9              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>n_reels</th>\n",
       "      <th>mean_scene_score</th>\n",
       "      <th>mean_clip_score</th>\n",
       "      <th>mean_hist_score</th>\n",
       "      <th>max_scene_score</th>\n",
       "      <th>max_clip_score</th>\n",
       "      <th>max_hist_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             creator  n_reels  mean_scene_score  mean_clip_score  \\\n",
       "0  badassbrownbeauty        5               0.0              0.0   \n",
       "1      mahiekasharma        5               0.0              0.0   \n",
       "2       museumofsoum        5               0.0              0.0   \n",
       "3        nevaforevaa        5               0.0              0.0   \n",
       "4          riapalkar        5               0.0              0.0   \n",
       "\n",
       "   mean_hist_score  max_scene_score  max_clip_score  max_hist_score  \n",
       "0              0.0              0.0             0.0             0.0  \n",
       "1              0.0              0.0             0.0             0.0  \n",
       "2              0.0              0.0             0.0             0.0  \n",
       "3              0.0              0.0             0.0             0.0  \n",
       "4              0.0              0.0             0.0             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FULL LOCAL-ONLY PIPELINE (WITH GEMINI PROMPT + WHISPER + CACHES)\n",
    "# - No Apify\n",
    "# - No downloads\n",
    "# - Reads cached mp4s from CACHE_DIR\n",
    "# - Uses caption/comments from sidecar JSON if available\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "CACHE_DIR = \"reel_cache\"          # <-- set this to your cache root\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\", \".mkv\", \".webm\"}\n",
    "\n",
    "WHISPER_MODEL_NAME = \"medium\"\n",
    "GEMINI_MODEL_NAME = \"models/gemini-2.0-flash-001\"\n",
    "\n",
    "MAX_FRAMES_PER_REEL = 16\n",
    "MAX_REELS_PER_CREATOR = 5\n",
    "MAX_TRANSCRIPT_CHARS = 12000\n",
    "\n",
    "# =============================================================================\n",
    "# 1) GEMINI MODULE (prompt + helpers) ‚Äî FROM YOUR CELL (with small fixes)\n",
    "# =============================================================================\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY=\"AIzaSyCKS5i6kcsAPK_TuAOno9OUHdoqFRx-PRU\"\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"Missing GEMINI_API_KEY (set it in .env or env vars)\")\n",
    "\n",
    "\n",
    "GEMINI_MODEL_NAME = \"models/gemini-2.0-flash-001\"\n",
    "\n",
    "_gemini_client: Optional[genai.Client] = None\n",
    "\n",
    "def get_gemini_client() -> genai.Client:\n",
    "    global _gemini_client\n",
    "    if _gemini_client is None:\n",
    "        _gemini_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "    return _gemini_client\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Prompt template (UPDATED)\n",
    "# -------------------------------------------------------------------------\n",
    "GEMINI_PROMPT_TEMPLATE = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    You are helping a beauty and personal-care brand evaluate Instagram creators\n",
    "    for potential collaborations.\n",
    "\n",
    "    You will receive ONLY text data for ONE reel in this format:\n",
    "\n",
    "    INSTAGRAM REEL TEXT DATA\n",
    "\n",
    "    --- CAPTION ---\n",
    "    {caption}\n",
    "\n",
    "    --- TRANSCRIPT (ASR) ---\n",
    "    {transcript}\n",
    "\n",
    "    --- COMMENTS (if any) ---\n",
    "    {comments_block}\n",
    "\n",
    "    Language may be English, Hinglish (Hindi in Latin script), or a mix.\n",
    "\n",
    "    Your job is to analyse this reel and return ONLY a compact JSON summary with\n",
    "    the following fields. Do NOT repeat the caption, transcript, or comments in\n",
    "    your output. Do NOT add extra text or explanations.\n",
    "\n",
    "    For each reel, infer:\n",
    "\n",
    "    1) genz_word_count (integer)\n",
    "       - Count how many Gen Z / internet slang terms are used in the TRANSCRIPT.\n",
    "       - Count total occurrences.\n",
    "\n",
    "    2) is_marketing (0 or 1)\n",
    "       - 1 if the reel is doing ANY kind of marketing or promotion.\n",
    "\n",
    "    3) is_educational (0 or 1)\n",
    "       - 1 if the reel is primarily educational or informative.\n",
    "\n",
    "    4) is_vlog (0 or 1)\n",
    "       - 1 if the reel is vlog-style / day-in-life / GRWM / narrated routine.\n",
    "\n",
    "    5) has_humour (0 or 1)\n",
    "       - Look at TRANSCRIPT and COMMENTS.\n",
    "       - 1 if there is clear humour / comedic tone / laughter reactions.\n",
    "\n",
    "    6) comment_sentiment_counts (object)\n",
    "       - For each TOP COMMENT, classify it into exactly ONE bucket:\n",
    "         \"questioning\", \"agreeing\", \"appreciating\", \"negative\", \"neutral\"\n",
    "       - Return only aggregate counts.\n",
    "\n",
    "    7) is_arts_culture (0 or 1)   ‚úÖ NEW\n",
    "       - 1 if the reel meaningfully discusses or references topics like:\n",
    "         - Art / artists / painting / sculpture / design / architecture\n",
    "         - Museums / exhibitions / galleries\n",
    "         - Literature / poetry / books / authors\n",
    "         - Theatre / dance / performance / classical arts\n",
    "         - Culture / cultural identity / heritage / tradition / mythology\n",
    "         - Cultural history / historical narratives / history explanations\n",
    "         - Movies / cinema / film / TV / documentaries / famous scenes\n",
    "         - Pop-culture commentary is allowed IF it‚Äôs about movies/film/media\n",
    "       - Use CAPTION + TRANSCRIPT primarily (COMMENTS can provide weak evidence).\n",
    "       - If it's only a passing mention (e.g., ‚Äúmovie night lol‚Äù), keep it 0.\n",
    "\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    OUTPUT FORMAT (STRICT)\n",
    "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    Return your answer as VALID JSON inside <res> ... </res> and nothing else.\n",
    "\n",
    "    <res>\n",
    "    {{\n",
    "      \"genz_word_count\": INTEGER,\n",
    "      \"is_marketing\": 0,\n",
    "      \"is_educational\": 0,\n",
    "      \"is_vlog\": 0,\n",
    "      \"has_humour\": 0,\n",
    "      \"is_arts_culture\": 0,\n",
    "      \"comment_sentiment_counts\": {{\n",
    "        \"questioning\": INTEGER,\n",
    "        \"agreeing\": INTEGER,\n",
    "        \"appreciating\": INTEGER,\n",
    "        \"negative\": INTEGER,\n",
    "        \"neutral\": INTEGER\n",
    "      }}\n",
    "    }}\n",
    "    </res>\n",
    "\n",
    "    Rules:\n",
    "    - Do NOT include reasons, explanations, or any extra fields.\n",
    "    - Do NOT repeat or summarise the caption, transcript, or comments.\n",
    "    - Always fill every field with an integer (for counts) or 0/1 for binary flags.\n",
    "    \"\"\"\n",
    ").strip()\n",
    "\n",
    "\n",
    "def _build_gemini_prompt(caption: str, transcript: str, comments: List[str]) -> str:\n",
    "    caption = caption or \"\"\n",
    "    transcript = transcript or \"\"\n",
    "\n",
    "    if comments is None:\n",
    "        comments_list = []\n",
    "    elif isinstance(comments, (list, tuple)):\n",
    "        comments_list = list(comments)\n",
    "    elif hasattr(comments, \"tolist\"):\n",
    "        comments_list = comments.tolist()\n",
    "    else:\n",
    "        comments_list = [comments]\n",
    "\n",
    "    cleaned_comments = []\n",
    "    for c in comments_list:\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if s:\n",
    "            cleaned_comments.append(s)\n",
    "\n",
    "    comments_block = \"\\n\".join(f\"- {c}\" for c in cleaned_comments[:20]) if cleaned_comments else \"None\"\n",
    "\n",
    "    return GEMINI_PROMPT_TEMPLATE.format(\n",
    "        caption=caption,\n",
    "        transcript=transcript,\n",
    "        comments_block=comments_block,\n",
    "    )\n",
    "\n",
    "\n",
    "def _extract_json_object(text: str) -> str:\n",
    "    text = (text or \"\").strip()\n",
    "\n",
    "    # Prefer <res> ... </res>\n",
    "    m = re.search(r\"<res>\\s*(\\{.*?\\})\\s*</res>\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        candidate = m.group(1).strip()\n",
    "        json.loads(candidate)\n",
    "        return candidate\n",
    "\n",
    "    # Fast path: whole string is JSON\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return text\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first '{' ... last '}'\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        raise ValueError(\"No JSON object found in Gemini output.\")\n",
    "    candidate = text[start:end+1]\n",
    "    json.loads(candidate)\n",
    "    return candidate\n",
    "\n",
    "\n",
    "# Expected schema (so your pipeline doesn't break if Gemini misses a field)\n",
    "_EXPECTED_TOP_LEVEL = {\n",
    "    \"genz_word_count\": 0,\n",
    "    \"is_marketing\": 0,\n",
    "    \"is_educational\": 0,\n",
    "    \"is_vlog\": 0,\n",
    "    \"has_humour\": 0,\n",
    "    \"is_arts_culture\": 0,  # ‚úÖ NEW\n",
    "    \"comment_sentiment_counts\": {\n",
    "        \"questioning\": 0,\n",
    "        \"agreeing\": 0,\n",
    "        \"appreciating\": 0,\n",
    "        \"negative\": 0,\n",
    "        \"neutral\": 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "def _coerce_int01(x, default=0):\n",
    "    try:\n",
    "        v = int(float(x))\n",
    "        return 1 if v >= 1 else 0\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _coerce_int(x, default=0):\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "def call_gemini_for_reel(\n",
    "    caption: str,\n",
    "    transcript: str,\n",
    "    comments: List[str],\n",
    "    temperature: float = 0.1,\n",
    ") -> str:\n",
    "    prompt = _build_gemini_prompt(caption, transcript, comments)\n",
    "    client = get_gemini_client()\n",
    "\n",
    "    try:\n",
    "        resp = client.models.generate_content(\n",
    "            model=GEMINI_MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config={\"temperature\": temperature},\n",
    "        )\n",
    "        raw_text = (getattr(resp, \"text\", None) or \"\").strip()\n",
    "        if not raw_text:\n",
    "            print(\"    ‚úó Gemini returned empty text\")\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Gemini API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        json_str = _extract_json_object(raw_text)\n",
    "        data = json.loads(json_str)\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Gemini JSON is not an object.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Gemini JSON parse failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # ---- Schema enforcement + coercion ----\n",
    "    out = dict(_EXPECTED_TOP_LEVEL)  # defaults\n",
    "\n",
    "    out[\"genz_word_count\"] = _coerce_int(data.get(\"genz_word_count\", 0), 0)\n",
    "    out[\"is_marketing\"] = _coerce_int01(data.get(\"is_marketing\", 0), 0)\n",
    "    out[\"is_educational\"] = _coerce_int01(data.get(\"is_educational\", 0), 0)\n",
    "    out[\"is_vlog\"] = _coerce_int01(data.get(\"is_vlog\", 0), 0)\n",
    "    out[\"has_humour\"] = _coerce_int01(data.get(\"has_humour\", 0), 0)\n",
    "    out[\"is_arts_culture\"] = _coerce_int01(data.get(\"is_arts_culture\", 0), 0)  # ‚úÖ NEW\n",
    "\n",
    "    csc = data.get(\"comment_sentiment_counts\", {}) or {}\n",
    "    out[\"comment_sentiment_counts\"] = {\n",
    "        \"questioning\": _coerce_int(csc.get(\"questioning\", 0), 0),\n",
    "        \"agreeing\": _coerce_int(csc.get(\"agreeing\", 0), 0),\n",
    "        \"appreciating\": _coerce_int(csc.get(\"appreciating\", 0), 0),\n",
    "        \"negative\": _coerce_int(csc.get(\"negative\", 0), 0),\n",
    "        \"neutral\": _coerce_int(csc.get(\"neutral\", 0), 0),\n",
    "    }\n",
    "\n",
    "    return json.dumps(out)\n",
    "\n",
    "# =============================================================================\n",
    "# 2) WHISPER TRANSCRIPT MODULE (your logic + disk cache)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Loading Whisper model: {WHISPER_MODEL_NAME} ...\")\n",
    "_whisper_model = whisper.load_model(WHISPER_MODEL_NAME)\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "_transcript_cache: dict[str, str] = {}\n",
    "\n",
    "def transcript_cache_path(video_path: str) -> str:\n",
    "    vp = Path(video_path)\n",
    "    return str(vp.with_suffix(vp.suffix + \".whisper.txt\"))\n",
    "\n",
    "def load_transcript_cache(video_path: str) -> str:\n",
    "    p = transcript_cache_path(video_path)\n",
    "    if os.path.exists(p) and os.path.getsize(p) > 0:\n",
    "        try:\n",
    "            return Path(p).read_text(encoding=\"utf-8\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    return \"\"\n",
    "\n",
    "def save_transcript_cache(video_path: str, text: str):\n",
    "    p = transcript_cache_path(video_path)\n",
    "    try:\n",
    "        Path(p).parent.mkdir(parents=True, exist_ok=True)\n",
    "        Path(p).write_text(text or \"\", encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Could not write transcript cache: {e}\")\n",
    "\n",
    "def transcribe_reel(video_path: str, reel_url: str | None = None, force: bool = False) -> str:\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    ‚úó Video file not found for transcription:\", video_path)\n",
    "        return \"\"\n",
    "\n",
    "    cache_key = reel_url or video_path\n",
    "    if not force and cache_key in _transcript_cache:\n",
    "        return _transcript_cache[cache_key]\n",
    "\n",
    "    if not force:\n",
    "        disk = load_transcript_cache(video_path)\n",
    "        if disk:\n",
    "            _transcript_cache[cache_key] = disk\n",
    "            return disk\n",
    "\n",
    "    try:\n",
    "        print(\"    üéô Transcribing audio with Whisper ...\")\n",
    "        use_fp16 = torch.cuda.is_available()\n",
    "        result = _whisper_model.transcribe(video_path, fp16=use_fp16)\n",
    "        text = (result.get(\"text\") or \"\").strip()\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Whisper transcription failed: {e}\")\n",
    "        text = \"\"\n",
    "\n",
    "    if len(text) > MAX_TRANSCRIPT_CHARS:\n",
    "        text = text[:MAX_TRANSCRIPT_CHARS] + \" ...\"\n",
    "\n",
    "    _transcript_cache[cache_key] = text\n",
    "    save_transcript_cache(video_path, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) GEMINI DISK CACHE\n",
    "# =============================================================================\n",
    "\n",
    "def gemini_cache_path(video_path: str) -> str:\n",
    "    vp = Path(video_path)\n",
    "    return str(vp.with_suffix(vp.suffix + \".gemini.json\"))\n",
    "\n",
    "def load_gemini_cache(video_path: str) -> str:\n",
    "    p = gemini_cache_path(video_path)\n",
    "    if os.path.exists(p) and os.path.getsize(p) > 0:\n",
    "        try:\n",
    "            return Path(p).read_text(encoding=\"utf-8\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    return \"\"\n",
    "\n",
    "def save_gemini_cache(video_path: str, gemini_raw: str):\n",
    "    p = gemini_cache_path(video_path)\n",
    "    try:\n",
    "        Path(p).parent.mkdir(parents=True, exist_ok=True)\n",
    "        Path(p).write_text(gemini_raw or \"\", encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Could not write Gemini cache: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) OPTIONAL: LOAD CAPTION/COMMENTS FROM SIDECAR JSON\n",
    "#    Put a JSON next to mp4 like: <video>.meta.json\n",
    "#    Example fields it can contain:\n",
    "#      { \"reel_url\": \"...\", \"caption\": \"...\", \"latestComments\": [...], \"flat_comments\": [...] }\n",
    "# =============================================================================\n",
    "\n",
    "def flatten_comments(latest_comments, max_n=50):\n",
    "    if not isinstance(latest_comments, list):\n",
    "        return []\n",
    "    out = []\n",
    "    for c in latest_comments[:max_n]:\n",
    "        if isinstance(c, dict):\n",
    "            txt = c.get(\"text\") or c.get(\"body\") or \"\"\n",
    "            if txt.strip():\n",
    "                out.append(txt.strip())\n",
    "        elif isinstance(c, str) and c.strip():\n",
    "            out.append(c.strip())\n",
    "    return out\n",
    "\n",
    "def load_text_sidecar(video_path: str):\n",
    "    \"\"\"\n",
    "    Looks for:\n",
    "      - <video>.meta.json\n",
    "      - OR any *.json in the same folder (first match) that contains caption/url/comments\n",
    "    Returns: (reel_url, caption, flat_comments)\n",
    "    \"\"\"\n",
    "    vp = Path(video_path)\n",
    "    meta1 = vp.with_suffix(vp.suffix + \".meta.json\")\n",
    "\n",
    "    candidates = []\n",
    "    if meta1.exists():\n",
    "        candidates.append(meta1)\n",
    "    # fallback: any json in same directory\n",
    "    candidates += list(vp.parent.glob(\"*.json\"))\n",
    "\n",
    "    for p in candidates:\n",
    "        try:\n",
    "            data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "            if not isinstance(data, dict):\n",
    "                continue\n",
    "            reel_url = data.get(\"reel_url\") or data.get(\"url\") or data.get(\"postUrl\") or None\n",
    "            caption = data.get(\"caption\") or \"\"\n",
    "            # accept either \"flat_comments\" already or build from \"latestComments\"\n",
    "            if \"flat_comments\" in data:\n",
    "                flat_comments = data.get(\"flat_comments\") or []\n",
    "            else:\n",
    "                flat_comments = flatten_comments(data.get(\"latestComments\"), max_n=50)\n",
    "            return reel_url, caption, flat_comments\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return None, \"\", []\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) LOCAL CACHE DISCOVERY\n",
    "# =============================================================================\n",
    "\n",
    "def list_cached_videos_for_creator(cache_root: str, creator: str, max_items: int = 10):\n",
    "    creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "    root = Path(cache_root)\n",
    "\n",
    "    cand = []\n",
    "\n",
    "    # Layout 1: cache_root/<creator>/**\n",
    "    p1 = root / creator_norm\n",
    "    if p1.exists():\n",
    "        cand += [p for p in p1.rglob(\"*\")\n",
    "                 if p.is_file() and p.suffix.lower() in VIDEO_EXTS and p.stat().st_size > 0]\n",
    "\n",
    "    # Layout 2: anywhere containing creator in path\n",
    "    if root.exists():\n",
    "        cand += [\n",
    "            p for p in root.rglob(\"*\")\n",
    "            if p.is_file()\n",
    "            and p.suffix.lower() in VIDEO_EXTS\n",
    "            and p.stat().st_size > 0\n",
    "            and (creator_norm in str(p.parent).lower() or creator_norm in str(p).lower())\n",
    "        ]\n",
    "\n",
    "    cand = list({str(p): p for p in cand}.values())\n",
    "    cand = sorted(cand, key=lambda p: p.stat().st_mtime, reverse=True)[:max_items]\n",
    "    return cand\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6) MAIN LOCAL PIPELINE\n",
    "#    Requires your existing function:\n",
    "#      compute_three_change_metrics_for_video(video_path, max_frames=...)\n",
    "# =============================================================================\n",
    "\n",
    "def run_local_cached_pipeline_for_creators(\n",
    "    creator_list,\n",
    "    cache_dir: str = CACHE_DIR,\n",
    "    max_reels_per_creator: int = MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel: int = MAX_FRAMES_PER_REEL,\n",
    "    run_whisper: bool = True,\n",
    "    force_whisper: bool = False,\n",
    "    run_gemini: bool = True,\n",
    "    force_gemini: bool = False,\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for creator in creator_list:\n",
    "        creator_norm = str(creator).strip().lstrip(\"@\").lower()\n",
    "        vids = list_cached_videos_for_creator(cache_dir, creator_norm, max_items=max_reels_per_creator)\n",
    "\n",
    "        print(f\"\\n=== LOCAL PIPELINE: {creator_norm} ===\")\n",
    "        print(f\"Found {len(vids)} cached videos under {cache_dir}\")\n",
    "\n",
    "        if not vids:\n",
    "            continue\n",
    "\n",
    "        for i, p in enumerate(vids):\n",
    "            video_path = str(p)\n",
    "            print(f\"\\n  ‚ñ∂ Reel {i}: {video_path}\")\n",
    "\n",
    "            # Load text bundle (caption/comments/url) for Gemini prompt\n",
    "            reel_url, caption, flat_comments = load_text_sidecar(video_path)\n",
    "\n",
    "            # 1) change metrics\n",
    "            try:\n",
    "                change_metrics = compute_three_change_metrics_for_video(\n",
    "                    video_path,\n",
    "                    max_frames=max_frames_per_reel\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚úó Change metric failed: {e}\")\n",
    "                change_metrics = {\n",
    "                    \"n_frames_used\": 0,\n",
    "                    \"scene_change_count\": 0,\n",
    "                    \"scene_change_density\": 0.0,\n",
    "                    \"scene_score_0_10\": 0.0,\n",
    "                    \"mean_clip_dist\": 0.0,\n",
    "                    \"std_clip_dist\": 0.0,\n",
    "                    \"clip_score_0_10\": 0.0,\n",
    "                    \"mean_hist_dist\": 0.0,\n",
    "                    \"std_hist_dist\": 0.0,\n",
    "                    \"hist_score_0_10\": 0.0,\n",
    "                }\n",
    "\n",
    "            # 2) whisper transcript\n",
    "            transcript = \"\"\n",
    "            if run_whisper:\n",
    "                transcript = transcribe_reel(video_path, reel_url=reel_url, force=force_whisper)\n",
    "\n",
    "            # 3) gemini (cached)\n",
    "            gemini_raw = \"\"\n",
    "            if run_gemini:\n",
    "                if not force_gemini:\n",
    "                    gemini_raw = load_gemini_cache(video_path)\n",
    "\n",
    "                if gemini_raw:\n",
    "                    print(\"    ‚úÖ Gemini cache hit\")\n",
    "                else:\n",
    "                    print(\"    ü§ñ Calling Gemini ...\")\n",
    "                    gemini_raw = call_gemini_for_reel(\n",
    "                        caption=caption,\n",
    "                        transcript=transcript,\n",
    "                        comments=flat_comments,\n",
    "                        temperature=0.1,\n",
    "                    )\n",
    "                    save_gemini_cache(video_path, gemini_raw)\n",
    "                    print(\"    üíæ Saved Gemini cache\")\n",
    "\n",
    "            row = {\n",
    "                \"creator\": creator_norm,\n",
    "                \"reel_idx\": i,\n",
    "                \"reel_url\": reel_url,\n",
    "                \"caption\": caption,\n",
    "                \"video_path\": video_path,\n",
    "                \"transcript\": transcript,\n",
    "                \"gemini_raw\": gemini_raw,\n",
    "            }\n",
    "            row.update(change_metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    df_reels_all = pd.DataFrame(rows)\n",
    "\n",
    "    if not df_reels_all.empty:\n",
    "        df_creator_all = (\n",
    "            df_reels_all\n",
    "            .groupby(\"creator\", as_index=False)\n",
    "            .agg(\n",
    "                n_reels=(\"reel_idx\", \"count\"),\n",
    "                mean_scene_score=(\"scene_score_0_10\", \"mean\"),\n",
    "                mean_clip_score=(\"clip_score_0_10\", \"mean\"),\n",
    "                mean_hist_score=(\"hist_score_0_10\", \"mean\"),\n",
    "                max_scene_score=(\"scene_score_0_10\", \"max\"),\n",
    "                max_clip_score=(\"clip_score_0_10\", \"max\"),\n",
    "                max_hist_score=(\"hist_score_0_10\", \"max\"),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df_creator_all = pd.DataFrame()\n",
    "\n",
    "    return df_reels_all, df_creator_all\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUN\n",
    "# =============================================================================\n",
    "df_reels_all, df_creator_all = run_local_cached_pipeline_for_creators(\n",
    "    CREATOR_LIST,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    max_reels_per_creator=MAX_REELS_PER_CREATOR,\n",
    "    max_frames_per_reel=MAX_FRAMES_PER_REEL,\n",
    "    run_whisper=True,\n",
    "    run_gemini=True,\n",
    "    force_whisper=False,\n",
    "    force_gemini=False,\n",
    ")\n",
    "\n",
    "display(df_reels_all.head(10))\n",
    "display(df_creator_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0aee461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creators matched: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genz_word_count</th>\n",
       "      <th>is_marketing</th>\n",
       "      <th>is_educational</th>\n",
       "      <th>is_vlog</th>\n",
       "      <th>has_humour</th>\n",
       "      <th>comment_questioning</th>\n",
       "      <th>comment_agreeing</th>\n",
       "      <th>comment_appreciating</th>\n",
       "      <th>comment_negative</th>\n",
       "      <th>comment_neutral</th>\n",
       "      <th>is_arts_culture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>1.392715e-01</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>-0.603510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspirational</th>\n",
       "      <td>1.611646e-01</td>\n",
       "      <td>0.026068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888235</td>\n",
       "      <td>-0.564076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatable</th>\n",
       "      <td>1.266863e-16</td>\n",
       "      <td>0.885937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.372678</td>\n",
       "      <td>-0.456435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.456435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credible</th>\n",
       "      <td>4.029115e-02</td>\n",
       "      <td>0.886320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.394771</td>\n",
       "      <td>-0.443203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.241747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communication</th>\n",
       "      <td>4.262465e-01</td>\n",
       "      <td>0.956037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208817</td>\n",
       "      <td>-0.596745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.085249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story_telling</th>\n",
       "      <td>2.274294e-01</td>\n",
       "      <td>0.956449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.061898</td>\n",
       "      <td>-0.606478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.037905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               genz_word_count  is_marketing  is_educational   is_vlog  \\\n",
       "cool              1.392715e-01      0.010012             NaN  0.909718   \n",
       "aspirational      1.611646e-01      0.026068             NaN  0.888235   \n",
       "relatable         1.266863e-16      0.885937             NaN -0.372678   \n",
       "credible          4.029115e-02      0.886320             NaN -0.394771   \n",
       "communication     4.262465e-01      0.956037             NaN  0.208817   \n",
       "story_telling     2.274294e-01      0.956449             NaN -0.061898   \n",
       "\n",
       "               has_humour  comment_questioning  comment_agreeing  \\\n",
       "cool            -0.603510                  NaN               NaN   \n",
       "aspirational    -0.564076                  NaN               NaN   \n",
       "relatable       -0.456435                  NaN               NaN   \n",
       "credible        -0.443203                  NaN               NaN   \n",
       "communication   -0.596745                  NaN               NaN   \n",
       "story_telling   -0.606478                  NaN               NaN   \n",
       "\n",
       "               comment_appreciating  comment_negative  comment_neutral  \\\n",
       "cool                            NaN               NaN              NaN   \n",
       "aspirational                    NaN               NaN              NaN   \n",
       "relatable                       NaN               NaN              NaN   \n",
       "credible                        NaN               NaN              NaN   \n",
       "communication                   NaN               NaN              NaN   \n",
       "story_telling                   NaN               NaN              NaN   \n",
       "\n",
       "               is_arts_culture  \n",
       "cool                  0.324967  \n",
       "aspirational          0.241747  \n",
       "relatable            -0.456435  \n",
       "credible             -0.241747  \n",
       "communication        -0.085249  \n",
       "story_telling        -0.037905  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "# ---- 1) Labels (train_data.csv) ----\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "def norm_col(c):\n",
    "    c = str(c).replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    c = c.strip().lower()\n",
    "    c = re.sub(r\"\\s+\", \"_\", c)\n",
    "    c = re.sub(r\"_+\", \"_\", c)\n",
    "    return c\n",
    "\n",
    "df_train.columns = [norm_col(c) for c in df_train.columns]\n",
    "df_train[\"creator_norm\"] = df_train[\"creator\"].astype(str).str.strip().str.lstrip(\"@\").str.lower()\n",
    "\n",
    "traits = [\"cool\", \"aspirational\", \"relatable\", \"credible\", \"communication\", \"story_telling\"]\n",
    "missing_traits = [t for t in traits if t not in df_train.columns]\n",
    "if missing_traits:\n",
    "    raise ValueError(f\"Missing trait cols {missing_traits}. Available: {list(df_train.columns)}\")\n",
    "\n",
    "df_labels = (\n",
    "    df_train.groupby(\"creator_norm\", as_index=False)\n",
    "    .agg(**{t: (t, \"mean\") for t in traits})\n",
    ")\n",
    "\n",
    "# ---- 2) Parse gemini_raw from df_reels_all ----\n",
    "if \"df_reels_all\" not in globals():\n",
    "    raise ValueError(\"df_reels_all not found. Run your pipeline first to create df_reels_all.\")\n",
    "\n",
    "df_g = df_reels_all.copy()\n",
    "df_g[\"creator_norm\"] = df_g[\"creator\"].astype(str).str.strip().str.lstrip(\"@\").str.lower()\n",
    "\n",
    "def parse_gemini_raw(s):\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return {}\n",
    "    try:\n",
    "        d = json.loads(s)\n",
    "        if not isinstance(d, dict):\n",
    "            return {}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    out = {}\n",
    "    # top-level fields\n",
    "    for k, v in d.items():\n",
    "        if k == \"comment_sentiment_counts\":\n",
    "            continue\n",
    "        out[k] = v\n",
    "\n",
    "    # flatten comment sentiment counts\n",
    "    csc = d.get(\"comment_sentiment_counts\") or {}\n",
    "    if isinstance(csc, dict):\n",
    "        for kk, vv in csc.items():\n",
    "            out[f\"comment_{kk}\"] = vv\n",
    "\n",
    "    return out\n",
    "\n",
    "df_gem = pd.json_normalize(df_g[\"gemini_raw\"].apply(parse_gemini_raw))\n",
    "df_g2 = pd.concat([df_g[[\"creator_norm\"]], df_gem], axis=1)\n",
    "\n",
    "# numeric coercion\n",
    "for c in df_g2.columns:\n",
    "    if c != \"creator_norm\":\n",
    "        df_g2[c] = pd.to_numeric(df_g2[c], errors=\"coerce\")\n",
    "\n",
    "gemini_metrics = [c for c in df_g2.columns if c != \"creator_norm\"]\n",
    "if not gemini_metrics:\n",
    "    raise ValueError(\"No Gemini metrics parsed from gemini_raw.\")\n",
    "\n",
    "# ---- 3) Aggregate gemini metrics per creator + merge ----\n",
    "df_gem_creator = (\n",
    "    df_g2.groupby(\"creator_norm\", as_index=False)\n",
    "    .agg(**{m: (m, \"mean\") for m in gemini_metrics})\n",
    ")\n",
    "\n",
    "df_m = df_labels.merge(df_gem_creator, on=\"creator_norm\", how=\"inner\")\n",
    "\n",
    "print(\"Creators matched:\", len(df_m))\n",
    "\n",
    "# ---- 4) Correlation matrix (Pearson) ----\n",
    "corr_matrix = df_m[traits + gemini_metrics].corr(method=\"pearson\").loc[traits, gemini_metrics]\n",
    "\n",
    "display(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dc5f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_norm</th>\n",
       "      <th>genz_word_count</th>\n",
       "      <th>is_marketing</th>\n",
       "      <th>is_educational</th>\n",
       "      <th>is_vlog</th>\n",
       "      <th>has_humour</th>\n",
       "      <th>comment_questioning</th>\n",
       "      <th>comment_agreeing</th>\n",
       "      <th>comment_appreciating</th>\n",
       "      <th>comment_negative</th>\n",
       "      <th>comment_neutral</th>\n",
       "      <th>is_arts_culture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badassbrownbeauty</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahiekasharma</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nevaforevaa</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riapalkar</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creator_norm  genz_word_count  is_marketing  is_educational  is_vlog  \\\n",
       "0  badassbrownbeauty              0.2           1.0             0.0      0.0   \n",
       "1      mahiekasharma              0.2           0.4             0.0      0.4   \n",
       "2       museumofsoum              0.0           0.0             0.0      0.0   \n",
       "3        nevaforevaa              0.2           0.0             0.0      0.0   \n",
       "4          riapalkar              0.2           0.2             0.0      0.4   \n",
       "\n",
       "   has_humour  comment_questioning  comment_agreeing  comment_appreciating  \\\n",
       "0         0.0                  0.0               0.0                   0.0   \n",
       "1         0.0                  0.0               0.0                   0.0   \n",
       "2         0.0                  0.0               0.0                   0.0   \n",
       "3         0.2                  0.0               0.0                   0.0   \n",
       "4         0.0                  0.0               0.0                   0.0   \n",
       "\n",
       "   comment_negative  comment_neutral  is_arts_culture  \n",
       "0               0.0              0.0              0.0  \n",
       "1               0.0              0.0              0.0  \n",
       "2               0.0              0.0              0.0  \n",
       "3               0.0              0.0              0.0  \n",
       "4               0.0              0.0              0.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gem_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5024f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
