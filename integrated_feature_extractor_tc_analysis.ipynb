{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fae052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1 â€” IMPORTS & CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import whisper\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "# Your existing helpers / models\n",
    "from mine_redis import get_files_gem  # SAME helper as in your notebooks\n",
    "from aesthetic_predictor import predict_aesthetic  # used in attractiveness\n",
    "# from ultralytics import YOLO  # if you use YOLO for accessories, uncomment\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "APIFY_API_KEY=os.getenv(\"APIFY_API_TOKEN\")\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "MAX_DOWNLOAD_WORKERS = 10\n",
    "\n",
    "\n",
    "if not APIFY_API_KEY:\n",
    "    raise RuntimeError(\"Missing APIFY_API_KEY in env/.env\")\n",
    "\n",
    "apify = ApifyClient(APIFY_API_KEY)\n",
    "\n",
    "# If you use Gemini\n",
    "from google import genai\n",
    "gemini_client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None\n",
    "GEMINI_MODEL = \"models/gemini-2.0-flash-001\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# GLOBAL CONFIG\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "REEL_DOWNLOAD_DIR = \"./_reel_cache\"\n",
    "os.makedirs(REEL_DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "MAX_REELS_PER_CREATOR = 1 # you can tune\n",
    "FRAME_SAMPLE_COUNT = 16    # frames per reel for vision metrics\n",
    "\n",
    "import torch\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "DEVICE = \"cuda\" if USE_GPU else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if (hasattr(whisper, \"cuda\") and torch.cuda.is_available()) else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202217f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_PATH = Path(\"reel_manifest.json\")\n",
    "\n",
    "def load_manifest():\n",
    "    if CACHE_PATH.exists():\n",
    "        with open(CACHE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_manifest(manifest):\n",
    "    with open(CACHE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "\n",
    "manifest = load_manifest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d8b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APIFY CLIENT + SCRAPER HELPERS â€” MATCHING gemini.ipynb\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "from mine_redis import get_files_gem  # same helper you use elsewhere\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# APIFY_API_KEY = os.getenv(\"APIFY_API_KEY\")\n",
    "if not APIFY_API_KEY:\n",
    "    raise RuntimeError(\"Missing APIFY_API_KEY (set it in .env or env vars)\")\n",
    "\n",
    "# Single Apify client (same as in gemini.ipynb)\n",
    "apify = ApifyClient(APIFY_API_KEY)\n",
    "\n",
    "\n",
    "def flatten_comments(comment_list, max_n: int = 50) -> list[str]:\n",
    "    \"\"\"\n",
    "    Convert a single comment list (Apify objects) â†’ simple text list.\n",
    "    Used as a primitive for both top-level and deep comment arrays.\n",
    "    \"\"\"\n",
    "    if not isinstance(comment_list, list):\n",
    "        return []\n",
    "    out = []\n",
    "    for c in comment_list[:max_n]:\n",
    "        if isinstance(c, dict):\n",
    "            txt = c.get(\"text\") or c.get(\"body\") or \"\"\n",
    "            txt = (txt or \"\").strip()\n",
    "            if txt:\n",
    "                out.append(txt)\n",
    "    return out\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "APIFY_CACHE_DIR = Path(\"cache_apify\")\n",
    "APIFY_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_or_fetch_reels_cached(creator: str, max_items: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cache wrapper around fetch_reels_from_apify.\n",
    "\n",
    "    - First run: hits Apify, saves to cache_apify/<creator>_max<max_items>.parquet\n",
    "    - Re-runs: loads from that file instead of hitting the network.\n",
    "    \"\"\"\n",
    "    cache_path = APIFY_CACHE_DIR / f\"{creator}_max{max_items}.parquet\"\n",
    "\n",
    "    if cache_path.exists():\n",
    "        print(f\"ðŸ“‚ Using cached Apify reels for @{creator} from {cache_path}\")\n",
    "        return pd.read_parquet(cache_path)\n",
    "\n",
    "    # Fallback: real network call once\n",
    "    df = fetch_reels_from_apify(creator, max_items=max_items)\n",
    "    if not df.empty:\n",
    "        df.to_parquet(cache_path, index=False)\n",
    "        print(f\"ðŸ’¾ Cached Apify reels for @{creator} â†’ {cache_path}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No reels for @{creator}, nothing cached.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_reels_from_apify(handle: str, max_items: int = MAX_REELS_PER_CREATOR) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    NO-CACHE reels fetch.\n",
    "\n",
    "    Timing components recorded (if `record(...)` exists):\n",
    "      - apify.actor.call\n",
    "      - apify.dataset.list_items\n",
    "      - items_to_df\n",
    "      - normalize_fields\n",
    "      - flatten_comments\n",
    "      - url_filter\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“¸ Fetching reels for @{handle} via Apify...\")\n",
    "\n",
    "    @contextmanager\n",
    "    def _t(name: str, **meta):\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            dt = time.perf_counter() - t0\n",
    "            if \"record\" in globals() and callable(globals()[\"record\"]):\n",
    "                globals()[\"record\"](\"api_component\", name, dt, creator=handle, **meta)\n",
    "\n",
    "    try:\n",
    "        run_input = {\n",
    "            \"username\": [handle],\n",
    "            \"resultsLimit\": int(max_items),\n",
    "            # Ensure your Apify actor input supports comments:\n",
    "            # \"scrapeComments\": True,\n",
    "            # \"scrapeDeepComments\": True,\n",
    "        }\n",
    "\n",
    "        with _t(\"apify.actor.call\", actor_id=\"xMc5Ga1oCONPmWJIa\"):\n",
    "            run = apify.actor(\"xMc5Ga1oCONPmWJIa\").call(run_input=run_input)\n",
    "\n",
    "        dataset_id = run.get(\"defaultDatasetId\")\n",
    "        if not dataset_id:\n",
    "            print(\"  âœ— Missing defaultDatasetId from Apify run.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        with _t(\"apify.dataset.list_items\", dataset_id=dataset_id):\n",
    "            items = apify.dataset(dataset_id).list_items().items\n",
    "\n",
    "        if not items:\n",
    "            print(\"  âœ— No items returned.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        with _t(\"items_to_df\"):\n",
    "            df = pd.DataFrame(items)\n",
    "\n",
    "        with _t(\"normalize_fields\"):\n",
    "            # ----------------- reel_url -----------------\n",
    "            if \"url\" in df.columns:\n",
    "                df[\"reel_url\"] = df[\"url\"]\n",
    "            elif \"shortcode\" in df.columns:\n",
    "                df[\"reel_url\"] = \"https://www.instagram.com/reel/\" + df[\"shortcode\"].astype(str) + \"/\"\n",
    "            else:\n",
    "                df[\"reel_url\"] = None\n",
    "\n",
    "            # ----------------- caption ------------------\n",
    "            if \"caption\" in df.columns:\n",
    "                df[\"caption_norm\"] = df[\"caption\"].fillna(\"\")\n",
    "            else:\n",
    "                df[\"caption_norm\"] = \"\"\n",
    "\n",
    "        # ----------------- comments (including deep) ------------------\n",
    "        # These are the fields Apify IG actors typically expose when deep comments are enabled.\n",
    "        comment_fields = [\n",
    "            \"latestComments\",        # top-level\n",
    "            \"comments\",              # alt top-level\n",
    "            \"deepLatestComments\",    # replies / threaded\n",
    "            \"deepComments\",          # alt deep field\n",
    "        ]\n",
    "        comment_fields = [c for c in comment_fields if c in df.columns]\n",
    "\n",
    "        with _t(\"flatten_comments\", fields=\",\".join(comment_fields) if comment_fields else \"\"):\n",
    "            if comment_fields:\n",
    "                def collect_all_comments(row, max_total=100):\n",
    "                    texts = []\n",
    "                    for col in comment_fields:\n",
    "                        texts.extend(flatten_comments(row.get(col), max_n=50))\n",
    "                    # de-duplicate while preserving order\n",
    "                    seen, uniq = set(), []\n",
    "                    for t in texts:\n",
    "                        if t and t not in seen:\n",
    "                            seen.add(t)\n",
    "                            uniq.append(t)\n",
    "                        if len(uniq) >= max_total:\n",
    "                            break\n",
    "                    return uniq\n",
    "\n",
    "                df[\"flat_comments\"] = df.apply(collect_all_comments, axis=1)\n",
    "            else:\n",
    "                df[\"flat_comments\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "        with _t(\"url_filter\"):\n",
    "            mask = (\n",
    "                df[\"reel_url\"].notna()\n",
    "                & (\n",
    "                    df[\"reel_url\"].astype(str).str.contains(\"/reel/\", na=False)\n",
    "                    | df[\"reel_url\"].astype(str).str.contains(\"/p/\", na=False)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        out = df.loc[mask, [\"reel_url\", \"caption_norm\", \"flat_comments\"]].copy()\n",
    "        out = out.rename(columns={\"caption_norm\": \"caption\"}).reset_index(drop=True)\n",
    "\n",
    "        print(f\"  âœ“ {len(out)} valid reels for @{handle}\")\n",
    "        return out\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Apify error for @{handle}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DOWNLOAD CACHING (your previous logic is basically fine)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "_download_cache = {}   # reel_url -> local_path\n",
    "\n",
    "def download_reel_cached(reel_url: str, reel_no: int, task_id: str = \"joint\") -> str | None:\n",
    "    \"\"\"\n",
    "    Wrapper around get_files_gem so we only hit your reel downloader ONCE per URL.\n",
    "    Mirrors the pattern used in the other notebooks.\n",
    "    \"\"\"\n",
    "    if reel_url in _download_cache:\n",
    "        return _download_cache[reel_url]\n",
    "\n",
    "    # out = get_files_gem(REEL_URL=reel_url, REEL_NO=str(reel_no), task_id=task_id)\n",
    "    # if not out:\n",
    "    #     return None\n",
    "\n",
    "    # # get_files_gem may return a path or a dict with 'path'\n",
    "    # if isinstance(out, dict):\n",
    "    #     path = out.get(\"path\")\n",
    "    # else:\n",
    "    #     path = out\n",
    "\n",
    "    # if not path or not os.path.exists(path):\n",
    "    #     return None\n",
    "\n",
    "    # local_path = os.path.abspath(path)\n",
    "    # _download_cache[reel_url] = local_path\n",
    "    # return local_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b3eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ATTRACTIVENESS MODULE (standalone)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from aesthetic_predictor import predict_aesthetic\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# How many frames to sample per reel for attractiveness\n",
    "FRAMES_PER_REEL = 16\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. FRAME SAMPLING\n",
    "# -----------------------------------------------------------------------------\n",
    "def sample_frames_from_video(video_path: str, max_frames: int = FRAMES_PER_REEL) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Uniformly sample up to `max_frames` frames from a video.\n",
    "\n",
    "    Returns a list of frames in BGR (OpenCV default).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        return []\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    # Choose indices uniformly across the video\n",
    "    indices = np.linspace(0, total_frames - 1, num=min(max_frames, total_frames), dtype=int)\n",
    "    indices_set = set(indices.tolist())\n",
    "\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if idx in indices_set:\n",
    "            frames.append(frame)\n",
    "        idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. FACE DETECTION & BEST-FRAME SELECTION\n",
    "# -----------------------------------------------------------------------------\n",
    "# Use a standard OpenCV Haar cascade for faces (lightweight, no extra deps)\n",
    "# You may swap this for a better detector (RetinaFace, MediaPipe, etc.) later.\n",
    "_CASCADE = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectedFace:\n",
    "    x: int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int\n",
    "\n",
    "    @property\n",
    "    def bbox(self) -> Tuple[int, int, int, int]:\n",
    "        return (self.x, self.y, self.w, self.h)\n",
    "\n",
    "\n",
    "def detect_faces_in_frame(frame_bgr: np.ndarray) -> List[DetectedFace]:\n",
    "    \"\"\"\n",
    "    Detect faces using Haar cascade, returns a list of DetectedFace.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    faces = _CASCADE.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=3,\n",
    "        minSize=(60, 60),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "    )\n",
    "    return [DetectedFace(int(x), int(y), int(w), int(h)) for (x, y, w, h) in faces]\n",
    "\n",
    "\n",
    "def select_best_face_frame(frames: List[np.ndarray]) -> Tuple[Optional[int], Optional[np.ndarray], Optional[DetectedFace]]:\n",
    "    \"\"\"\n",
    "    From a list of frames, pick the one with the 'best' face:\n",
    "      - Here we choose the face with largest area (can be refined).\n",
    "    Returns: (best_frame_index, best_frame, best_face_object)\n",
    "    If no faces are found, returns (None, None, None).\n",
    "    \"\"\"\n",
    "    best_idx = None\n",
    "    best_frame = None\n",
    "    best_face = None\n",
    "    best_area = 0.0\n",
    "\n",
    "    for idx, frame in enumerate(frames):\n",
    "        faces = detect_faces_in_frame(frame)\n",
    "        if not faces:\n",
    "            continue\n",
    "        for f in faces:\n",
    "            area = f.w * f.h\n",
    "            if area > best_area:\n",
    "                best_area = area\n",
    "                best_idx = idx\n",
    "                best_frame = frame\n",
    "                best_face = f\n",
    "\n",
    "    return best_idx, best_frame, best_face\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. BASIC VISUAL CUES\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_lighting_score(frame_bgr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Lighting score based on average brightness of the frame.\n",
    "    Returns a value in [0, 1].\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    v_channel = hsv[..., 2].astype(np.float32)  # 0â€“255\n",
    "    mean_v = float(v_channel.mean())\n",
    "    # Normalize 0â€“255 â†’ 0â€“1\n",
    "    score = max(0.0, min(1.0, mean_v / 255.0))\n",
    "    return score\n",
    "\n",
    "\n",
    "def compute_sharpness_score(frame_bgr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Sharpness score based on variance of Laplacian.\n",
    "    Returns a value in [0, 1] after normalization.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    var = float(lap.var())\n",
    "\n",
    "    # Heuristic normalization: 0â€“500 â†’ 0â€“1, clamp\n",
    "    # You can tune this threshold based on your dataset.\n",
    "    norm = var / 500.0\n",
    "    norm = max(0.0, min(1.0, norm))\n",
    "    return norm\n",
    "\n",
    "\n",
    "def face_cues(frame_shape: Tuple[int, int, int], bbox: Tuple[int, int, int, int]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - face_area_frac: face bounding box area / frame area\n",
    "      - center_offset_norm: distance between face center and frame center,\n",
    "        normalized to [0, 1] (0 = perfectly centered, 1 = at extreme corner).\n",
    "    \"\"\"\n",
    "    h, w = frame_shape[:2]\n",
    "    x, y, bw, bh = bbox\n",
    "\n",
    "    face_area = float(bw * bh)\n",
    "    frame_area = float(w * h) if (w > 0 and h > 0) else 1.0\n",
    "    face_area_frac = face_area / frame_area\n",
    "\n",
    "    frame_cx, frame_cy = w / 2.0, h / 2.0\n",
    "    face_cx, face_cy = x + bw / 2.0, y + bh / 2.0\n",
    "\n",
    "    dx = face_cx - frame_cx\n",
    "    dy = face_cy - frame_cy\n",
    "    dist = math.sqrt(dx * dx + dy * dy)\n",
    "\n",
    "    # Max possible distance is corner to center\n",
    "    max_dist = math.sqrt(frame_cx ** 2 + frame_cy ** 2) or 1.0\n",
    "    center_offset_norm = dist / max_dist  # 0 center â†’ 1 corner\n",
    "\n",
    "    return float(face_area_frac), float(center_offset_norm)\n",
    "\n",
    "\n",
    "def crop_face(frame_bgr: np.ndarray, face: DetectedFace) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Crop the face region and return a PIL Image (RGB).\n",
    "    \"\"\"\n",
    "    x, y, w, h = face.bbox\n",
    "    h_img, w_img = frame_bgr.shape[:2]\n",
    "\n",
    "    x0 = max(0, x)\n",
    "    y0 = max(0, y)\n",
    "    x1 = min(w_img, x + w)\n",
    "    y1 = min(h_img, y + h)\n",
    "\n",
    "    face_bgr = frame_bgr[y0:y1, x0:x1]\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(face_rgb)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. AESTHETIC SCORE (STUB + EXAMPLE HEURISTIC)\n",
    "# -----------------------------------------------------------------------------\n",
    "def aesthetic_score(img) -> float:\n",
    "    \"\"\"\n",
    "    Mirror notebook logic: delegate to predict_aesthetic(img) and map to [0, 10].\n",
    "\n",
    "    - In the original notebook, predict_aesthetic expects a PIL Image (RGB).\n",
    "    - If we get a NumPy array (BGR from OpenCV), convert it to PIL RGB first.\n",
    "    \"\"\"\n",
    "    # If it's an OpenCV frame or cropped region (NumPy array)\n",
    "    if isinstance(img, np.ndarray):\n",
    "        # assume BGR and convert â†’ RGB PIL\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    elif isinstance(img, Image.Image):\n",
    "        # already PIL; ensure RGB\n",
    "        img = img.convert(\"RGB\")\n",
    "    else:\n",
    "        # Fallback: try to wrap whatever it is as PIL\n",
    "        img = Image.fromarray(np.array(img)).convert(\"RGB\")\n",
    "\n",
    "    # Notebook logic: just call the model and cast to float\n",
    "    score = predict_aesthetic(img)   # returns 0â€“10 in your original code\n",
    "    return float(score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. MULTI-CUE ATTRACTIVENESS FUSION\n",
    "# -----------------------------------------------------------------------------\n",
    "def multi_cue_attractiveness(\n",
    "    aesthetic_face_0_10: float,\n",
    "    aesthetic_full_0_10: float,\n",
    "    lighting_0_1: float,\n",
    "    sharpness_0_1: float,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Fuse cues exactly like the notebook:\n",
    "\n",
    "        0.65 * face aesthetic\n",
    "        0.20 * full-frame aesthetic\n",
    "        0.10 * lighting\n",
    "        0.05 * sharpness\n",
    "\n",
    "    Returns a 0â€“10 score.\n",
    "    \"\"\"\n",
    "    # Normalize aesthetics to [0, 1]\n",
    "    face_norm = np.clip((aesthetic_face_0_10 or 0.0) / 10.0, 0.0, 1.0)\n",
    "    full_norm = np.clip((aesthetic_full_0_10 or 0.0) / 10.0, 0.0, 1.0)\n",
    "\n",
    "    # Clamp lighting & sharpness\n",
    "    lt = np.clip(lighting_0_1 or 0.0, 0.0, 1.0)\n",
    "    sh = np.clip(sharpness_0_1 or 0.0, 0.0, 1.0)\n",
    "\n",
    "    score_0_1 = (\n",
    "        0.65 * face_norm +\n",
    "        0.20 * full_norm +\n",
    "        0.10 * lt +\n",
    "        0.05 * sh\n",
    "    )\n",
    "\n",
    "    score_0_1 = float(np.clip(score_0_1, 0.0, 1.0))\n",
    "    return score_0_1 * 10.0\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. MAIN ENTRYPOINT: compute_attractiveness_for_reel\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_attractiveness_for_reel(\n",
    "    video_path: str,\n",
    "    frames_per_reel: int = FRAMES_PER_REEL,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Standalone per-reel attractiveness computation.\n",
    "\n",
    "    Pipeline:\n",
    "      1. Sample frames from the video.\n",
    "      2. Pick the 'best' face frame (largest detected face).\n",
    "      3. Compute:\n",
    "         - lighting score                -> [0, 1]\n",
    "         - sharpness score               -> [0, 1]\n",
    "         - face_area_frac                -> (0, 1)\n",
    "         - center_offset_norm            -> [0, 1]\n",
    "         - aesthetic_face_0_10           -> [0, 10]\n",
    "         - aesthetic_full_0_10           -> [0, 10]\n",
    "         - multi_cue_attr_0_10           -> [0, 10] (fused)\n",
    "      4. Return all of the above as a dict.\n",
    "\n",
    "    If anything fails (no frames, no faces, etc.), returns NaNs.\n",
    "    \"\"\"\n",
    "    empty = {\n",
    "        \"best_frame_idx\": None,\n",
    "        \"lighting\": np.nan,\n",
    "        \"sharpness\": np.nan,\n",
    "        \"face_area_frac\": np.nan,\n",
    "        \"center_offset_norm\": np.nan,\n",
    "        \"aesthetic_face_0_10\": np.nan,\n",
    "        \"aesthetic_full_0_10\": np.nan,\n",
    "        \"multi_cue_attr_0_10\": np.nan,\n",
    "    }\n",
    "\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video path does not exist:\", video_path)\n",
    "        return empty\n",
    "\n",
    "    # 1) Sample frames\n",
    "    frames = sample_frames_from_video(video_path, max_frames=frames_per_reel)\n",
    "    if not frames:\n",
    "        print(\"    âœ— No frames sampled from video\")\n",
    "        return empty\n",
    "\n",
    "    # 2) Select best face frame\n",
    "    best_idx, best_frame, best_face = select_best_face_frame(frames)\n",
    "    if best_frame is None or best_face is None:\n",
    "        print(\"    âœ— No face detected in sampled frames\")\n",
    "        return empty\n",
    "\n",
    "    # 3) Visual cues\n",
    "    lighting = compute_lighting_score(best_frame)    # 0â€“1\n",
    "    sharpness = compute_sharpness_score(best_frame)  # 0â€“1\n",
    "    face_area_frac, center_offset_norm = face_cues(best_frame.shape, best_face.bbox)\n",
    "\n",
    "    # 4) Aesthetic scores (face + full frame)\n",
    "    face_img = crop_face(best_frame, best_face)      # PIL image\n",
    "    aest_face = aesthetic_score(face_img)            # 0â€“10\n",
    "    # full-frame aesthetic uses the whole frame\n",
    "    full_rgb = cv2.cvtColor(best_frame, cv2.COLOR_BGR2RGB)\n",
    "    full_img = Image.fromarray(full_rgb)\n",
    "    aest_full = aesthetic_score(full_img)            # 0â€“10\n",
    "\n",
    "    # 5) Fuse\n",
    "    fused_score = multi_cue_attractiveness(\n",
    "        aest_face,\n",
    "        aest_full,\n",
    "        lighting,\n",
    "        sharpness,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"best_frame_idx\": best_idx,\n",
    "        \"lighting\": float(lighting),\n",
    "        \"sharpness\": float(sharpness),\n",
    "        \"face_area_frac\": float(face_area_frac),\n",
    "        \"center_offset_norm\": float(center_offset_norm),\n",
    "        \"aesthetic_face_0_10\": float(aest_face),\n",
    "        \"aesthetic_full_0_10\": float(aest_full),\n",
    "        \"multi_cue_attr_0_10\": float(fused_score),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e38932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EYE CONTACT MODULE â€” standalone, matching eye_contact.ipynb\n",
    "# Produces: eye_contact_ratio, eye_contact_score_0_10\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Haar cascades (same as notebook)\n",
    "# -------------------------------------------------------------------------\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "eye_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_eye.xml\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. Per-frame eye-contact check (is_eye_contact_frame)\n",
    "# -------------------------------------------------------------------------\n",
    "def is_eye_contact_frame(frame_bgr: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    True if frame looks like creator is facing camera:\n",
    "      - frontal-ish face\n",
    "      - at least 2 reasonably aligned eyes\n",
    "    Logic mirrors eye_contact.ipynb.\n",
    "    \"\"\"\n",
    "    if frame_bgr is None:\n",
    "        return False\n",
    "\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(60, 60),\n",
    "    )\n",
    "    if len(faces) == 0:\n",
    "        return False\n",
    "\n",
    "    # Largest face â†’ assume this is the creator\n",
    "    x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "    face_roi = gray[y:y + h, x:x + w]\n",
    "\n",
    "    # Detect eyes inside the face ROI\n",
    "    eyes = eye_cascade.detectMultiScale(\n",
    "        face_roi,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=4,\n",
    "        minSize=(15, 15),\n",
    "    )\n",
    "    if len(eyes) < 2:\n",
    "        return False\n",
    "\n",
    "    # Use first two eyes\n",
    "    eye_centers = []\n",
    "    for (ex, ey, ew, eh) in eyes[:2]:\n",
    "        cx = ex + ew / 2.0\n",
    "        cy = ey + eh / 2.0\n",
    "        eye_centers.append((cx, cy))\n",
    "\n",
    "    if len(eye_centers) < 2:\n",
    "        return False\n",
    "\n",
    "    (cx1, cy1), (cx2, cy2) = eye_centers\n",
    "\n",
    "    # Horizontal distance between eyes vs face width\n",
    "    horiz_dist = abs(cx1 - cx2)\n",
    "    if horiz_dist < 0.2 * w:\n",
    "        # too close together â†’ probably not a valid frontal face\n",
    "        return False\n",
    "\n",
    "    # Vertical alignment: eyes roughly on same row\n",
    "    vert_diff = abs(cy1 - cy2)\n",
    "    if vert_diff > 0.25 * h:\n",
    "        # one eye much higher than the other â†’ tilted profile\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. Core logic: compute_eye_contact_ratio_from_video\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_eye_contact_ratio_from_video(\n",
    "    video_path: str,\n",
    "    frame_stride: int = 3,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Stream through a video, check every Nth frame for eye contact,\n",
    "    return (ratio, score_0_10).\n",
    "\n",
    "    This matches compute_eye_contact_ratio_from_video in eye_contact.ipynb:\n",
    "    - iterate over frames\n",
    "    - subsample by frame_stride\n",
    "    - ratio = eye_contact_frames / total_frames_considered\n",
    "    - score_0_10 = round(10 * ratio, 2)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    total_frames_considered = 0\n",
    "    eye_contact_frames = 0\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_idx += 1\n",
    "        if frame_idx % frame_stride != 0:\n",
    "            continue\n",
    "\n",
    "        total_frames_considered += 1\n",
    "        if is_eye_contact_frame(frame):\n",
    "            eye_contact_frames += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if total_frames_considered == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    ratio = eye_contact_frames / total_frames_considered\n",
    "    score_0_10 = round(10 * ratio, 2)\n",
    "    return float(ratio), float(score_0_10)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. Joint-pipeline wrapper: compute_eye_contact_for_reel\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_eye_contact_for_reel(\n",
    "    video_path: str,\n",
    "    frame_stride: int = 3,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Joint-pipeline friendly wrapper.\n",
    "\n",
    "    Uses the same ratio logic as eye_contact.ipynb, but:\n",
    "      - does NOT download/delete files\n",
    "      - returns a dict you can .update(row_out) with\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"eye_contact_ratio\": float,\n",
    "            \"eye_contact_score_0_10\": float\n",
    "        }\n",
    "    \"\"\"\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video path does not exist:\", video_path)\n",
    "        return {\n",
    "            \"eye_contact_ratio\": np.nan,\n",
    "            \"eye_contact_score_0_10\": np.nan,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        ratio, score = compute_eye_contact_ratio_from_video(\n",
    "            video_path,\n",
    "            frame_stride=frame_stride,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Eye-contact failed for {video_path}: {e}\")\n",
    "        return {\n",
    "            \"eye_contact_ratio\": np.nan,\n",
    "            \"eye_contact_score_0_10\": np.nan,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"eye_contact_ratio\": float(ratio),\n",
    "        \"eye_contact_score_0_10\": float(score),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd7f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP ViT-B/32 for creativity metrics on cpu\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATIVITY MODULE â€” matching creativity.ipynb\n",
    "# Produces per-reel: hist_score_0_10 (then per-creator mean_hist_score)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# How many frames per reel to use for creativity (same default as notebook)\n",
    "if \"MAX_FRAMES_PER_REEL\" not in globals():\n",
    "    MAX_FRAMES_PER_REEL = 16\n",
    "\n",
    "# Device + CLIP model (reuse if already loaded)\n",
    "if \"device\" not in globals():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = DEVICE\n",
    "if \"clip_model\" not in globals() or \"clip_preprocess\" not in globals():\n",
    "    print(\"Loading CLIP ViT-B/32 for creativity metrics on\", device)\n",
    "    clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=DEVICE)\n",
    "    clip_model.eval()\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1) Frame sampling (sample_uniform_frames from notebook)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def sample_uniform_frames_creativity(\n",
    "    video_path: str,\n",
    "    max_frames: int = MAX_FRAMES_PER_REEL,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample up to `max_frames` frames roughly uniformly across the video.\n",
    "    Returns: list of np.ndarray (BGR images)\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"    âœ— Could not open video for frame sampling.\")\n",
    "        return frames\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Fallback if metadata is broken\n",
    "    if frame_count <= 0:\n",
    "        print(\"    âš ï¸ CAP_PROP_FRAME_COUNT not available, reading sequentially.\")\n",
    "        i = 0\n",
    "        while i < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "            i += 1\n",
    "        cap.release()\n",
    "        print(f\"    âœ“ Sampled {len(frames)} frames (sequential fallback).\")\n",
    "        return frames\n",
    "\n",
    "    # Normal path: uniform indices\n",
    "    if frame_count <= max_frames:\n",
    "        indices = list(range(frame_count))\n",
    "    else:\n",
    "        indices = np.linspace(0, frame_count - 1, max_frames, dtype=int)\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"    âœ“ Sampled {len(frames)} frames (uniform across {frame_count} total).\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2) Histogram distance (compute_hist_distance from notebook)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def compute_hist_distance(frame1, frame2, bins: int = 16) -> float:\n",
    "    \"\"\"\n",
    "    Compute Bhattacharyya distance between color histograms of two frames.\n",
    "    Returns a float in [0, 1+] (0 = identical, larger = more different).\n",
    "    \"\"\"\n",
    "    # Convert to HSV (same as notebook)\n",
    "    f1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)\n",
    "    f2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h1 = cv2.calcHist(\n",
    "        [f1], [0, 1, 2], None,\n",
    "        [bins, bins, bins],\n",
    "        [0, 180, 0, 256, 0, 256],\n",
    "    )\n",
    "    h2 = cv2.calcHist(\n",
    "        [f2], [0, 1, 2], None,\n",
    "        [bins, bins, bins],\n",
    "        [0, 180, 0, 256, 0, 256],\n",
    "    )\n",
    "\n",
    "    h1 = h1.flatten().astype(\"float32\")\n",
    "    h2 = h2.flatten().astype(\"float32\")\n",
    "\n",
    "    h1 /= (h1.sum() + 1e-8)\n",
    "    h2 /= (h2.sum() + 1e-8)\n",
    "\n",
    "    dist = cv2.compareHist(h1, h2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "    return float(dist)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3) CLIP embedding helper (clip_embed_frame from notebook)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def clip_embed_frame(frame_bgr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute CLIP embedding (L2-normalized) for a single frame (BGR).\n",
    "    Returns 1D numpy vector.\n",
    "    \"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(frame_rgb)\n",
    "\n",
    "    img = clip_preprocess(pil_img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        emb = clip_model.encode_image(img)\n",
    "        emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return emb.cpu().numpy().flatten().astype(\"float32\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4) Core per-video metrics (compute_three_change_metrics_for_video)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def compute_three_change_metrics_for_video(\n",
    "    video_path: str,\n",
    "    max_frames: int = MAX_FRAMES_PER_REEL,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    For a given video:\n",
    "      - Sample frames\n",
    "      - Compute three frame-to-frame change metrics:\n",
    "          1) Scene-change density (hist-based threshold â†’ approx shot boundaries)\n",
    "          2) Mean CLIP embedding distance between consecutive frames\n",
    "          3) Mean histogram distance between consecutive frames\n",
    "      - Also returns normalized scores 0â€“10 for each metric.\n",
    "    \"\"\"\n",
    "    frames = sample_uniform_frames_creativity(video_path, max_frames=max_frames)\n",
    "    n_frames = len(frames)\n",
    "\n",
    "    if n_frames < 2:\n",
    "        return {\n",
    "            \"n_frames_used\": n_frames,\n",
    "            \"scene_change_count\": 0,\n",
    "            \"scene_change_density\": 0.0,\n",
    "            \"scene_score_0_10\": 0.0,\n",
    "            \"mean_clip_dist\": 0.0,\n",
    "            \"std_clip_dist\": 0.0,\n",
    "            \"clip_score_0_10\": 0.0,\n",
    "            \"mean_hist_dist\": 0.0,\n",
    "            \"std_hist_dist\": 0.0,\n",
    "            \"hist_score_0_10\": 0.0,\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # METHOD 3: Histogram diffs\n",
    "    # -------------------------\n",
    "    hist_dists = []\n",
    "    for i in range(1, n_frames):\n",
    "        d = compute_hist_distance(frames[i - 1], frames[i])\n",
    "        hist_dists.append(d)\n",
    "    hist_dists = np.array(hist_dists, dtype=np.float32)\n",
    "\n",
    "    mean_hist = float(hist_dists.mean())\n",
    "    std_hist = float(hist_dists.std())\n",
    "\n",
    "    # We'll assume typical Bhattacharyya distances are in [0, 1].\n",
    "    # Clip to [0,1] before mapping to 0â€“10\n",
    "    mean_hist_clipped = float(np.clip(mean_hist, 0.0, 1.0))\n",
    "    hist_score = round(mean_hist_clipped * 10.0, 2)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # METHOD 1: Scene-change density\n",
    "    # -----------------------------------\n",
    "    scene_thresh = 0.5\n",
    "    scene_changes = int((hist_dists > scene_thresh).sum())\n",
    "    scene_change_density = scene_changes / float(n_frames - 1)\n",
    "\n",
    "    # Normalise density (5Ã— scaling heuristic) then map to 0â€“10\n",
    "    scene_density_clipped = float(\n",
    "        np.clip(scene_change_density * 5.0, 0.0, 1.0)\n",
    "    )\n",
    "    scene_score = round(scene_density_clipped * 10.0, 2)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # METHOD 2: CLIP embedding distances\n",
    "    # -----------------------------------\n",
    "    clip_embs = []\n",
    "    for f in frames:\n",
    "        e = clip_embed_frame(f)\n",
    "        clip_embs.append(e)\n",
    "    clip_embs = np.stack(clip_embs, axis=0)  # [n_frames, d]\n",
    "\n",
    "    # compute distances between consecutive embeddings\n",
    "    clip_dists = []\n",
    "    for i in range(1, n_frames):\n",
    "        v1 = clip_embs[i - 1]\n",
    "        v2 = clip_embs[i]\n",
    "        # Since vectors are normalized, 1 - cosine similarity âˆˆ [0, 2]\n",
    "        cos_sim = float(np.dot(v1, v2))\n",
    "        d = 1.0 - cos_sim\n",
    "        clip_dists.append(d)\n",
    "    clip_dists = np.array(clip_dists, dtype=np.float32)\n",
    "\n",
    "    mean_clip = float(clip_dists.mean())\n",
    "    std_clip = float(clip_dists.std())\n",
    "\n",
    "    # Clip-sim distance is usually within [0, 1]; clip to [0,1]\n",
    "    mean_clip_clipped = float(np.clip(mean_clip, 0.0, 1.0))\n",
    "    clip_score = round(mean_clip_clipped * 10.0, 2)\n",
    "\n",
    "    return {\n",
    "        \"n_frames_used\": n_frames,\n",
    "        # scene-based\n",
    "        \"scene_change_count\": int(scene_changes),\n",
    "        \"scene_change_density\": float(scene_change_density),\n",
    "        \"scene_score_0_10\": scene_score,\n",
    "        # CLIP-based\n",
    "        \"mean_clip_dist\": mean_clip,\n",
    "        \"std_clip_dist\": std_clip,\n",
    "        \"clip_score_0_10\": clip_score,\n",
    "        # histogram-based\n",
    "        \"mean_hist_dist\": mean_hist,\n",
    "        \"std_hist_dist\": std_hist,\n",
    "        \"hist_score_0_10\": hist_score,\n",
    "    }\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 5) Wrapper used by the joint pipeline\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def compute_creativity_for_reel(video_path: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Joint-pipeline friendly wrapper, adapted from run_change_metrics_pipeline_for_creators.\n",
    "\n",
    "    - Takes a local video_path (already downloaded by the orchestrator).\n",
    "    - Computes all three change metrics using compute_three_change_metrics_for_video.\n",
    "    - Returns hist_score_0_10 (your creativity metric) plus other scores.\n",
    "\n",
    "    This mirrors the logic that ends up producing mean_hist_score in df_creator_agg:\n",
    "        mean_hist_score = mean of per-reel hist_score_0_10.\n",
    "    \"\"\"\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video path does not exist:\", video_path)\n",
    "        return {\n",
    "            \"scene_score_0_10\": 0.0,\n",
    "            \"clip_score_0_10\": 0.0,\n",
    "            \"hist_score_0_10\": 0.0,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        metrics = compute_three_change_metrics_for_video(\n",
    "            video_path,\n",
    "            max_frames=MAX_FRAMES_PER_REEL,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Error during creativity metrics: {repr(e)}\")\n",
    "        metrics = {\n",
    "            \"n_frames_used\": 0,\n",
    "            \"scene_change_count\": 0,\n",
    "            \"scene_change_density\": 0.0,\n",
    "            \"scene_score_0_10\": 0.0,\n",
    "            \"mean_clip_dist\": 0.0,\n",
    "            \"std_clip_dist\": 0.0,\n",
    "            \"clip_score_0_10\": 0.0,\n",
    "            \"mean_hist_dist\": 0.0,\n",
    "            \"std_hist_dist\": 0.0,\n",
    "            \"hist_score_0_10\": 0.0,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"scene_score_0_10\": metrics[\"scene_score_0_10\"],\n",
    "        \"clip_score_0_10\": metrics[\"clip_score_0_10\"],\n",
    "        \"hist_score_0_10\": metrics[\"hist_score_0_10\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f442440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SEQUENTIAL MODULE â€” detect_series_from_text (adapted from sequential.ipynb)\n",
    "# =============================================================================\n",
    "\n",
    "import re\n",
    "from typing import Optional, Dict\n",
    "\n",
    "# --- same keywords as notebook ---\n",
    "SERIES_KEYWORDS = [\n",
    "    r\"\\bseries\\b\",\n",
    "    r\"\\bserie\\b\",\n",
    "    r\"\\bepisode\\b\",\n",
    "    r\"\\bep\\b\",\n",
    "    r\"\\bpart\\b\",\n",
    "    r\"\\bpt\\b\",\n",
    "    r\"\\bseason\\b\",\n",
    "]\n",
    "\n",
    "# --- same episode patterns as notebook ---\n",
    "EP_PATTERNS = [\n",
    "    r\"(?:episode|ep|ep\\.)\\s*(\\d+)\",\n",
    "    r\"(?:part|pt|pt\\.)\\s*(\\d+)\",\n",
    "    r\"s(?:eason)?\\s*\\d+\\s*(?:episode|ep)\\s*(\\d+)\",\n",
    "]\n",
    "\n",
    "def clean(t: Optional[str]) -> str:\n",
    "    \"\"\"Lowercase and collapse whitespace, exactly like `clean` in the notebook.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", t.lower()).strip() if isinstance(t, str) else \"\"\n",
    "\n",
    "\n",
    "def detect_series_from_text(caption: str, transcript: str) -> Dict[str, Optional[int]]:\n",
    "    \"\"\"\n",
    "    Same logic as `detect_series(caption, transcript)` in sequential.ipynb.\n",
    "\n",
    "    Inputs:\n",
    "        caption    - raw reel caption string\n",
    "        transcript - Whisper transcript string\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"series_flag\": 0 or 1,\n",
    "          \"matched_keywords\": \"pipe|separated|hits\",\n",
    "          \"episode_number\": int or None\n",
    "        }\n",
    "    \"\"\"\n",
    "    c = clean(caption)\n",
    "    t = clean(transcript)\n",
    "    combined = c + \" \" + t\n",
    "\n",
    "    # --- keyword hit ---\n",
    "    matched = [kw for kw in SERIES_KEYWORDS if re.search(kw, combined)]\n",
    "    is_series = len(matched) > 0\n",
    "\n",
    "    # --- extract episode/part number ---\n",
    "    epi = None\n",
    "    for p in EP_PATTERNS:\n",
    "        m = re.search(p, combined)\n",
    "        if m:\n",
    "            try:\n",
    "                epi = int(m.group(1))\n",
    "                break\n",
    "            except:\n",
    "                # bare except to mirror notebook behaviour\n",
    "                pass\n",
    "\n",
    "    return {\n",
    "        \"series_flag\": 1 if is_series else 0,\n",
    "        \"matched_keywords\": \"|\".join(matched) if matched else \"\",\n",
    "        \"episode_number\": epi,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb97c364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EasyOCR reader initialised for caption detection.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VIDEO CAPTION MODULE â€” adapted from video_caption_detector.ipynb\n",
    "# Produces per-reel:\n",
    "#   has_dynamic_captions (0/1)\n",
    "#   caption_style: \"none\" | \"static\" | \"dynamic\"\n",
    "#   num_segments\n",
    "#   caption_coverage\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import difflib\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from easyocr import Reader\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# GLOBAL CONFIG (mirrors the notebook)\n",
    "# -------------------------------------------------------------------------\n",
    "# MAX_REELS_PER_CREATOR = 5           # how many reels per creator to check\n",
    "TARGET_FPS = 3                       # how many frames per second to sample\n",
    "BOTTOM_CROP_RATIO = 0.4              # bottom X% of frame considered \"caption band\"\n",
    "MIN_TEXT_LEN = 3                     # min OCR text length to keep\n",
    "SIMILARITY_SAME_SEGMENT = 0.6        # similarity threshold => same caption segment\n",
    "MIN_SEGMENT_DURATION = 0.0           # seconds; ignore too-short blips if > 0\n",
    "MAX_SEGMENT_DURATION = 15.0          # cap on segment duration\n",
    "CAPTION_MIN_COVERAGE = 0.05          # <5% coverage â†’ treat as \"no captions\"\n",
    "STATIC_OVERLAY_MAX_SEGMENTS = 2      # <= this & dominant = static overlay\n",
    "STATIC_DOMINANCE_RATIO = 0.7         # one segment dominates >70% of caption time\n",
    "\n",
    "# Init EasyOCR (same as notebook â€” CPU)\n",
    "ocr = Reader(['en'], gpu=False if DEVICE == 'cpu' else True)\n",
    "print(\"EasyOCR reader initialised for caption detection.\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Sample bottom frames from a reel (Cell 3 logic)\n",
    "# -------------------------------------------------------------------------\n",
    "def sample_bottom_frames(\n",
    "    video_path: str,\n",
    "    target_fps: float = TARGET_FPS,\n",
    "    bottom_ratio: float = BOTTOM_CROP_RATIO,\n",
    ") -> Tuple[List[Tuple[float, Any]], float]:\n",
    "    \"\"\"\n",
    "    Open a video, sample frames at target_fps, and return:\n",
    "      frames:   list of (time_sec, cropped_bottom_frame)\n",
    "      duration: total video duration in seconds\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return [], 0.0\n",
    "\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS) or 0.0\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "\n",
    "    if original_fps <= 0.0:\n",
    "        # fallback: assume 30 fps to avoid div-by-zero\n",
    "        original_fps = 30.0\n",
    "\n",
    "    duration = frame_count / original_fps if frame_count > 0 else 0.0\n",
    "\n",
    "    # how many frames to skip between samples\n",
    "    frame_step = max(1, int(round(original_fps / max(target_fps, 0.1))))\n",
    "\n",
    "    frames: List[Tuple[float, Any]] = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_step == 0:\n",
    "            h, w = frame.shape[:2]\n",
    "            y0 = int(h * (1.0 - bottom_ratio))\n",
    "            cropped = frame[y0:h, 0:w]\n",
    "\n",
    "            t_sec = frame_idx / original_fps\n",
    "            frames.append((t_sec, cropped))\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames, float(duration)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. OCR on a bottom frame (Cell 4 logic, defensive)\n",
    "# -------------------------------------------------------------------------\n",
    "def ocr_caption_text(frame_bgr) -> str:\n",
    "    \"\"\"\n",
    "    Run OCR using EasyOCR on a bottom-band BGR frame.\n",
    "    Returns a cleaned, lowercased text string (or \"\" if none / error).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # EasyOCR expects an RGB numpy array\n",
    "        results = ocr.readtext(frame_rgb, detail=1)\n",
    "\n",
    "        if not results:\n",
    "            return \"\"\n",
    "\n",
    "        texts = []\n",
    "        for item in results:\n",
    "            # EasyOCR sometimes returns (bbox, text, conf) or [bbox, text, conf]\n",
    "            if not isinstance(item, (list, tuple)) or len(item) < 2:\n",
    "                continue\n",
    "            text = item[1]\n",
    "            if not isinstance(text, str):\n",
    "                continue\n",
    "\n",
    "            text_clean = text.strip()\n",
    "            if len(text_clean) < MIN_TEXT_LEN:\n",
    "                continue\n",
    "\n",
    "            texts.append(text_clean)\n",
    "\n",
    "        if not texts:\n",
    "            return \"\"\n",
    "\n",
    "        joined = \" \".join(texts)\n",
    "        joined = joined.lower()\n",
    "        joined = \" \".join(joined.split())\n",
    "        return joined\n",
    "\n",
    "    except Exception:\n",
    "        # Frame-level OCR errors should not kill the whole reel\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. Build caption timeline for a video (Cell 5)\n",
    "# -------------------------------------------------------------------------\n",
    "def build_caption_timeline(video_path: str) -> Tuple[List[Tuple[float, str]], float]:\n",
    "    \"\"\"\n",
    "    For a video:\n",
    "      1. Sample frames from the bottom band.\n",
    "      2. OCR each sampled frame.\n",
    "\n",
    "    Returns:\n",
    "      timeline: list of (time_sec, text) (text may be \"\")\n",
    "      duration: total video duration in seconds\n",
    "    \"\"\"\n",
    "    frames, duration = sample_bottom_frames(video_path)\n",
    "    if not frames or duration <= 0:\n",
    "        return [], 0.0\n",
    "\n",
    "    timeline: List[Tuple[float, str]] = []\n",
    "    for t_sec, frame in frames:\n",
    "        if frame is None:\n",
    "            timeline.append((t_sec, \"\"))\n",
    "            continue\n",
    "        text = ocr_caption_text(frame)\n",
    "        timeline.append((t_sec, text))\n",
    "\n",
    "    return timeline, duration\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. Convert timeline â†’ logical caption segments (Cell 6)\n",
    "# -------------------------------------------------------------------------\n",
    "def text_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"Simple normalized similarity between two strings in [0, 1].\"\"\"\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def timeline_to_segments(\n",
    "    timeline: List[Tuple[float, str]],\n",
    "    duration: float,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert (time, text) timeline into segments where text is mostly the same.\n",
    "    Each segment:\n",
    "        {\"text\": str, \"start\": float, \"end\": float}\n",
    "    \"\"\"\n",
    "    if not timeline or duration <= 0:\n",
    "        return []\n",
    "\n",
    "    segments: List[Dict[str, Any]] = []\n",
    "\n",
    "    current_text: str | None = None\n",
    "    current_start: float | None = None\n",
    "    last_time: float | None = None\n",
    "\n",
    "    for item in timeline:\n",
    "        # Extra defensive unpack (matches notebook style)\n",
    "        if not isinstance(item, (list, tuple)) or len(item) != 2:\n",
    "            continue\n",
    "        t_sec, raw_text = item\n",
    "        text = (raw_text or \"\").strip()\n",
    "        if len(text) < MIN_TEXT_LEN:\n",
    "            text = \"\"\n",
    "\n",
    "        # If we have no active segment yet\n",
    "        if current_text is None:\n",
    "            if text:\n",
    "                current_text = text\n",
    "                current_start = t_sec\n",
    "                last_time = t_sec\n",
    "            else:\n",
    "                last_time = t_sec\n",
    "            continue\n",
    "\n",
    "        # We are in a segment already\n",
    "        sim = text_similarity(text, current_text) if text and current_text else 0.0\n",
    "\n",
    "        if text and sim >= SIMILARITY_SAME_SEGMENT:\n",
    "            # same logical caption, extend segment\n",
    "            last_time = t_sec\n",
    "        else:\n",
    "            # close previous segment\n",
    "            end_time = last_time if last_time is not None else t_sec\n",
    "            seg_duration = max(0.0, end_time - (current_start or 0.0))\n",
    "            if seg_duration >= MIN_SEGMENT_DURATION and current_text:\n",
    "                segments.append(\n",
    "                    {\n",
    "                        \"text\": current_text,\n",
    "                        \"start\": current_start,\n",
    "                        \"end\": min(end_time, duration),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # start new segment if there is new text; otherwise reset\n",
    "            if text:\n",
    "                current_text = text\n",
    "                current_start = t_sec\n",
    "                last_time = t_sec\n",
    "            else:\n",
    "                current_text = None\n",
    "                current_start = None\n",
    "                last_time = t_sec\n",
    "\n",
    "    # close final open segment\n",
    "    if current_text is not None and current_start is not None:\n",
    "        end_time = last_time if last_time is not None else duration\n",
    "        seg_duration = max(0.0, end_time - current_start)\n",
    "        if seg_duration >= MIN_SEGMENT_DURATION:\n",
    "            segments.append(\n",
    "                {\n",
    "                    \"text\": current_text,\n",
    "                    \"start\": current_start,\n",
    "                    \"end\": min(end_time, duration),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Clip extremely long segments\n",
    "    for seg in segments:\n",
    "        if seg[\"end\"] - seg[\"start\"] > MAX_SEGMENT_DURATION:\n",
    "            seg[\"end\"] = seg[\"start\"] + MAX_SEGMENT_DURATION\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5. Classify: dynamic captions vs static vs none (Cell 7)\n",
    "# -------------------------------------------------------------------------\n",
    "def classify_caption_style(\n",
    "    segments: List[Dict[str, Any]],\n",
    "    duration: float,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Decide if the reel has dynamic captions, static overlay, or no captions.\n",
    "\n",
    "    Returns dict with:\n",
    "      has_dynamic_captions: bool\n",
    "      style: \"none\" | \"static\" | \"dynamic\"\n",
    "      num_segments\n",
    "      caption_coverage\n",
    "      segments (for debugging / inspection)\n",
    "    \"\"\"\n",
    "    if duration <= 0 or not segments:\n",
    "        return {\n",
    "            \"has_dynamic_captions\": False,\n",
    "            \"style\": \"none\",\n",
    "            \"num_segments\": 0,\n",
    "            \"caption_coverage\": 0.0,\n",
    "            \"segments\": [],\n",
    "        }\n",
    "\n",
    "    # compute durations per segment\n",
    "    seg_durations = []\n",
    "    total_caption_time = 0.0\n",
    "    for seg in segments:\n",
    "        d = max(0.0, float(seg[\"end\"] - seg[\"start\"]))\n",
    "        seg_durations.append(d)\n",
    "        total_caption_time += d\n",
    "\n",
    "    if total_caption_time <= 0.0:\n",
    "        return {\n",
    "            \"has_dynamic_captions\": False,\n",
    "            \"style\": \"none\",\n",
    "            \"num_segments\": len(segments),\n",
    "            \"caption_coverage\": 0.0,\n",
    "            \"segments\": segments,\n",
    "        }\n",
    "\n",
    "    caption_coverage = float(total_caption_time / duration)\n",
    "    num_segments = len(segments)\n",
    "\n",
    "    # Very tiny coverage â†’ treat as no captions (hard-coded 5% in notebook)\n",
    "    if caption_coverage < CAPTION_MIN_COVERAGE:\n",
    "        return {\n",
    "            \"has_dynamic_captions\": False,\n",
    "            \"style\": \"none\",\n",
    "            \"num_segments\": num_segments,\n",
    "            \"caption_coverage\": caption_coverage,\n",
    "            \"segments\": segments,\n",
    "        }\n",
    "\n",
    "    dominant_ratio = max(seg_durations) / total_caption_time if total_caption_time > 0 else 0.0\n",
    "\n",
    "    # Heuristic:\n",
    "    # - if one segment dominates and there are few segments â†’ static overlay\n",
    "    # - otherwise â†’ dynamic captions\n",
    "    if num_segments <= STATIC_OVERLAY_MAX_SEGMENTS and dominant_ratio >= STATIC_DOMINANCE_RATIO:\n",
    "        style = \"static\"\n",
    "        has_dynamic = False\n",
    "    else:\n",
    "        style = \"dynamic\"\n",
    "        has_dynamic = True\n",
    "\n",
    "    return {\n",
    "        \"has_dynamic_captions\": has_dynamic,\n",
    "        \"style\": style,\n",
    "        \"num_segments\": num_segments,\n",
    "        \"caption_coverage\": caption_coverage,\n",
    "        \"segments\": segments,\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_reel_captions(video_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Wrapper: given a local mp4 path, compute dynamic caption classification.\n",
    "    \"\"\"\n",
    "    timeline, duration = build_caption_timeline(video_path)\n",
    "    segments = timeline_to_segments(timeline, duration)\n",
    "    classification = classify_caption_style(segments, duration)\n",
    "    classification[\"duration\"] = duration\n",
    "    return classification\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 6. Entry for the joint pipeline: compute_video_caption_flag_for_reel\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_video_caption_flag_for_reel(video_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Joint-pipeline friendly wrapper.\n",
    "\n",
    "    Input:\n",
    "        video_path: local path to the reel mp4 (already downloaded once)\n",
    "\n",
    "    Output dict (per reel):\n",
    "        {\n",
    "          \"has_dynamic_captions\": 0/1,\n",
    "          \"caption_style\": \"none\" | \"static\" | \"dynamic\",\n",
    "          \"num_segments\": int,\n",
    "          \"caption_coverage\": float,   # 0â€“1\n",
    "        }\n",
    "    \"\"\"\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video path does not exist:\", video_path)\n",
    "        return {\n",
    "            \"has_dynamic_captions\": np.nan,\n",
    "            \"caption_style\": \"none\",\n",
    "            \"num_segments\": 0,\n",
    "            \"caption_coverage\": np.nan,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        info = analyze_reel_captions(video_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Caption detection failed for {video_path}: {e}\")\n",
    "        return {\n",
    "            \"has_dynamic_captions\": np.nan,\n",
    "            \"caption_style\": \"none\",\n",
    "            \"num_segments\": 0,\n",
    "            \"caption_coverage\": np.nan,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        # original notebook keeps this as bool; we cast to int for easy averaging\n",
    "        \"has_dynamic_captions\": int(bool(info.get(\"has_dynamic_captions\", False))),\n",
    "        \"caption_style\": info.get(\"style\", \"none\"),\n",
    "        \"num_segments\": int(info.get(\"num_segments\", 0)),\n",
    "        \"caption_coverage\": float(info.get(\"caption_coverage\", 0.0)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2524d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ACCESSORIES MODULE â€” MATCHES accessories2.ipynb LOGIC (per-reel part)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- classes & buckets: same as accessories2.ipynb ---\n",
    "\n",
    "ACCESSORY_CLASSES = [\n",
    "    \"backpack\",\"handbag\",\"hat\",\"scarf\",\"sunglasses\",\"glasses\",\n",
    "    \"necklace\",\"earrings\",\"watch\",\"bracelet\",\"ring\",\"wallet\",\"belt\",\n",
    "    \"mobile_phone\",\"laptop\",\"tablet\",\"smartwatch\",\"headphones\",\"camera\",\n",
    "    \"car\",\"sports_car\",\"motorcycle\",\"bike\",\"airplane\",\"boat\",\n",
    "    \"suitcase\",\"luggage\",\"surfboard\",\"skis\",\"horse\",\n",
    "    \"dress\",\"coat\",\"suit\",\"high_heels\",\n",
    "]\n",
    "\n",
    "CLASS_BUCKET = {\n",
    "    \"backpack\":     \"travel_gear\",\n",
    "    \"handbag\":      \"travel_gear\",\n",
    "    \"suitcase\":     \"travel_gear\",\n",
    "    \"luggage\":      \"travel_gear\",\n",
    "    \"surfboard\":    \"travel_gear\",\n",
    "    \"skis\":         \"travel_gear\",\n",
    "\n",
    "    \"hat\":          \"clothing\",\n",
    "    \"scarf\":        \"clothing\",\n",
    "    \"dress\":        \"clothing\",\n",
    "    \"coat\":         \"clothing\",\n",
    "    \"suit\":         \"clothing\",\n",
    "    \"belt\":         \"clothing\",\n",
    "    \"high_heels\":   \"clothing\",\n",
    "\n",
    "    \"necklace\":     \"jewellery\",\n",
    "    \"earrings\":     \"jewellery\",\n",
    "    \"watch\":        \"jewellery\",\n",
    "    \"bracelet\":     \"jewellery\",\n",
    "    \"ring\":         \"jewellery\",\n",
    "\n",
    "    \"mobile_phone\": \"gadgets\",\n",
    "    \"laptop\":       \"gadgets\",\n",
    "    \"tablet\":       \"gadgets\",\n",
    "    \"smartwatch\":   \"gadgets\",\n",
    "    \"headphones\":   \"gadgets\",\n",
    "    \"camera\":       \"gadgets\",\n",
    "\n",
    "    \"car\":          \"vehicles\",\n",
    "    \"sports_car\":   \"vehicles\",\n",
    "    \"motorcycle\":   \"vehicles\",\n",
    "    \"bike\":         \"vehicles\",\n",
    "    \"airplane\":     \"vehicles\",\n",
    "    \"boat\":         \"vehicles\",\n",
    "    \"horse\":        \"vehicles\",\n",
    "    \"sunglasses\":   \"clothing\",\n",
    "    \"glasses\":      \"clothing\",\n",
    "}\n",
    "\n",
    "for cls in ACCESSORY_CLASSES:\n",
    "    CLASS_BUCKET.setdefault(cls, \"other\")\n",
    "\n",
    "BUCKET_NAMES = sorted(set(CLASS_BUCKET.values()))\n",
    "\n",
    "# --- model singleton (same weights as accessories2) ---\n",
    "\n",
    "ACCESSORIES_MODEL_PATH = os.path.join(\"models\", \"accessories_best.pt\")\n",
    "ACCESSORIES_DEVICE = 0 if USE_GPU else \"cpu\"   # YOLO expects 0,1,... or \"cpu\"\n",
    "ACCESSORIES_DEVICE = DEVICE\n",
    "_accessories_model = None\n",
    "\n",
    "def get_accessories_model() -> YOLO:\n",
    "    global _accessories_model\n",
    "    if _accessories_model is None:\n",
    "        print(f\"Loading accessories YOLO model from {ACCESSORIES_MODEL_PATH} ...\")\n",
    "        _accessories_model = YOLO(ACCESSORIES_MODEL_PATH)\n",
    "    return _accessories_model\n",
    "\n",
    "\n",
    "# --- exact same idea as count_accessories_in_video (UNIQUE objects per reel) ---\n",
    "\n",
    "def _unique_accessories_in_video(\n",
    "    video_path: str,\n",
    "    model: YOLO,\n",
    "    frame_sample_rate: int = 5,\n",
    "    conf: float = 0.35,\n",
    "    iou_threshold: float = 0.5,\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count UNIQUE accessories in a reel (same IoU-based logic as accessories2.ipynb).\n",
    "    One physical object is counted once even if it appears in many frames.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video path does not exist:\", video_path)\n",
    "        return {}\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"    âœ— Cannot open video:\", video_path)\n",
    "        return {}\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    step = max(1, int(round(fps / frame_sample_rate)))\n",
    "\n",
    "    seen_boxes = defaultdict(list)  # class_name -> list of [x1,y1,x2,y2]\n",
    "\n",
    "    def iou(boxA, boxB):\n",
    "        xA = max(boxA[0], boxB[0])\n",
    "        yA = max(boxA[1], boxB[1])\n",
    "        xB = min(boxA[2], boxB[2])\n",
    "        yB = min(boxA[3], boxB[3])\n",
    "\n",
    "        inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "        if inter <= 0:\n",
    "            return 0.0\n",
    "\n",
    "        areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "        areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "        return inter / float(areaA + areaB - inter + 1e-8)\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % step != 0:\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            results = model.predict(source=frame, imgsz=640, conf=conf, verbose=False, device = DEVICE)\n",
    "        except TypeError:\n",
    "            results = model(frame, device = DEVICE)\n",
    "\n",
    "        if not results:\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "\n",
    "        r = results[0]\n",
    "        if getattr(r, \"boxes\", None) is None or len(r.boxes) == 0:\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "\n",
    "        for box, cls_id in zip(r.boxes.xyxy.cpu().numpy(),\n",
    "                               r.boxes.cls.cpu().numpy().astype(int)):\n",
    "            name = model.names[int(cls_id)]\n",
    "            if name not in ACCESSORY_CLASSES:\n",
    "                continue\n",
    "\n",
    "            is_new = True\n",
    "            for prev_box in seen_boxes[name]:\n",
    "                if iou(box, prev_box) > iou_threshold:\n",
    "                    is_new = False\n",
    "                    break\n",
    "            if is_new:\n",
    "                seen_boxes[name].append(box)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    class_counts = {cls: len(seen_boxes[cls]) for cls in ACCESSORY_CLASSES}\n",
    "    total = sum(class_counts.values())\n",
    "    class_counts[\"total_accessories\"] = total\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "def compute_accessories_for_reel(video_path: str) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Joint-pipeline wrapper, but logic mirrors accessories2.ipynb:\n",
    "\n",
    "    - Load YOLO accessories model once.\n",
    "    - Count UNIQUE objects per class in this reel.\n",
    "    - Return raw class counts + total_accessories.\n",
    "    (Bucket-level aggregations are handled later at per-creator aggregation.)\n",
    "    \"\"\"\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video path does not exist:\", video_path)\n",
    "        zeros = {cls: 0 for cls in ACCESSORY_CLASSES}\n",
    "        zeros[\"total_accessories\"] = 0\n",
    "        return zeros\n",
    "\n",
    "    model = get_accessories_model()\n",
    "\n",
    "    try:\n",
    "        counts = _unique_accessories_in_video(video_path, model=model)\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Error in accessories YOLO for {video_path}: {e}\")\n",
    "        counts = {}\n",
    "\n",
    "    # Ensure all classes present, even if 0\n",
    "    out = {cls: int(counts.get(cls, 0)) for cls in ACCESSORY_CLASSES}\n",
    "    out[\"total_accessories\"] = int(counts.get(\"total_accessories\", sum(out.values())))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1559b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COLOURS2 MODULE â€” SUN EXPOSURE (standalone, matching colours2.ipynb)\n",
    "# Produces: sun_exposure_raw_A (0â€“âˆž) and sun_exposure_0_10_A (0â€“10)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color  # used for Lab chroma\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 0. Config\n",
    "# -------------------------------------------------------------------------\n",
    "# In the original notebook, 5 frames per reel are used for sun exposure.\n",
    "FRAMES_PER_REEL_SUN = 5\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Frame sampling (sample_video_frames from notebook)\n",
    "# -------------------------------------------------------------------------\n",
    "def sample_video_frames(\n",
    "    video_path: str,\n",
    "    num_frames: int = FRAMES_PER_REEL_SUN,\n",
    "    min_valid_frames: int = 3,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Sample ~num_frames frames from a video, spread across the duration.\n",
    "    Frames are returned in BGR (OpenCV) format.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[WARN] Could not open video: {video_path}\")\n",
    "        return []\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_count <= 0:\n",
    "        print(f\"[WARN] No frames detected in: {video_path}\")\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    indices = np.linspace(0, frame_count - 1,\n",
    "                          num=min(num_frames, frame_count),\n",
    "                          dtype=int)\n",
    "    frames: List[np.ndarray] = []\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < min_valid_frames:\n",
    "        print(f\"[WARN] Only {len(frames)} valid frames from {video_path}\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. MHCC-style illuminant estimation (from notebook)\n",
    "# -------------------------------------------------------------------------\n",
    "def _safe_mean_channel(image_rgb: np.ndarray, p: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generalized mean per channel for Shades-of-Grey.\n",
    "    image_rgb in [0,1].\n",
    "    \"\"\"\n",
    "    eps = 1e-6\n",
    "    img = np.clip(image_rgb.astype(np.float32), 0.0, 1.0)\n",
    "    if p == 1.0:\n",
    "        return img.mean(axis=(0, 1))\n",
    "    return (np.power(img, p).mean(axis=(0, 1)) + eps) ** (1.0 / p)\n",
    "\n",
    "\n",
    "def estimate_illuminant_mhcc_style(frame_bgr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Estimate illuminant using a multi-hypothesis color constancy approach.\n",
    "    Returns RGB vector in [0,1] (approx).\n",
    "    \"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    frame_rgb /= 255.0\n",
    "\n",
    "    # Candidate 1: Gray-World\n",
    "    gw = _safe_mean_channel(frame_rgb, p=1.0)\n",
    "\n",
    "    # Candidate 2: White-Patch (top 5% brightest pixels)\n",
    "    gray = cv2.cvtColor((frame_rgb * 255).astype(np.uint8),\n",
    "                        cv2.COLOR_RGB2GRAY)\n",
    "    thresh = np.percentile(gray, 95)\n",
    "    mask = gray >= thresh\n",
    "    if mask.sum() > 0:\n",
    "        wp = frame_rgb[mask].mean(axis=0)\n",
    "    else:\n",
    "        wp = gw\n",
    "\n",
    "    # Candidate 3 & 4: Shades-of-Grey with different p\n",
    "    sog4 = _safe_mean_channel(frame_rgb, p=4.0)\n",
    "    sog6 = _safe_mean_channel(frame_rgb, p=6.0)\n",
    "\n",
    "    candidates = np.stack([gw, wp, sog4, sog6], axis=0)\n",
    "\n",
    "    # Score each candidate via achromaticity in Lab\n",
    "    scores = []\n",
    "    for illum in candidates:\n",
    "        eps = 1e-6\n",
    "        illum_n = np.maximum(illum.astype(np.float32), eps)\n",
    "        illum_n = illum_n / illum_n.max()\n",
    "\n",
    "        corrected = frame_rgb / illum_n[None, None, :]\n",
    "        corrected = np.clip(corrected, 0.0, 1.0)\n",
    "\n",
    "        lab = color.rgb2lab(corrected)\n",
    "        a = lab[:, :, 1]\n",
    "        b = lab[:, :, 2]\n",
    "        chroma = np.sqrt(a * a + b * b)\n",
    "        scores.append(chroma.mean())\n",
    "\n",
    "    best_idx = int(np.argmin(scores))\n",
    "    best_illum = candidates[best_idx]\n",
    "    return best_illum  # roughly [0,1]\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. Video quality + outdoor cues (from notebook)\n",
    "# -------------------------------------------------------------------------\n",
    "def estimate_video_quality(frame_bgr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Estimate video quality using:\n",
    "      - sharpness (Laplacian variance)\n",
    "      - noise level\n",
    "      - compression/blockiness (DCT high-frequency energy)\n",
    "    Returns: quality score in [0,1].\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Sharpness\n",
    "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    sharp = min(1.0, lap_var / 500.0)\n",
    "\n",
    "    # Noise\n",
    "    noise = np.std(\n",
    "        gray.astype(np.float32) - cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    )\n",
    "    noise_norm = min(1.0, noise / 30.0)\n",
    "\n",
    "    # Compression / blockiness via DCT high frequency\n",
    "    h, w = gray.shape\n",
    "    patch = gray[h // 4:h // 4 + 64, w // 4:w // 4 + 64]\n",
    "    patch_f = np.float32(patch) / 255.0\n",
    "    dct = cv2.dct(patch_f)\n",
    "    high_freq_energy = np.mean(np.abs(dct[20:, 20:]))\n",
    "    compression_norm = min(1.0, high_freq_energy * 5.0)\n",
    "\n",
    "    quality = 0.5 * sharp + 0.3 * compression_norm + 0.2 * noise_norm\n",
    "    return float(np.clip(quality, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def compute_outdoor_cues(frame_bgr: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Heuristic outdoor cues: sky, greenery, shadow contrast.\n",
    "    \"\"\"\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    Hn = (H.astype(np.float32) / 179.0 * 360.0)  # hue in degrees\n",
    "\n",
    "    # sky in top 1/3 of frame\n",
    "    top_band = int(h * 0.33)\n",
    "    sky_mask = ((Hn > 190) & (Hn < 250) & (S > 40) & (V > 140))\n",
    "    sky_score = float(sky_mask[:top_band, :].mean())\n",
    "\n",
    "    # greenery anywhere\n",
    "    green_mask = ((Hn > 60) & (Hn < 170) & (S > 40) & (V > 50))\n",
    "    green_score = float(green_mask.mean())\n",
    "\n",
    "    # shadow contrast / hard light\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    local_contrast = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    global_contrast = gray.std()\n",
    "    shadow_score = min(\n",
    "        1.0,\n",
    "        (local_contrast / 500.0) * 0.7 + (global_contrast / 80.0) * 0.3,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"sky\": sky_score,\n",
    "        \"green\": green_score,\n",
    "        \"shadow\": shadow_score,\n",
    "    }\n",
    "\n",
    "\n",
    "def scale_sun_score_0_10(raw: float) -> float:\n",
    "    \"\"\"\n",
    "    Convert raw sun exposure value to 0â€“10 scale using sigmoid.\n",
    "    This is exactly what the notebook uses at the creator level.\n",
    "    \"\"\"\n",
    "    raw = max(0.0, raw)\n",
    "    x = raw * 6.0\n",
    "    return float((1.0 / (1.0 + np.exp(-x))) * 10.0)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. Per-frame + per-reel sun score (from notebook)\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_sun_frame_score_quality_only(frame_bgr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    'How sunlit & outdoor is this frame?' with integrated video quality.\n",
    "    No face-based logic.\n",
    "    \"\"\"\n",
    "    cues = compute_outdoor_cues(frame_bgr)\n",
    "    sky, green, shadow = cues[\"sky\"], cues[\"green\"], cues[\"shadow\"]\n",
    "\n",
    "    # Warmth (supporting signal from illuminant)\n",
    "    illum = estimate_illuminant_mhcc_style(frame_bgr)\n",
    "    R, G, B = float(illum[0]), float(illum[1]), float(illum[2])\n",
    "    warmth = max(0.0, R - B)\n",
    "    warmth_norm = float(np.clip((warmth + 0.2) / 0.4, 0.0, 1.0))\n",
    "\n",
    "    # Base outdoor score\n",
    "    outdoor_raw = 0.5 * sky + 0.3 * green + 0.2 * shadow\n",
    "\n",
    "    # Warmth bonus only if already somewhat outdoor\n",
    "    warmth_bonus = outdoor_raw * 0.4 * warmth_norm\n",
    "\n",
    "    # Penalise warm but no sky/green â†’ studio lighting\n",
    "    studio_penalty = 0.0\n",
    "    if sky < 0.01 and green < 0.01 and warmth_norm > 0.6:\n",
    "        studio_penalty = 0.3 * warmth_norm\n",
    "\n",
    "    quality = estimate_video_quality(frame_bgr)\n",
    "\n",
    "    sun_raw = outdoor_raw + warmth_bonus - studio_penalty\n",
    "    sun_quality_adjusted = sun_raw * (0.4 + 0.6 * quality)\n",
    "\n",
    "    return float(sun_quality_adjusted)\n",
    "\n",
    "\n",
    "# def analyze_reel_sun_quality_only(\n",
    "#     video_path: str,\n",
    "#     num_frames: int = FRAMES_PER_REEL_SUN,\n",
    "# ) -> float:\n",
    "#     \"\"\"\n",
    "#     Average sun exposure (with quality) across frames in a reel.\n",
    "#     Returns the *raw* sun exposure value (same as 'sun_exposure_raw_A' per reel).\n",
    "#     \"\"\"\n",
    "#     frames = sample_video_frames(video_path, num_frames=num_frames)\n",
    "#     if not frames:\n",
    "#         return 0.0\n",
    "#     scores = [compute_sun_frame_score_quality_only(f) for f in frames]\n",
    "#     return float(np.mean(scores))\n",
    "\n",
    "def analyze_reel_sun_quality_only(\n",
    "    video_path: str,\n",
    "    num_frames: int = FRAMES_PER_REEL_SUN,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Maximum sun exposure (with quality) across frames in a reel.\n",
    "    Returns the *raw* sun exposure value (same as 'sun_exposure_raw_A' per reel),\n",
    "    but now using the max over frames instead of the mean.\n",
    "    \"\"\"\n",
    "    frames = sample_video_frames(video_path, num_frames=num_frames)\n",
    "    if not frames:\n",
    "        return 0.0\n",
    "\n",
    "    scores = [compute_sun_frame_score_quality_only(f) for f in frames]\n",
    "    # â¬‡â¬‡ change is here: max instead of mean\n",
    "    return float(np.max(scores))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. Per-frame sun exposure score\n",
    "#    (this replaces the missing `_sun_exposure_score_for_frame` symbol)\n",
    "# -------------------------------------------------------------------------\n",
    "def _sun_exposure_score_for_frame(frame_bgr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute a scalar 'sun exposure' score for a single frame.\n",
    "\n",
    "    Heuristic:\n",
    "      - Convert to Lab.\n",
    "      - Use mean lightness (L) and chroma (sqrt(a^2 + b^2)).\n",
    "      - Combine and scale into roughly [0, 10].\n",
    "    \"\"\"\n",
    "    # Resize to speed up computation if frames are big\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    if max(h, w) > 720:\n",
    "        scale = 720 / max(h, w)\n",
    "        frame_bgr = cv2.resize(frame_bgr, None, fx=scale, fy=scale)\n",
    "\n",
    "    lab = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    L, a, b = cv2.split(lab)\n",
    "\n",
    "    # Normalize lightness to [0, 1]\n",
    "    L_norm = L / 255.0\n",
    "\n",
    "    # Chroma around neutral (128, 128)\n",
    "    chroma = np.sqrt((a - 128.0) ** 2 + (b - 128.0) ** 2)\n",
    "    # Roughly normalize chroma to [0, 1]\n",
    "    chroma_norm = chroma / (np.sqrt(2) * 128.0)\n",
    "\n",
    "    mean_L = float(L_norm.mean())\n",
    "    mean_chroma = float(chroma_norm.mean())\n",
    "\n",
    "    # Weighted combination â†’ raw score in [0, 1] ish\n",
    "    raw = 0.7 * mean_L + 0.3 * mean_chroma\n",
    "\n",
    "    # Scale to [0, 10]\n",
    "    return float(raw * 10.0)\n",
    "# -------------------------------------------------------------------------\n",
    "# 5. Main entrypoint for joint pipeline\n",
    "# -------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------\n",
    "# REEL-LEVEL + FRAME-LEVEL SUN EXPOSURE\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_sun_exposure_for_reel(\n",
    "    video_path: str,\n",
    "    num_frames: int = FRAMES_PER_REEL_SUN,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute sun exposure for a reel.\n",
    "\n",
    "    Returns a dict with:\n",
    "      - sun_exposure_raw_A      (float)  â†’ max sun score across sampled frames\n",
    "      - sun_exposure_0_10_A     (float)  â†’ scaled to 0â€“10\n",
    "      - sun_frame_scores        (list)   â†’ per-frame raw scores (same metric)\n",
    "    \"\"\"\n",
    "    frames = sample_video_frames(video_path, num_frames=num_frames)\n",
    "    if not frames:\n",
    "        return {\n",
    "            \"sun_exposure_raw_A\": 0.0,\n",
    "            \"sun_exposure_0_10_A\": 0.0,\n",
    "            \"sun_frame_scores\": [],\n",
    "        }\n",
    "\n",
    "    frame_scores = []\n",
    "    for f in frames:\n",
    "        # ðŸ”´ IMPORTANT:\n",
    "        # Replace `_sun_exposure_score_for_frame(f)` with whichever function /\n",
    "        # logic you currently use inside your module to score a SINGLE frame.\n",
    "        score = _sun_exposure_score_for_frame(f)\n",
    "        frame_scores.append(float(score))\n",
    "\n",
    "    # You had asked earlier to use MAX across frames, not average:\n",
    "    sun_raw = max(frame_scores) if frame_scores else 0.0\n",
    "\n",
    "    # Keep the same scaling you already use â€“ example below:\n",
    "    # If your notebook does something different, mirror that here.\n",
    "    sun_0_10 = max(0.0, min(10.0, sun_raw))\n",
    "\n",
    "    return {\n",
    "        \"sun_exposure_raw_A\": float(sun_raw),\n",
    "        \"sun_exposure_0_10_A\": float(sun_0_10),\n",
    "        \"sun_frame_scores\": frame_scores,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc90f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DROP-IN CELL â€” ENGLISH PERCENT MODULE (token-level fastText LID)\n",
    "# Public API kept the same:\n",
    "#   - is_music_only_transcript(transcript)\n",
    "#   - english_percentage(text)\n",
    "#   - compute_english_percent_from_transcript(transcript)\n",
    "#\n",
    "# Works in this venv on Windows + Python 3.13 by:\n",
    "#   - using fasttext-predict wheels (imported as `fasttext`)\n",
    "#   - auto-downloading lid.176.ftz if no local model is found\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np  # in case you rely on np.nan elsewhere\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# fastText import with fallback to fasttext-predict\n",
    "# -------------------------------------------------------------------------\n",
    "try:\n",
    "    import fasttext  # type: ignore\n",
    "except Exception:\n",
    "    # Install fasttext-predict (has Windows + Py3.13 wheels) and re-import\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"fasttext-predict\"])\n",
    "    import fasttext  # type: ignore\n",
    "\n",
    "ENGLISH_WORD_RE = re.compile(r\"[A-Za-z]\")  # kept for music-only heuristic\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Model path resolution: env var > existing file > auto-download\n",
    "# -------------------------------------------------------------------------\n",
    "_LID_MODEL_PATH: str | None = None  # resolved lazily\n",
    "_lid_model = None\n",
    "_token_cache: dict[str, tuple[str | None, float]] = {}  # simple in-memory cache\n",
    "\n",
    "\n",
    "def _resolve_lid_model_path() -> str:\n",
    "    \"\"\"\n",
    "    Resolve path to the fastText LID model.\n",
    "\n",
    "    Priority:\n",
    "      1) $LID_MODEL_PATH (if it points to an existing file)\n",
    "      2) local files: lid.176.ftz, lid.176.bin\n",
    "      3) auto-download lid.176.ftz into current directory\n",
    "    \"\"\"\n",
    "    # 1) Explicit env var\n",
    "    env_path = os.getenv(\"LID_MODEL_PATH\")\n",
    "    if env_path:\n",
    "        p = Path(env_path)\n",
    "        if p.is_file():\n",
    "            return str(p.resolve())\n",
    "\n",
    "    # 2) Common local filenames\n",
    "    for name in [\"lid.176.ftz\", \"lid.176.bin\"]:\n",
    "        p = Path(name)\n",
    "        if p.is_file():\n",
    "            return str(p.resolve())\n",
    "\n",
    "    # 3) Auto-download .ftz if nothing found\n",
    "    url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\"\n",
    "    dest = Path(\"lid.176.ftz\")\n",
    "    print(f\"[english_pct] No LID model found, downloading {url} â†’ {dest} â€¦\")\n",
    "\n",
    "    import urllib.request  # local import to keep top-level clean\n",
    "\n",
    "    urllib.request.urlretrieve(url, dest)\n",
    "    print(f\"[english_pct] Downloaded LID model to: {dest.resolve()}\")\n",
    "    return str(dest.resolve())\n",
    "\n",
    "\n",
    "def _get_lid_model():\n",
    "    \"\"\"\n",
    "    Lazy-load the fastText lid.176 model exactly once.\n",
    "    Works with fasttext-predict (predict-only bindings).\n",
    "    \"\"\"\n",
    "    global _lid_model, _LID_MODEL_PATH\n",
    "    if _lid_model is None:\n",
    "        if _LID_MODEL_PATH is None:\n",
    "            _LID_MODEL_PATH = _resolve_lid_model_path()\n",
    "        _lid_model = fasttext.load_model(_LID_MODEL_PATH)\n",
    "    return _lid_model\n",
    "\n",
    "\n",
    "def _clean_transcript(t: str | None) -> str:\n",
    "    if not isinstance(t, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Music-only heuristic  (same signature / semantics as before)\n",
    "# -------------------------------------------------------------------------\n",
    "def is_music_only_transcript(transcript: str | None) -> bool:\n",
    "    \"\"\"\n",
    "    Text-only heuristic: mark reel as 'music-only' so you can EXCLUDE it from\n",
    "    avg_english_pct_non_music when you only have the transcript.\n",
    "\n",
    "    This is intentionally simple and compatible with your existing usage:\n",
    "        df_non_music = df[~df[\"transcript\"].apply(is_music_only_transcript)]\n",
    "    \"\"\"\n",
    "    if not isinstance(transcript, str):\n",
    "        return False\n",
    "\n",
    "    txt = transcript.lower().strip()\n",
    "    if not txt:\n",
    "        return False\n",
    "\n",
    "    # Common Whisper-style tags or obvious music hints\n",
    "    music_keywords = [\n",
    "        \"[music]\",\n",
    "        \"[applause]\",\n",
    "        \"instrumental\",\n",
    "        \"lofi\",\n",
    "        \"bgm\",\n",
    "    ]\n",
    "    if any(k in txt for k in music_keywords):\n",
    "        # extremely short + only tags â†’ treat as music-only\n",
    "        if len(txt.split()) <= 8:\n",
    "            return True\n",
    "\n",
    "    # Short transcript with no alphabetic tokens â†’ likely non-speech (sfx)\n",
    "    tokens = re.findall(r\"\\w+\", txt)\n",
    "    if tokens and not any(ENGLISH_WORD_RE.search(tok) for tok in tokens):\n",
    "        if len(tokens) <= 5:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. Token-level language detection using fastText LID\n",
    "# -------------------------------------------------------------------------\n",
    "def _detect_lang_token(token: str) -> tuple[str | None, float]:\n",
    "    \"\"\"\n",
    "    Use fastText lid.176 to classify a single token.\n",
    "    Returns (lang_code, prob) or (None, 0.0) if unusable.\n",
    "\n",
    "    Includes a tiny cache so the same token isn't passed to the model repeatedly.\n",
    "    \"\"\"\n",
    "    if not isinstance(token, str):\n",
    "        return None, 0.0\n",
    "\n",
    "    cleaned = re.sub(r\"[^A-Za-z]\", \"\", token).lower()\n",
    "    if not cleaned:\n",
    "        return None, 0.0\n",
    "\n",
    "    # cache lookup\n",
    "    cached = _token_cache.get(cleaned)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "\n",
    "    model = _get_lid_model()\n",
    "    labels, probs = model.predict(cleaned)\n",
    "    lang = labels[0].replace(\"__label__\", \"\")\n",
    "    result = (lang, float(probs[0]))\n",
    "    _token_cache[cleaned] = result\n",
    "    return result\n",
    "\n",
    "\n",
    "def _is_english_token(\n",
    "    token: str,\n",
    "    min_prob: float = 0.80,\n",
    "    min_len: int = 2,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Decide if a token is genuinely English, not just Latin-script.\n",
    "\n",
    "    - Uses fastText language-id per token.\n",
    "    - Requires lang == 'en' with reasonably high probability.\n",
    "    - Ignores very short tokens (1-char noise).\n",
    "    \"\"\"\n",
    "    if not isinstance(token, str):\n",
    "        return False\n",
    "\n",
    "    cleaned = re.sub(r\"[^A-Za-z]\", \"\", token)\n",
    "    if len(cleaned) < min_len:\n",
    "        return False\n",
    "\n",
    "    lang, prob = _detect_lang_token(cleaned)\n",
    "    return lang == \"en\" and prob >= min_prob\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. english_percentage(text)  (same function name, upgraded logic)\n",
    "# -------------------------------------------------------------------------\n",
    "def english_percentage(text: str) -> float:\n",
    "    r\"\"\"\n",
    "    Percentage of tokens in `text` that are genuinely English words.\n",
    "\n",
    "    Behaviour, with the SAME name as before:\n",
    "    - Tokenise with \\\\w+ (word regex).\n",
    "    - For each token, run fastText language ID.\n",
    "    - Count a token as English if lang == 'en' with high probability.\n",
    "    - Return % of English tokens in [0, 100], rounded to 2 decimals.\n",
    "\n",
    "    Hinglish example:\n",
    "        \"Okay so aaj hum ek new curly hair routine try karne wale hain\"\n",
    "    Tokens like 'aaj', 'hum', 'karne', 'wale', 'hain' will be classified\n",
    "    as 'hi' (or not 'en') and NOT counted as English.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return 0.0\n",
    "\n",
    "    tokens = re.findall(r\"\\w+\", text)\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "\n",
    "    total_valid = 0\n",
    "    english_count = 0\n",
    "\n",
    "    for tok in tokens:\n",
    "        # Only consider tokens with at least one Latin letter\n",
    "        if not ENGLISH_WORD_RE.search(tok):\n",
    "            continue\n",
    "\n",
    "        total_valid += 1\n",
    "        if _is_english_token(tok):\n",
    "            english_count += 1\n",
    "\n",
    "    if total_valid == 0:\n",
    "        return 0.0\n",
    "\n",
    "    pct = 100.0 * english_count / total_valid\n",
    "    return round(float(pct), 2)\n",
    "\n",
    "\n",
    "# ----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39bdf8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GEMINI MODULE â€” call_gemini_for_reel\n",
    "# Target: per-reel `gemini_raw` (JSON string with numeric features)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "from typing import List, Optional\n",
    "\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ENV + CLIENT SETUP (matching notebook pattern)\n",
    "# -------------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "# GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"Missing GEMINI_API_KEY (set it in .env or env vars)\")\n",
    "\n",
    "# Use the same style of model name as in the notebook\n",
    "GEMINI_MODEL_NAME = \"models/gemini-2.0-flash-001\"\n",
    "\n",
    "_gemini_client: Optional[genai.Client] = None\n",
    "\n",
    "\n",
    "def get_gemini_client() -> genai.Client:\n",
    "    \"\"\"Singleton-style client initialisation (same pattern as notebook).\"\"\"\n",
    "    global _gemini_client\n",
    "    if _gemini_client is None:\n",
    "        _gemini_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "    return _gemini_client\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Prompt template (aligned with how you want gemini_raw to look)\n",
    "# -------------------------------------------------------------------------\n",
    "GEMINI_PROMPT_TEMPLATE = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    You are helping a beauty and personal-care brand evaluate Instagram creators\n",
    "    for potential collaborations.\n",
    "\n",
    "    You will receive ONLY text data for ONE reel in this format:\n",
    "\n",
    "    INSTAGRAM REEL TEXT DATA\n",
    "\n",
    "    --- CAPTION ---\n",
    "    {caption}\n",
    "\n",
    "    --- TRANSCRIPT (ASR) ---\n",
    "    {transcript}\n",
    "\n",
    "    --- COMMENTS (if any) ---\n",
    "    {comments_block}\n",
    "\n",
    "    Language may be English, Hinglish (Hindi in Latin script), or a mix.\n",
    "\n",
    "    Your job is to analyse this reel and return ONLY a compact JSON summary with\n",
    "    the following fields. Do NOT repeat the caption, transcript, or comments in\n",
    "    your output. Do NOT add extra text or explanations.\n",
    "\n",
    "    For each reel, infer:\n",
    "\n",
    "    1) genz_word_count (integer)\n",
    "       - Count how many Gen Z / internet slang terms are used in the TRANSCRIPT. \n",
    "       - The spellings in transcript may vary.\n",
    "       - Examples: \"lit\", \"low-key\", \"high-key\", \"slay\", \"vibe\", \"aesthetic\",\n",
    "         \"fr\", \"no cap\", \"cap\", \"on fleek\", \"serving\", \"ate\", \"mood\", \"delulu\",\n",
    "         \"rizz\", \"iykyk\", \"brooo\", \"lol\", \"lmao\", etc.\n",
    "       - Count total occurrences (if \"slay\" appears 3 times, that is 3).\n",
    "\n",
    "    2) is_marketing (0 or 1)\n",
    "       - 1 if the reel is doing ANY kind of marketing or promotion of beauty /\n",
    "         personal-care products, brands, or routines.\n",
    "       - This includes sponsored content, product mentions, recommendations,\n",
    "         discount codes, affiliate links, \"shop now\", \"use my code\", etc.\n",
    "       - Else 0.\n",
    "\n",
    "    3) is_educational (0 or 1)\n",
    "       - 1 if the reel is primarily educational or informative (beauty/hair/skin\n",
    "         tips, how-to steps, ingredient explanations, routines, \"do this / don't\n",
    "         do this\").\n",
    "       - Else 0.\n",
    "\n",
    "    4) is_vlog (0 or 1)\n",
    "       - 1 if the reel is a vlog-style snippet of the creator's life (day in the\n",
    "         life, GRWM, routine, \"come with me\", events narrated in first person).\n",
    "       - Else 0.\n",
    "\n",
    "    5) has_humour (0 or 1)\n",
    "       - Look at both TRANSCRIPT and COMMENTS.\n",
    "       - 1 if there is clear humour or playful/comedic tone, or comments react\n",
    "         with laughter (ðŸ˜‚, ðŸ¤£, \"I'm dead\", \"too funny\", etc.).\n",
    "       - Else 0.\n",
    "\n",
    "    6) comment_sentiment_counts (object)\n",
    "       - For each TOP COMMENT, classify it into exactly ONE of these buckets:\n",
    "         - \"questioning\"   â†’ asking questions, clarifications, doubts\n",
    "         - \"agreeing\"      â†’ agreeing or saying \"same\", \"relatable\", \"me too\"\n",
    "         - \"appreciating\"  â†’ compliments, praise, admiration\n",
    "         - \"negative\"      â†’ criticism, dislike, disagreement\n",
    "         - \"neutral\"       â†’ factual/unclear/irrelevant/any other not fitting above\n",
    "       - Then return only the aggregate counts of how many comments fall into each\n",
    "         bucket.\n",
    "\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    OUTPUT FORMAT (STRICT)\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    Return your answer as VALID JSON inside <res> ... </res> and nothing else.\n",
    "\n",
    "    <res>\n",
    "    {{\n",
    "      \"genz_word_count\": INTEGER,\n",
    "      \"is_marketing\": 0,\n",
    "      \"is_educational\": 0,\n",
    "      \"is_vlog\": 0,\n",
    "      \"has_humour\": 0,\n",
    "      \"comment_sentiment_counts\": {{\n",
    "        \"questioning\": INTEGER,\n",
    "        \"agreeing\": INTEGER,\n",
    "        \"appreciating\": INTEGER,\n",
    "        \"negative\": INTEGER,\n",
    "        \"neutral\": INTEGER\n",
    "      }}\n",
    "    }}\n",
    "    </res>\n",
    "\n",
    "    Rules:\n",
    "    - Do NOT include reasons, explanations, or any extra fields.\n",
    "    - Do NOT repeat or summarise the caption, transcript, or comments.\n",
    "    - Always fill every field with an integer (for counts) or 0/1 for binary flags.\n",
    "    \"\"\"\n",
    ").strip()\n",
    "\n",
    "\n",
    "\n",
    "def _build_gemini_prompt(caption: str, transcript: str, comments: List[str]) -> str:\n",
    "    \"\"\"Format the prompt with caption / transcript / comments.\"\"\"\n",
    "    caption = caption or \"\"\n",
    "    transcript = transcript or \"\"\n",
    "\n",
    "    # â”€â”€ NORMALISE COMMENTS TO A SIMPLE LIST OF STRINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # comments can be:\n",
    "    # - None\n",
    "    # - Python list/tuple of strings\n",
    "    # - numpy array / pandas Series\n",
    "    # - a single string\n",
    "    if comments is None:\n",
    "        comments_list = []\n",
    "    elif isinstance(comments, (list, tuple)):\n",
    "        comments_list = list(comments)\n",
    "    elif hasattr(comments, \"tolist\"):  # e.g. numpy array, pandas Series\n",
    "        comments_list = comments.tolist()\n",
    "    else:\n",
    "        # single scalar (string or something else) â†’ wrap in a list\n",
    "        comments_list = [comments]\n",
    "\n",
    "    # Ensure everything is a stripped string and non-empty\n",
    "    cleaned_comments = []\n",
    "    for c in comments_list:\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if s:\n",
    "            cleaned_comments.append(s)\n",
    "\n",
    "    if cleaned_comments:\n",
    "        comments_block = \"\\n\".join(f\"- {c}\" for c in cleaned_comments[:20])\n",
    "    else:\n",
    "        comments_block = \"None\"\n",
    "\n",
    "    return GEMINI_PROMPT_TEMPLATE.format(\n",
    "        caption=caption,\n",
    "        transcript=transcript,\n",
    "        comments_block=comments_block,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _extract_json_object(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Try to extract a JSON object substring from the model output.\n",
    "    Returns the substring if it parses as JSON, else raises ValueError.\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    # Fast path: whole string is JSON\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return text\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try to find first '{' and last '}' and parse that substring\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        raise ValueError(\"No JSON object found in Gemini output.\")\n",
    "\n",
    "    candidate = text[start : end + 1]\n",
    "    json.loads(candidate)  # will raise if invalid\n",
    "    return candidate\n",
    "\n",
    "\n",
    "def call_gemini_for_reel(\n",
    "    caption: str,\n",
    "    transcript: str,\n",
    "    comments: List[str],\n",
    "    temperature: float = 0.1,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call Gemini on a single reel's text information and return a JSON string.\n",
    "\n",
    "    Inputs:\n",
    "        caption    - reel caption (string, can be empty)\n",
    "        transcript - Whisper transcript (string, can be empty)\n",
    "        comments   - list of comment strings (can be empty)\n",
    "\n",
    "    Output:\n",
    "        gemini_raw (str): a JSON string representing a dict of numeric features.\n",
    "                          This is what you store in your dataframe column 'gemini_raw'.\n",
    "    \"\"\"\n",
    "    prompt = _build_gemini_prompt(caption, transcript, comments)\n",
    "    client = get_gemini_client()\n",
    "\n",
    "    try:\n",
    "        resp = client.models.generate_content(\n",
    "            model=GEMINI_MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config={\"temperature\": temperature},\n",
    "        )\n",
    "        # New google-genai client: text is on resp.text\n",
    "        raw_text = (getattr(resp, \"text\", None) or \"\").strip()\n",
    "        if not raw_text:\n",
    "            print(\"    âœ— Gemini returned empty text\")\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Gemini API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Try to extract a valid JSON object from the output\n",
    "    try:\n",
    "        json_str = _extract_json_object(raw_text)\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Could not extract JSON from Gemini output: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Final validation: ensure it loads and values are numeric\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Gemini JSON is not an object.\")\n",
    "        # Coerce numeric-looking strings into numbers\n",
    "        for k, v in list(data.items()):\n",
    "            if isinstance(v, str):\n",
    "                try:\n",
    "                    if \".\" in v:\n",
    "                        data[k] = float(v)\n",
    "                    else:\n",
    "                        data[k] = int(v)\n",
    "                except Exception:\n",
    "                    # leave non-numeric strings as-is; they'll be ignored with numeric_only=True\n",
    "                    pass\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Gemini JSON validation failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Return the cleaned JSON string\n",
    "    return json.dumps(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7066cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from urllib.parse import urlsplit, urlunsplit\n",
    "\n",
    "COMMENTS_ACTOR_ID = \"apify/instagram-comment-scraper\"  # official Apify actor\n",
    "\n",
    "def _canon_ig_url(u: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize IG post/reel URL so grouping/lookup works reliably.\n",
    "    - remove query/fragment\n",
    "    - ensure trailing slash\n",
    "    \"\"\"\n",
    "    if not u:\n",
    "        return u\n",
    "    parts = urlsplit(u.strip())\n",
    "    clean = urlunsplit((parts.scheme, parts.netloc, parts.path, \"\", \"\"))\n",
    "    if not clean.endswith(\"/\"):\n",
    "        clean += \"/\"\n",
    "    return clean\n",
    "\n",
    "def fetch_deep_comments_apify(reel_url: str, max_comments: int = 150, prof=None) -> list[str]:\n",
    "    \"\"\"\n",
    "    Fetch deeper comments for ONE reel/post using apify/instagram-comment-scraper.\n",
    "    Returns a flat list of comment texts.\n",
    "\n",
    "    Time breakdown (if prof is provided):\n",
    "      - apify.comments.actor.start\n",
    "      - apify.comments.run.wait_for_finish\n",
    "      - apify.comments.dataset.list_items\n",
    "      - apify.comments.parse_items\n",
    "    \"\"\"\n",
    "    reel_url = _canon_ig_url(reel_url)\n",
    "    print(f\"    ðŸ’¬ Fetching deep comments (max {max_comments}) for: {reel_url}\")\n",
    "\n",
    "    try:\n",
    "        run_input = {\n",
    "            \"directUrls\": [reel_url],             # MUST be an array\n",
    "            \"resultsLimit\": int(max_comments),    # per-URL limit (actor behavior)\n",
    "            \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "        }\n",
    "\n",
    "        # --- Start run ---\n",
    "        if prof:\n",
    "            with prof.span(\"api_component\", \"apify.comments.actor.start\", meta={\"n_urls\": 1}):\n",
    "                run = apify.actor(COMMENTS_ACTOR_ID).start(run_input=run_input)\n",
    "        else:\n",
    "            run = apify.actor(COMMENTS_ACTOR_ID).start(run_input=run_input)\n",
    "\n",
    "        print(\"starting api ***\\n\")\n",
    "        print(run)\n",
    "        print(\"\\n*** api finished starting\")\n",
    "        run_id = run[\"id\"]\n",
    "\n",
    "        # --- Wait ---\n",
    "        if prof:\n",
    "            with prof.span(\"api_component\", \"apify.comments.run.wait_for_finish\", meta={\"run_id\": run_id}):\n",
    "                finished = apify.run(run_id).wait_for_finish()\n",
    "        else:\n",
    "            finished = apify.run(run_id).wait_for_finish()\n",
    "\n",
    "        print(\"waiting api ***\\n\")\n",
    "        print(finished)\n",
    "        print(\"\\n*** api finished waiting\")\n",
    "        ds_id = finished[\"defaultDatasetId\"]\n",
    "\n",
    "        # --- Download dataset items ---\n",
    "        if prof:\n",
    "            with prof.span(\"api_component\", \"apify.comments.dataset.list_items\", meta={\"dataset_id\": ds_id}):\n",
    "                items = apify.dataset(ds_id).list_items().items\n",
    "        else:\n",
    "            items = apify.dataset(ds_id).list_items().items\n",
    "\n",
    "        print(\"fetched dataset items api ***\\n\")\n",
    "        print(items)\n",
    "        print(\"\\n*** api finished fetching dataset items\")\n",
    "        # --- Parse ---\n",
    "        comments = []\n",
    "        if prof:\n",
    "            with prof.span(\"api_component\", \"apify.comments.parse_items\", meta={\"n_items\": len(items)}):\n",
    "                for it in items:\n",
    "                    txt = it.get(\"text\") or it.get(\"body\") or \"\"\n",
    "                    if isinstance(txt, str) and txt.strip():\n",
    "                        comments.append(txt.strip())\n",
    "        else:\n",
    "            for it in items:\n",
    "                txt = it.get(\"text\") or it.get(\"body\") or \"\"\n",
    "                if isinstance(txt, str) and txt.strip():\n",
    "                    comments.append(txt.strip())\n",
    "\n",
    "        print(f\"    âœ“ Deep comments fetched: {len(comments)}\")\n",
    "        return comments\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Deep comment fetch failed: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09a41fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model: medium ...\n",
      "Whisper model loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRANSCRIPT MODULE â€” transcribe_reel (shared for Gemini, series, english %)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# Load Whisper once (pick size as you like: \"tiny\", \"base\", \"small\", \"medium\", \"large\")\n",
    "WHISPER_MODEL_NAME = \"medium\"\n",
    "\n",
    "print(f\"Loading Whisper model: {WHISPER_MODEL_NAME} ...\")\n",
    "_whisper_model = whisper.load_model(WHISPER_MODEL_NAME)\n",
    "print(\"Whisper model loaded.\")\n",
    "\n",
    "# Simple cache so we don't transcribe the same reel twice\n",
    "_transcript_cache: dict[str, str] = {}\n",
    "\n",
    "\n",
    "def transcribe_reel(\n",
    "    video_path: str,\n",
    "    reel_url: str | None = None,\n",
    "    force: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Shared transcript helper.\n",
    "\n",
    "    - Takes local `video_path` (already downloaded by download_reel_cached).\n",
    "    - Optional `reel_url` is only used as a cache key.\n",
    "    - Returns a plain text transcript (\"\" on failure).\n",
    "    \"\"\"\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        print(\"    âœ— Video file not found for transcription:\", video_path)\n",
    "        return \"\"\n",
    "\n",
    "    cache_key = reel_url or video_path\n",
    "    if not force and cache_key in _transcript_cache:\n",
    "        return _transcript_cache[cache_key]\n",
    "\n",
    "    try:\n",
    "        print(\"    ðŸŽ™ Transcribing audio with Whisper ...\")\n",
    "        # fp16 only if GPU is available\n",
    "        use_fp16 = torch.cuda.is_available()\n",
    "        result = _whisper_model.transcribe(video_path, fp16=\"true\" if DEVICE == \"cuda\" else \"false\")\n",
    "        text = (result.get(\"text\") or \"\").strip()\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Whisper transcription failed: {e}\")\n",
    "        text = \"\"\n",
    "\n",
    "    _transcript_cache[cache_key] = text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0542a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\gaura\\AppData\\Local\\Temp\\ipykernel_38992\\2841812559.py:13: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  - Counts tokens matched by \\w+ (letters/digits/underscore).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SPOKEN WORD COUNT MODULE â€” per-reel word_count\n",
    "# Target metric (per creator): avg_words_spoken_non_music\n",
    "# =============================================================================\n",
    "\n",
    "import re\n",
    "\n",
    "def compute_spoken_word_count(transcript: str | None) -> int:\n",
    "    \"\"\"\n",
    "    Return the number of spoken 'word' tokens in the transcript.\n",
    "\n",
    "    - Uses the same _clean_transcript helper as english_percentage.\n",
    "    - Counts tokens matched by \\w+ (letters/digits/underscore).\n",
    "    - Returns 0 for empty / None transcript.\n",
    "    \"\"\"\n",
    "    txt = _clean_transcript(transcript)\n",
    "    if not txt:\n",
    "        return 0\n",
    "\n",
    "    tokens = re.findall(r\"\\w+\", txt)\n",
    "    return len(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca757f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_pure_emoji_or_symbol(comment: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the comment is 'emoji-only' or symbols-only:\n",
    "    - No letters or digits.\n",
    "    - Spaces are ignored.\n",
    "    Examples treated as pure-emoji/symbol:\n",
    "      \"ðŸ˜‚ðŸ˜‚ðŸ˜‚\", \"â¤ï¸â¤ï¸\", \"ðŸ”¥ðŸ”¥\", \"ðŸ’–\", \"ðŸ˜ðŸ˜ðŸ˜\", \"!!!!\", \"???\".\n",
    "    \"\"\"\n",
    "    if not comment:\n",
    "        return True\n",
    "    # Remove spaces\n",
    "    s = comment.replace(\" \", \"\")\n",
    "    if not s:\n",
    "        return True\n",
    "\n",
    "    # If there is ANY alphanumeric char, we treat it as not pure-emoji\n",
    "    if any(ch.isalnum() for ch in s):\n",
    "        return False\n",
    "\n",
    "    # No alnum characters â†’ treat as pure emoji / symbol\n",
    "    return True\n",
    "\n",
    "\n",
    "def filter_top_comments_for_gemini(\n",
    "    comments,\n",
    "    max_total: int = 100,\n",
    "    max_after_filter: int = 30,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    1) Normalise `comments` into a list of strings.\n",
    "    2) Take the top `max_total` comments (by existing order).\n",
    "    3) Drop comments that are pure emoji / symbol (using is_pure_emoji_or_symbol).\n",
    "    4) Return only the first `max_after_filter` of the remaining comments.\n",
    "\n",
    "    This is what we'll actually feed to Gemini.\n",
    "    \"\"\"\n",
    "    # Normalise to list of strings\n",
    "    if comments is None:\n",
    "        comments_list = []\n",
    "    elif isinstance(comments, (list, tuple)):\n",
    "        comments_list = list(comments)\n",
    "    elif hasattr(comments, \"tolist\"):  # numpy array, pandas Series\n",
    "        comments_list = comments.tolist()\n",
    "    else:\n",
    "        comments_list = [comments]\n",
    "\n",
    "    cleaned = []\n",
    "    for c in comments_list:\n",
    "        if c is None:\n",
    "            continue\n",
    "        s = str(c).strip()\n",
    "        if s:\n",
    "            cleaned.append(s)\n",
    "\n",
    "    # 1) Top N (by whatever ordering you already have = likes/time/etc.)\n",
    "    top_n = cleaned[:max_total]\n",
    "\n",
    "    # 2) Drop pure-emoji / symbol-only comments\n",
    "    non_emoji = [c for c in top_n if not is_pure_emoji_or_symbol(c)]\n",
    "\n",
    "    # 3) Only feed top M of those to Gemini\n",
    "    return non_emoji[:max_after_filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "291df2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# POSTS vs REELS RATIO MODULE\n",
    "#   - Uses Apify \"apify/instagram-scraper\" to sample recent posts per creator\n",
    "#   - Computes per-creator:\n",
    "#       total_posts_sampled, reels_sampled, static_posts_sampled, other_posts_sampled\n",
    "#       reels_ratio = reels_sampled / total_posts_sampled\n",
    "#       static_ratio = static_posts_sampled / total_posts_sampled\n",
    "# =============================================================================\n",
    "\n",
    "# Reuse your existing APIFY key if already defined, otherwise pull from env\n",
    "APIFY_TOKEN = APIFY_API_KEY\n",
    "\n",
    "if not APIFY_TOKEN:\n",
    "    raise RuntimeError(\"Missing APIFY_API_KEY / APIFY_TOKEN for postsâ†’reels ratio module\")\n",
    "\n",
    "POSTS_ACTOR_ID = \"apify/instagram-scraper\"   # same actor you used in posts_to_reels_ratio.ipynb\n",
    "MAX_POSTS_PER_CREATOR = 30                  # sample size per creator (tune as needed)\n",
    "\n",
    "\n",
    "def fetch_all_posts_for_creators(creators, max_posts: int = MAX_POSTS_PER_CREATOR) -> dict:\n",
    "    \"\"\"\n",
    "    For a list of IG handles, fetch up to `max_posts` recent posts per handle\n",
    "    using Apify instagram-scraper.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"username1\": [post_dict, post_dict, ...],\n",
    "          \"username2\": [...],\n",
    "          ...\n",
    "        }\n",
    "    where each post_dict is one Apify post item.\n",
    "    \"\"\"\n",
    "    client = ApifyClient(APIFY_TOKEN)\n",
    "\n",
    "    # Build profile URLs exactly like in posts_to_reels_ratio.ipynb\n",
    "    profile_urls = [f\"https://www.instagram.com/{u.lstrip('@')}/\" for u in creators]\n",
    "    print(f\"ðŸš€ Scraping up to {max_posts} posts for {len(creators)} creators...\")\n",
    "\n",
    "    run_input = {\n",
    "        \"directUrls\": profile_urls,\n",
    "        \"resultsLimit\": max_posts,\n",
    "        \"addUserInfo\": True,\n",
    "        \"addLocation\": False,\n",
    "        \"addLikes\": False,\n",
    "        \"addVideoThumbnails\": False,\n",
    "        \"proxyConfiguration\": {\n",
    "            \"useApifyProxy\": True,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    run = client.actor(POSTS_ACTOR_ID).call(run_input=run_input)\n",
    "    items = client.dataset(run[\"defaultDatasetId\"]).list_items().items\n",
    "\n",
    "    # Group posts by username (ownerUsername / username) exactly as in the notebook\n",
    "    grouped: dict[str, list] = {}\n",
    "    for it in items:\n",
    "        if not isinstance(it, dict):\n",
    "            continue\n",
    "        user = (it.get(\"ownerUsername\") or it.get(\"username\") or \"unknown\").lower()\n",
    "        grouped.setdefault(user, []).append(it)\n",
    "\n",
    "    print(f\"âœ“ Got {len(items)} posts across {len(grouped)} creators\")\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def summarise_posts_by_type(posts_by_user: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Take posts_by_user from fetch_all_posts_for_creators and summarise counts.\n",
    "\n",
    "    Output columns:\n",
    "      - creator\n",
    "      - total_posts_sampled\n",
    "      - reels_sampled\n",
    "      - static_posts_sampled\n",
    "      - other_posts_sampled\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for user, items in posts_by_user.items():\n",
    "        total_posts = len(items)\n",
    "        reel_count = 0\n",
    "        static_count = 0\n",
    "        other_count = 0\n",
    "\n",
    "        for it in items:\n",
    "            if not isinstance(it, dict):\n",
    "                continue\n",
    "\n",
    "            # --- Heuristics from posts_to_reels_ratio.ipynb ---\n",
    "            is_reel = False\n",
    "            is_static = False\n",
    "\n",
    "            # 1) Explicit Apify field if present\n",
    "            if it.get(\"isReel\") is True:\n",
    "                is_reel = True\n",
    "            else:\n",
    "                # 2) Fall back on 'type' (e.g. \"GraphVideoReel\")\n",
    "                ig_type = str(it.get(\"type\") or \"\").lower()\n",
    "                if \"reel\" in ig_type:\n",
    "                    is_reel = True\n",
    "\n",
    "            # Everything non-reel we treat as static-ish unless clearly \"other\"\n",
    "            if not is_reel:\n",
    "                is_static = True\n",
    "\n",
    "            if is_reel:\n",
    "                reel_count += 1\n",
    "            elif is_static:\n",
    "                static_count += 1\n",
    "            else:\n",
    "                other_count += 1\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"creator\": user,  # lowercased username (no '@')\n",
    "                \"total_posts_sampled\": total_posts,\n",
    "                \"reels_sampled\": reel_count,\n",
    "                \"static_posts_sampled\": static_count,\n",
    "                \"other_posts_sampled\": other_count,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def compute_static_reel_ratios(posts_by_user: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    High-level helper:\n",
    "       posts_by_user -> summary df with ratios.\n",
    "    \"\"\"\n",
    "    df = summarise_posts_by_type(posts_by_user)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Avoid division by zero while keeping NaNs\n",
    "    denom = df[\"total_posts_sampled\"].replace({0: np.nan})\n",
    "    df[\"reels_ratio\"] = df[\"reels_sampled\"] / denom\n",
    "    df[\"static_ratio\"] = df[\"static_posts_sampled\"] / denom\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85992099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, functools, threading, contextlib, urllib.parse, pandas as pd, numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Global timing sink\n",
    "# -----------------------------\n",
    "TIMING_ROWS = []\n",
    "\n",
    "def _now():\n",
    "    return time.perf_counter()\n",
    "\n",
    "def _sanitize_url(url: str) -> str:\n",
    "    try:\n",
    "        u = urllib.parse.urlsplit(url)\n",
    "        return f\"{u.scheme}://{u.netloc}{u.path}\"\n",
    "    except Exception:\n",
    "        return str(url)\n",
    "\n",
    "def record(kind: str, name: str, duration_s: float, **meta):\n",
    "    TIMING_ROWS.append({\n",
    "        \"ts\": time.time(),\n",
    "        \"kind\": kind,\n",
    "        \"name\": name,\n",
    "        \"duration_s\": float(duration_s),\n",
    "        **meta\n",
    "    })\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timed_block(name: str, kind: str = \"block\", **meta):\n",
    "    t0 = _now()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        record(kind, name, _now() - t0, **meta)\n",
    "\n",
    "def timed_fn(fn_name: str = None, kind: str = \"fn\"):\n",
    "    \"\"\"\n",
    "    Decorator that records inclusive time for each call.\n",
    "    \"\"\"\n",
    "    def deco(fn):\n",
    "        nm = fn_name or fn.__name__\n",
    "        @functools.wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            t0 = _now()\n",
    "            try:\n",
    "                return fn(*args, **kwargs)\n",
    "            finally:\n",
    "                record(kind, nm, _now() - t0)\n",
    "        return wrapper\n",
    "    return deco\n",
    "\n",
    "# -----------------------------\n",
    "# Patch requests + httpx (if present) to break down API time\n",
    "# Components we log:\n",
    "# - total wall time\n",
    "# - ttfb_s (requests: response.elapsed ~ time to first byte/headers)\n",
    "# - body_s (approx = total - ttfb)\n",
    "# - json_parse_s (timed separately by patching Response.json)\n",
    "# -----------------------------\n",
    "def install_http_timing():\n",
    "    # requests\n",
    "    try:\n",
    "        import requests\n",
    "        from requests.sessions import Session\n",
    "        from requests.models import Response\n",
    "\n",
    "        if not hasattr(install_http_timing, \"_requests_patched\"):\n",
    "            install_http_timing._requests_patched = True\n",
    "            install_http_timing._requests_orig_request = Session.request\n",
    "            install_http_timing._requests_orig_json = Response.json\n",
    "\n",
    "            def _patched_request(self, method, url, **kwargs):\n",
    "                url_s = _sanitize_url(url)\n",
    "                t0 = _now()\n",
    "                resp = install_http_timing._requests_orig_request(self, method, url, **kwargs)\n",
    "                t_total = _now() - t0\n",
    "\n",
    "                ttfb = None\n",
    "                try:\n",
    "                    # response.elapsed is a timedelta; good proxy for \"headers received\"\n",
    "                    ttfb = resp.elapsed.total_seconds()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                body_s = None\n",
    "                if ttfb is not None:\n",
    "                    body_s = max(t_total - ttfb, 0.0)\n",
    "\n",
    "                record(\n",
    "                    \"http\",\n",
    "                    f\"requests {method.upper()}\",\n",
    "                    t_total,\n",
    "                    url=url_s,\n",
    "                    status=getattr(resp, \"status_code\", None),\n",
    "                    ttfb_s=ttfb,\n",
    "                    body_s=body_s,\n",
    "                    stream=bool(kwargs.get(\"stream\", False)),\n",
    "                )\n",
    "                return resp\n",
    "\n",
    "            def _patched_json(self, **kwargs):\n",
    "                url_s = _sanitize_url(getattr(self, \"url\", \"\"))\n",
    "                t0 = _now()\n",
    "                out = install_http_timing._requests_orig_json(self, **kwargs)\n",
    "                record(\n",
    "                    \"http_json\",\n",
    "                    \"requests Response.json\",\n",
    "                    _now() - t0,\n",
    "                    url=url_s,\n",
    "                    status=getattr(self, \"status_code\", None),\n",
    "                )\n",
    "                return out\n",
    "\n",
    "            Session.request = _patched_request\n",
    "            Response.json = _patched_json\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"requests timing not installed:\", e)\n",
    "\n",
    "    # httpx (some SDKs use it under the hood)\n",
    "    try:\n",
    "        import httpx\n",
    "        if not hasattr(install_http_timing, \"_httpx_patched\"):\n",
    "            install_http_timing._httpx_patched = True\n",
    "            install_http_timing._httpx_orig_request = httpx.Client.request\n",
    "            install_http_timing._httpx_orig_json = httpx.Response.json\n",
    "\n",
    "            def _patched_httpx_request(self, method, url, **kwargs):\n",
    "                url_s = _sanitize_url(str(url))\n",
    "                t0 = _now()\n",
    "                resp = install_http_timing._httpx_orig_request(self, method, url, **kwargs)\n",
    "                t_total = _now() - t0\n",
    "\n",
    "                # httpx doesn't expose response.elapsed like requests; we at least log total.\n",
    "                record(\n",
    "                    \"http\",\n",
    "                    f\"httpx {method.upper()}\",\n",
    "                    t_total,\n",
    "                    url=url_s,\n",
    "                    status=getattr(resp, \"status_code\", None),\n",
    "                )\n",
    "                return resp\n",
    "\n",
    "            def _patched_httpx_json(self, **kwargs):\n",
    "                url_s = _sanitize_url(str(getattr(self, \"url\", \"\")))\n",
    "                t0 = _now()\n",
    "                out = install_http_timing._httpx_orig_json(self, **kwargs)\n",
    "                record(\n",
    "                    \"http_json\",\n",
    "                    \"httpx Response.json\",\n",
    "                    _now() - t0,\n",
    "                    url=url_s,\n",
    "                    status=getattr(self, \"status_code\", None),\n",
    "                )\n",
    "                return out\n",
    "\n",
    "            httpx.Client.request = _patched_httpx_request\n",
    "            httpx.Response.json = _patched_httpx_json\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"httpx timing not installed:\", e)\n",
    "\n",
    "install_http_timing()\n",
    "\n",
    "# -----------------------------\n",
    "# Wrap the exact functions called in your main loop\n",
    "# (inclusive timing per call)\n",
    "# -----------------------------\n",
    "MAIN_LOOP_FUNCS = [\n",
    "    \"fetch_reels_from_apify\",\n",
    "    \"download_reel_cached\",\n",
    "    \"fetch_deep_comments_apify\",\n",
    "    \"filter_top_comments_for_gemini\",\n",
    "    \"transcribe_reel\",\n",
    "    \"compute_attractiveness_for_reel\",\n",
    "    \"is_music_only_transcript\",\n",
    "    \"compute_spoken_word_count\",\n",
    "    \"compute_sun_exposure_for_reel\",\n",
    "    \"compute_eye_contact_for_reel\",\n",
    "    \"compute_creativity_for_reel\",\n",
    "    \"detect_series_from_text\",\n",
    "    \"compute_video_caption_flag_for_reel\",\n",
    "    \"compute_accessories_for_reel\",\n",
    "    \"english_percentage\",\n",
    "    \"call_gemini_for_reel\",\n",
    "]\n",
    "\n",
    "for fn_name in MAIN_LOOP_FUNCS:\n",
    "    if fn_name in globals() and callable(globals()[fn_name]):\n",
    "        globals()[fn_name] = timed_fn(fn_name, kind=\"feature_fn\")(globals()[fn_name])\n",
    "\n",
    "def timing_report():\n",
    "    df = pd.DataFrame(TIMING_ROWS)\n",
    "    if df.empty:\n",
    "        print(\"No timing rows captured.\")\n",
    "        return df\n",
    "\n",
    "    # handy columns\n",
    "    df[\"ms\"] = df[\"duration_s\"] * 1000.0\n",
    "\n",
    "    def p95(x): return float(np.percentile(x, 95)) if len(x) else np.nan\n",
    "    def p99(x): return float(np.percentile(x, 99)) if len(x) else np.nan\n",
    "\n",
    "    agg = (df.groupby([\"kind\", \"name\"])\n",
    "             .agg(\n",
    "                 calls=(\"duration_s\", \"count\"),\n",
    "                 total_s=(\"duration_s\", \"sum\"),\n",
    "                 mean_s=(\"duration_s\", \"mean\"),\n",
    "                 p95_s=(\"duration_s\", p95),\n",
    "                 p99_s=(\"duration_s\", p99),\n",
    "             )\n",
    "             .reset_index()\n",
    "             .sort_values(\"total_s\", ascending=False))\n",
    "\n",
    "    display(agg)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c63d86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NEW: Batch deep-comment fetch â€” ONE Apify run per creator (still timed)\n",
    "#   - Uses the same actor: apify/instagram-comment-scraper\n",
    "#   - Input: list of reel URLs\n",
    "#   - Output: {reel_url: [comment_text, ...]}\n",
    "#   - Timing components:\n",
    "#       * apify.comments.actor.call\n",
    "#       * apify.comments.dataset.list_items\n",
    "#       * apify.comments.parse_group\n",
    "# =============================================================================\n",
    "\n",
    "# COMMENTS_ACTOR_ID = \"apify/instagram-comment-scraper\"\n",
    "\n",
    "def _norm_ig_url(u: str) -> str:\n",
    "    \"\"\"Normalize IG reel URL to reduce join misses.\"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return \"\"\n",
    "    u = u.strip()\n",
    "    if not u:\n",
    "        return \"\"\n",
    "    # strip query\n",
    "    u = u.split(\"?\", 1)[0]\n",
    "    # ensure trailing slash for matching\n",
    "    if not u.endswith(\"/\"):\n",
    "        u = u + \"/\"\n",
    "    # prefer canonical host\n",
    "    u = u.replace(\"http://\", \"https://\")\n",
    "    u = u.replace(\"https://instagram.com/\", \"https://www.instagram.com/\")\n",
    "    u = u.replace(\"https://m.instagram.com/\", \"https://www.instagram.com/\")\n",
    "    return u\n",
    "\n",
    "def fetch_deep_comments_apify_batch(reel_urls: list[str], max_comments_per_url: int = 150, prof=None) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Batch comment fetch: ONE actor run for MANY reel/post URLs.\n",
    "    Returns: {canonical_post_url: [comment_texts...]}\n",
    "\n",
    "    Time breakdown (if prof is provided):\n",
    "      - apify.comments.actor.start\n",
    "      - apify.comments.run.wait_for_finish\n",
    "      - apify.comments.dataset.list_items\n",
    "      - apify.comments.group_by_url\n",
    "    \"\"\"\n",
    "    reel_urls = [_canon_ig_url(u) for u in reel_urls if isinstance(u, str) and u.strip()]\n",
    "    reel_urls = list(dict.fromkeys(reel_urls))  # dedupe preserving order\n",
    "\n",
    "    if not reel_urls:\n",
    "        return {}\n",
    "\n",
    "    print(f\"    ðŸ’¬ Batch deep comments: {len(reel_urls)} urls, limit={max_comments_per_url}\")\n",
    "\n",
    "    run_input = {\n",
    "        \"directUrls\": reel_urls,\n",
    "        \"resultsLimit\": int(max_comments_per_url),\n",
    "        \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "    }\n",
    "\n",
    "    # --- Start ---\n",
    "    if prof:\n",
    "        with prof.span(\"api_component\", \"apify.comments.actor.start\", meta={\"n_urls\": len(reel_urls)}):\n",
    "            run = apify.actor(COMMENTS_ACTOR_ID).start(run_input=run_input)\n",
    "    else:\n",
    "        run = apify.actor(COMMENTS_ACTOR_ID).start(run_input=run_input)\n",
    "\n",
    "    run_id = run[\"id\"]\n",
    "    print(\"actor caled ****\")\n",
    "    print(run)\n",
    "\n",
    "    # --- Wait ---\n",
    "    if prof:\n",
    "        with prof.span(\"api_component\", \"apify.comments.run.wait_for_finish\", meta={\"run_id\": run_id}):\n",
    "            finished = apify.run(run_id).wait_for_finish()\n",
    "    else:\n",
    "        finished = apify.run(run_id).wait_for_finish()\n",
    "\n",
    "    ds_id = finished[\"defaultDatasetId\"]\n",
    "\n",
    "    # --- Download dataset ---\n",
    "    if prof:\n",
    "        with prof.span(\"api_component\", \"apify.comments.dataset.list_items\", meta={\"dataset_id\": ds_id}):\n",
    "            items = apify.dataset(ds_id).list_items().items\n",
    "    else:\n",
    "        items = apify.dataset(ds_id).list_items().items\n",
    "\n",
    "    # --- Group by post URL (field name can vary, so we try several) ---\n",
    "    by_url = defaultdict(list)\n",
    "\n",
    "    def _item_url(it: dict) -> str:\n",
    "        # These are common keys across comment scrapers\n",
    "        return (\n",
    "            it.get(\"postUrl\")\n",
    "            or it.get(\"postURL\")\n",
    "            or it.get(\"url\")\n",
    "            or it.get(\"postLink\")\n",
    "            or \"\"\n",
    "        )\n",
    "\n",
    "    if prof:\n",
    "        with prof.span(\"api_component\", \"apify.comments.group_by_url\", meta={\"n_items\": len(items)}):\n",
    "            for it in items:\n",
    "                u = _canon_ig_url(_item_url(it))\n",
    "                txt = it.get(\"text\") or it.get(\"body\") or \"\"\n",
    "                if u and isinstance(txt, str) and txt.strip():\n",
    "                    by_url[u].append(txt.strip())\n",
    "    else:\n",
    "        for it in items:\n",
    "            u = _canon_ig_url(_item_url(it))\n",
    "            txt = it.get(\"text\") or it.get(\"body\") or \"\"\n",
    "            if u and isinstance(txt, str) and txt.strip():\n",
    "                by_url[u].append(txt.strip())\n",
    "\n",
    "    return dict(by_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "365e49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SINGLE-DECODE HELPERS (decode once per reel, reuse frames)\n",
    "# =============================================================================\n",
    "import math\n",
    "from typing import Any\n",
    "\n",
    "def _resize_max_side(frame_bgr: np.ndarray, max_side: int) -> np.ndarray:\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    m = max(h, w)\n",
    "    if m <= max_side:\n",
    "        return frame_bgr\n",
    "    scale = max_side / float(m)\n",
    "    nh, nw = int(round(h * scale)), int(round(w * scale))\n",
    "    return cv2.resize(frame_bgr, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def decode_video_once_for_all_tasks(\n",
    "    video_path: str,\n",
    "    *,\n",
    "    frames_uniform_16: int = 16,\n",
    "    frames_uniform_sun: int = 5,\n",
    "    eye_stride: int = 3,\n",
    "    caption_target_fps: int = TARGET_FPS,     # from caption module\n",
    "    caption_bottom_crop_ratio: float = BOTTOM_CROP_RATIO,\n",
    "    accessories_fps: int = 5,                 # matches accessories default\n",
    "    max_side_eye: int = 320,\n",
    "    max_side_caption: int = 640,\n",
    "    max_side_accessories: int = 640,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Open video ONCE and return all sampled frames needed by every subtask.\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"ok\": False,\n",
    "        \"fps\": 0.0,\n",
    "        \"frame_count\": 0,\n",
    "        \"duration\": 0.0,\n",
    "        \"frames16\": [],\n",
    "        \"frames5\": [],\n",
    "        \"eye_frames\": [],          # resized for Haar\n",
    "        \"caption_samples\": [],     # list[(t_sec, bottom_crop_bgr_resized)]\n",
    "        \"accessory_frames\": [],    # resized for YOLO\n",
    "    }\n",
    "\n",
    "    if not video_path or (not os.path.exists(video_path)):\n",
    "        return out\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return out\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    if fps <= 0:\n",
    "        fps = 30.0\n",
    "    duration = (frame_count / fps) if frame_count > 0 else 0.0\n",
    "\n",
    "    out[\"fps\"] = float(fps)\n",
    "    out[\"frame_count\"] = int(frame_count)\n",
    "    out[\"duration\"] = float(duration)\n",
    "\n",
    "    # Uniform indices (match your other samplers)\n",
    "    if frame_count and frame_count > 0:\n",
    "        idx16 = set(np.linspace(0, frame_count - 1, num=min(frames_uniform_16, frame_count), dtype=int).tolist())\n",
    "        idx5  = set(np.linspace(0, frame_count - 1, num=min(frames_uniform_sun, frame_count), dtype=int).tolist())\n",
    "    else:\n",
    "        idx16 = set()\n",
    "        idx5  = set()\n",
    "\n",
    "    # Step sampling for caption/accessories\n",
    "    step_caption = max(1, int(round(fps / float(max(1, caption_target_fps)))))\n",
    "    step_access  = max(1, int(round(fps / float(max(1, accessories_fps)))))\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            break\n",
    "\n",
    "        # fallback if CAP_PROP_FRAME_COUNT is broken: approximate idx16/idx5 by first N frames\n",
    "        if frame_count <= 0:\n",
    "            if len(out[\"frames16\"]) < frames_uniform_16:\n",
    "                out[\"frames16\"].append(frame.copy())\n",
    "            if len(out[\"frames5\"]) < frames_uniform_sun:\n",
    "                out[\"frames5\"].append(frame.copy())\n",
    "        else:\n",
    "            if i in idx16:\n",
    "                out[\"frames16\"].append(frame.copy())\n",
    "            if i in idx5:\n",
    "                out[\"frames5\"].append(frame.copy())\n",
    "\n",
    "        # eye contact stride (store resized)\n",
    "        if (i % eye_stride) == 0:\n",
    "            out[\"eye_frames\"].append(_resize_max_side(frame, max_side_eye))\n",
    "\n",
    "        # captions at TARGET_FPS: store bottom crop (resized)\n",
    "        if (i % step_caption) == 0:\n",
    "            h = frame.shape[0]\n",
    "            y0 = int(h * (1.0 - caption_bottom_crop_ratio))\n",
    "            band = frame[y0:, :]\n",
    "            band = _resize_max_side(band, max_side_caption)\n",
    "            t_sec = i / fps\n",
    "            out[\"caption_samples\"].append((float(t_sec), band))\n",
    "\n",
    "        # accessories at accessories_fps: store resized\n",
    "        if (i % step_access) == 0:\n",
    "            out[\"accessory_frames\"].append(_resize_max_side(frame, max_side_accessories))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    cap.release()\n",
    "    out[\"ok\"] = True\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---- cached versions of each metric (same outputs as your wrappers) ----\n",
    "\n",
    "def compute_eye_contact_for_reel_from_frames(eye_frames: list[np.ndarray]) -> dict:\n",
    "    if not eye_frames:\n",
    "        return {\"eye_contact_ratio\": np.nan, \"eye_contact_score_0_10\": np.nan}\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    for f in eye_frames:\n",
    "        total += 1\n",
    "        if is_eye_contact_frame(f):\n",
    "            hits += 1\n",
    "    ratio = (hits / total) if total else 0.0\n",
    "    return {\"eye_contact_ratio\": float(ratio), \"eye_contact_score_0_10\": float(round(10.0 * ratio, 2))}\n",
    "\n",
    "\n",
    "def compute_sun_exposure_for_reel_from_frames(frames5: list[np.ndarray]) -> dict:\n",
    "    if not frames5:\n",
    "        return {\"sun_exposure_raw_A\": 0.0, \"sun_exposure_0_10_A\": 0.0, \"sun_frame_scores\": []}\n",
    "\n",
    "    # Keep your current reel-level logic (MAX over per-frame raw scores)\n",
    "    frame_scores = [float(_sun_exposure_score_for_frame(f)) for f in frames5]\n",
    "    sun_raw = max(frame_scores) if frame_scores else 0.0\n",
    "    sun_0_10 = max(0.0, min(10.0, sun_raw))\n",
    "    return {\"sun_exposure_raw_A\": float(sun_raw), \"sun_exposure_0_10_A\": float(sun_0_10), \"sun_frame_scores\": frame_scores}\n",
    "\n",
    "\n",
    "def compute_attractiveness_for_reel_from_frames(frames16: list[np.ndarray]) -> dict:\n",
    "    # Mirror your original wrapperâ€™s empty behaviour\n",
    "    empty = {\n",
    "        \"best_frame_idx\": None,\n",
    "        \"lighting\": np.nan,\n",
    "        \"sharpness\": np.nan,\n",
    "        \"face_area_frac\": np.nan,\n",
    "        \"center_offset_norm\": np.nan,\n",
    "        \"aesthetic_face_0_10\": np.nan,\n",
    "        \"aesthetic_full_0_10\": np.nan,\n",
    "        \"multi_cue_attr_0_10\": np.nan,\n",
    "    }\n",
    "    if not frames16:\n",
    "        return empty\n",
    "\n",
    "    best_idx, best_frame, best_face = select_best_face_frame(frames16)\n",
    "    if best_frame is None or best_face is None:\n",
    "        return empty\n",
    "\n",
    "    lighting = compute_lighting_score(best_frame)\n",
    "    sharpness = compute_sharpness_score(best_frame)\n",
    "    face_area_frac, center_offset_norm = face_cues(best_frame.shape, best_face.bbox)\n",
    "\n",
    "    face_img = crop_face(best_frame, best_face)\n",
    "    aest_face = aesthetic_score(face_img)\n",
    "\n",
    "    full_rgb = cv2.cvtColor(best_frame, cv2.COLOR_BGR2RGB)\n",
    "    full_img = Image.fromarray(full_rgb)\n",
    "    aest_full = aesthetic_score(full_img)\n",
    "\n",
    "    fused_score = multi_cue_attractiveness(aest_face, aest_full, lighting, sharpness)\n",
    "\n",
    "    return {\n",
    "        \"best_frame_idx\": best_idx,\n",
    "        \"lighting\": float(lighting),\n",
    "        \"sharpness\": float(sharpness),\n",
    "        \"face_area_frac\": float(face_area_frac),\n",
    "        \"center_offset_norm\": float(center_offset_norm),\n",
    "        \"aesthetic_face_0_10\": float(aest_face),\n",
    "        \"aesthetic_full_0_10\": float(aest_full),\n",
    "        \"multi_cue_attr_0_10\": float(fused_score),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_three_change_metrics_for_frames(frames: list[np.ndarray]) -> dict:\n",
    "    # Same logic as compute_three_change_metrics_for_video, but no VideoCapture\n",
    "    if not frames or len(frames) < 2:\n",
    "        return {\n",
    "            \"n_frames_used\": int(len(frames) if frames else 0),\n",
    "            \"scene_change_count\": 0,\n",
    "            \"scene_change_density\": 0.0,\n",
    "            \"scene_score_0_10\": 0.0,\n",
    "            \"mean_clip_dist\": 0.0,\n",
    "            \"std_clip_dist\": 0.0,\n",
    "            \"clip_score_0_10\": 0.0,\n",
    "            \"mean_hist_dist\": 0.0,\n",
    "            \"std_hist_dist\": 0.0,\n",
    "            \"hist_score_0_10\": 0.0,\n",
    "        }\n",
    "\n",
    "    n_frames = len(frames)\n",
    "\n",
    "    # Histogram distances\n",
    "    hist_dists = []\n",
    "    for i in range(n_frames - 1):\n",
    "        d = hist_distance_bhattacharyya(frames[i], frames[i + 1])\n",
    "        hist_dists.append(d)\n",
    "    hist_dists = np.array(hist_dists, dtype=np.float32)\n",
    "\n",
    "    mean_hist = float(hist_dists.mean())\n",
    "    std_hist = float(hist_dists.std())\n",
    "    mean_hist_clipped = float(np.clip(mean_hist, 0.0, 1.0))\n",
    "    hist_score = round(mean_hist_clipped * 10.0, 2)\n",
    "\n",
    "    # Scene-change density\n",
    "    scene_thresh = 0.5\n",
    "    scene_changes = int((hist_dists > scene_thresh).sum())\n",
    "    scene_change_density = scene_changes / float(n_frames - 1)\n",
    "    scene_density_clipped = float(np.clip(scene_change_density * 5.0, 0.0, 1.0))\n",
    "    scene_score = round(scene_density_clipped * 10.0, 2)\n",
    "\n",
    "    # CLIP embedding distances\n",
    "    clip_embs = [clip_embed_frame(f) for f in frames]\n",
    "    clip_dists = []\n",
    "    for i in range(len(clip_embs) - 1):\n",
    "        d = float(1.0 - np.dot(clip_embs[i], clip_embs[i + 1]))\n",
    "        clip_dists.append(d)\n",
    "    clip_dists = np.array(clip_dists, dtype=np.float32)\n",
    "\n",
    "    mean_clip = float(clip_dists.mean()) if len(clip_dists) else 0.0\n",
    "    std_clip = float(clip_dists.std()) if len(clip_dists) else 0.0\n",
    "    mean_clip_clipped = float(np.clip(mean_clip, 0.0, 1.0))\n",
    "    clip_score = round(mean_clip_clipped * 10.0, 2)\n",
    "\n",
    "    return {\n",
    "        \"n_frames_used\": int(n_frames),\n",
    "        \"scene_change_count\": int(scene_changes),\n",
    "        \"scene_change_density\": float(scene_change_density),\n",
    "        \"scene_score_0_10\": float(scene_score),\n",
    "        \"mean_clip_dist\": float(mean_clip),\n",
    "        \"std_clip_dist\": float(std_clip),\n",
    "        \"clip_score_0_10\": float(clip_score),\n",
    "        \"mean_hist_dist\": float(mean_hist),\n",
    "        \"std_hist_dist\": float(std_hist),\n",
    "        \"hist_score_0_10\": float(hist_score),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_creativity_for_reel_from_frames(frames16: list[np.ndarray]) -> dict:\n",
    "    # This matches your wrapper output: includes hist_score_0_10 etc\n",
    "    try:\n",
    "        return compute_three_change_metrics_for_frames(frames16)\n",
    "    except Exception as e:\n",
    "        print(f\"    âœ— Error during creativity metrics (cached): {repr(e)}\")\n",
    "        return {\n",
    "            \"n_frames_used\": 0,\n",
    "            \"scene_change_count\": 0,\n",
    "            \"scene_change_density\": 0.0,\n",
    "            \"scene_score_0_10\": 0.0,\n",
    "            \"mean_clip_dist\": 0.0,\n",
    "            \"std_clip_dist\": 0.0,\n",
    "            \"clip_score_0_10\": 0.0,\n",
    "            \"mean_hist_dist\": 0.0,\n",
    "            \"std_hist_dist\": 0.0,\n",
    "            \"hist_score_0_10\": 0.0,\n",
    "        }\n",
    "\n",
    "\n",
    "def compute_caption_flag_from_samples(caption_samples: list[tuple[float, np.ndarray]], duration: float) -> dict:\n",
    "    if (not caption_samples) or duration <= 0:\n",
    "        return {\n",
    "            \"has_dynamic_captions\": int(False),\n",
    "            \"caption_style\": \"none\",\n",
    "            \"num_segments\": 0,\n",
    "            \"caption_coverage\": 0.0,\n",
    "        }\n",
    "\n",
    "    # Build timeline using existing OCR helper\n",
    "    timeline: list[tuple[float, str]] = []\n",
    "    for t_sec, frame in caption_samples:\n",
    "        txt = ocr_caption_text(frame)  # uses your global EasyOCR reader\n",
    "        timeline.append((float(t_sec), txt))\n",
    "\n",
    "    segments = timeline_to_segments(timeline, duration)\n",
    "    classification = classify_caption_style(segments, duration)\n",
    "\n",
    "    return {\n",
    "        \"has_dynamic_captions\": int(bool(classification.get(\"has_dynamic_captions\", False))),\n",
    "        \"caption_style\": classification.get(\"style\", \"none\"),\n",
    "        \"num_segments\": int(classification.get(\"num_segments\", 0)),\n",
    "        \"caption_coverage\": float(classification.get(\"caption_coverage\", 0.0)),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_accessories_for_reel_from_frames(accessory_frames: list[np.ndarray]) -> dict:\n",
    "    # Mirror compute_accessories_for_reel behaviour (zeros on failure)\n",
    "    zeros = {cls: 0 for cls in ACCESSORY_CLASSES}\n",
    "    zeros[\"total_accessories\"] = 0\n",
    "\n",
    "    if not accessory_frames:\n",
    "        return zeros\n",
    "\n",
    "    model = get_accessories_model()\n",
    "\n",
    "    from collections import defaultdict\n",
    "    seen_boxes = defaultdict(list)\n",
    "\n",
    "    def iou(boxA, boxB):\n",
    "        xA = max(boxA[0], boxB[0])\n",
    "        yA = max(boxA[1], boxB[1])\n",
    "        xB = min(boxA[2], boxB[2])\n",
    "        yB = min(boxA[3], boxB[3])\n",
    "        inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "        if inter <= 0:\n",
    "            return 0.0\n",
    "        areaA = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n",
    "        areaB = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n",
    "        return float(inter / (areaA + areaB - inter + 1e-9))\n",
    "\n",
    "    conf = 0.35\n",
    "    iou_threshold = 0.5\n",
    "\n",
    "    for frame in accessory_frames:\n",
    "        try:\n",
    "            results = model.predict(source=frame, imgsz=640, conf=conf, verbose=False, device=DEVICE)\n",
    "        except TypeError:\n",
    "            results = model(frame, device=DEVICE)\n",
    "\n",
    "        if not results:\n",
    "            continue\n",
    "        r = results[0]\n",
    "        if getattr(r, \"boxes\", None) is None or len(r.boxes) == 0:\n",
    "            continue\n",
    "\n",
    "        for box, cls_id in zip(r.boxes.xyxy.cpu().numpy(),\n",
    "                               r.boxes.cls.cpu().numpy().astype(int)):\n",
    "            name = model.names[int(cls_id)]\n",
    "            if name not in ACCESSORY_CLASSES:\n",
    "                continue\n",
    "\n",
    "            is_new = True\n",
    "            for prev_box in seen_boxes[name]:\n",
    "                if iou(box, prev_box) > iou_threshold:\n",
    "                    is_new = False\n",
    "                    break\n",
    "            if is_new:\n",
    "                seen_boxes[name].append(box)\n",
    "\n",
    "    class_counts = {cls: len(seen_boxes[cls]) for cls in ACCESSORY_CLASSES}\n",
    "    class_counts[\"total_accessories\"] = int(sum(class_counts.values()))\n",
    "    return class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e543b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Fetching reels for @museumofsoum via Apify...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:07.144Z ACTOR: Pulling container image of build gWxOmlKJ3WrmuIQE3 from registry.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:07.145Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:07.188Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:07.188Z ACTOR: Running under \"LIMITED_PERMISSIONS\" permission level.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:07.849Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.5.1\",\"apifyClientVersion\":\"2.19.0\",\"crawleeVersion\":\"3.15.3\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.21.1\"}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:07.943Z \u001b[32mINFO\u001b[39m  Results Limit [object Object], ACTOR_MAX_PAID_DATASET_ITEMS\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:08.045Z \u001b[32mINFO\u001b[39m  Starting Apify client's scheduler\u001b[90m {\"clientName\":\"CLIENT\"}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:08.141Z \u001b[32mINFO\u001b[39m  [Status message]: Starting the scraper with 1 direct URL(s)\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:08.292Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:12.202Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. The proxy server rejected the request with status code 590 (UPSTREAM503)\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> Status: RUNNING, Message: Crawled 1/2 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> Status: RUNNING, Message: Crawled 2/7 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:54:12.203Z     at ClientRequest.<anonymous> (file:///usr/src/app/dist/984.index.js:16244:109)\u001b[90m {\"id\":\"9l5aok5rCyNIvBX\",\"url\":\"https://i.instagram.com/api/v1/clips/user/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:03.920Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:03.923Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:03.928Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:03.936Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:03.968Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:08.293Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":10877,\"requestsFinishedPerMinute\":2,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":21754,\"requestsTotal\":2,\"crawlerRuntimeMillis\":60099,\"retryHistogram\":[1,1]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:08.296Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":5,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:37.034Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:37.038Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:37.040Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:37.043Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:55:37.044Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:08.292Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":10877,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":21754,\"requestsTotal\":2,\"crawlerRuntimeMillis\":120098,\"retryHistogram\":[1,1]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:08.300Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":5,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:10.234Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":3}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:10.240Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":3}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:10.241Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":3}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:10.242Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":3}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:10.309Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":3}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:43.411Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":4}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:43.412Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":4}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:43.414Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":4}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:43.421Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":4}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:56:43.509Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":4}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:08.292Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":10877,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":21754,\"requestsTotal\":2,\"crawlerRuntimeMillis\":180098,\"retryHistogram\":[1,1]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:08.303Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":5,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:16.718Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":5}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:16.723Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":5}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:16.727Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":5}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:16.774Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":5}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:16.799Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":5}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:49.932Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":6}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:49.937Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":6}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:49.937Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":6}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:50.010Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":6}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:57:50.011Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":6}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:08.292Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":10877,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":21754,\"requestsTotal\":2,\"crawlerRuntimeMillis\":240098,\"retryHistogram\":[1,1]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:08.306Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":5,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:23.227Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":7}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:23.231Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":7}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:23.232Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":7}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:23.245Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":7}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:23.253Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":7}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:56.417Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":8}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:56.421Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":8}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:56.439Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":8}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:56.442Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":8}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:58:56.453Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":8}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:08.292Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":10877,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":21754,\"requestsTotal\":2,\"crawlerRuntimeMillis\":300099,\"retryHistogram\":[1,1]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:18.306Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":5,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:29.855Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":9}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:29.856Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":9}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:29.858Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":9}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:29.868Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":9}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:29.878Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":9}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.934Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. socket hang up\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.935Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15760:21)\u001b[90m {\"id\":\"NSCpa7yYJrjjXEG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":10}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.936Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. socket hang up\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.936Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15760:21)\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":10}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.936Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. socket hang up\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.937Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15760:21)\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":10}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.937Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. socket hang up\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.938Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15760:21)\u001b[90m {\"id\":\"ogYyHZr7kpRefIP\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":10}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.939Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. socket hang up\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:43.939Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15760:21)\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":10}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:49.316Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked, retrying it again with different session\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:49.317Z     at handlePostDetails (file:///usr/src/app/dist/index.js:44:611846)\u001b[90m {\"id\":\"oUY4D2KOrgBQmCh\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":11}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:50.360Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked, retrying it again with different session\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:50.361Z     at handlePostDetails (file:///usr/src/app/dist/index.js:44:611846)\u001b[90m {\"id\":\"lnw89Q0MLhxGFuO\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":11}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:58.321Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:58.441Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":7,\"requestsFailed\":0,\"retryHistogram\":[1,1,null,null,null,null,null,null,null,null,3,2],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":5136,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":35951,\"requestsTotal\":7,\"crawlerRuntimeMillis\":350248}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:58.442Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Finished! Total 7 requests: 7 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:58.443Z \u001b[32mINFO\u001b[39m  [Status message]: Scraper finished\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> 2025-12-24T13:59:58.590Z \u001b[32mINFO\u001b[39m  Stopping Apify client's scheduler\u001b[90m {\"clientName\":\"CLIENT\"}\u001b[39m\n",
      "\u001b[36m[apify.instagram-reel-scraper runId:dtJu13uee6UqyfIjh]\u001b[0m -> Status: SUCCEEDED, Message: Scraper finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ 5 valid reels for @museumofsoum\n",
      "    ðŸ’¬ Batch deep comments: 5 urls, limit=150\n",
      "actor caled ****\n",
      "{'id': 'wt56SEA26CQwSzjCT', 'actId': 'SbK00X0JYCPblD2wp', 'userId': 'WhLkpc5q3EVJ3CFLb', 'startedAt': datetime.datetime(2025, 12, 24, 14, 0, 6, 995000, tzinfo=datetime.timezone.utc), 'finishedAt': None, 'status': 'READY', 'meta': {'origin': 'API', 'userAgent': 'ApifyClient/2.2.1 (win32; Python/3.13.7); isAtHome/False'}, 'stats': {'inputBodyLen': 294, 'migrationCount': 0, 'rebootCount': 0, 'restartCount': 0, 'resurrectCount': 0, 'computeUnits': 0}, 'options': {'build': 'latest', 'timeoutSecs': 30000, 'memoryMbytes': 1024, 'maxTotalChargeUsd': 184.447036, 'diskMbytes': 2048}, 'buildId': 'ELS03AiyDrXa7qkSU', 'defaultKeyValueStoreId': 'rvWKwNzgWiiS4EAKC', 'defaultDatasetId': 'KSQJ1bwWRABMEbrYF', 'defaultRequestQueueId': 'KsDf1bT4neLp8zPUs', 'pricingInfo': {'minimalMaxTotalChargeUsd': None, 'pricingModel': 'PAY_PER_EVENT', 'isPriceChangeNotificationSuppressed': True, 'createdAt': datetime.datetime(2025, 12, 12, 13, 3, 57, 603000, tzinfo=datetime.timezone.utc), 'startedAt': datetime.datetime(2025, 12, 12, 13, 3, 57, 603000, tzinfo=datetime.timezone.utc), 'apifyMarginPercentage': 0.2, 'pricingPerEvent': {'actorChargeEvents': {'comment': {'eventTitle': 'Comment', 'eventDescription': 'Each comment written to the dataset', 'isOneTimeEvent': False, 'eventPriceUsd': 0.0023}}}}, 'chargedEventCounts': {'comment': 0}, 'platformUsageBillingModel': 'DEVELOPER', 'accountedChargedEventCounts': {'comment': 0}, 'generalAccess': 'FOLLOW_USER_SETTING', 'buildNumber': '0.0.360', 'containerUrl': 'https://8vizvizbzefg.runs.apify.net', 'usageTotalUsd': 0}\n",
      "Fetching CDN URL for: https://www.instagram.com/p/DQoRSPWDewf/\n",
      "Fetching CDN URL for: https://www.instagram.com/p/DRjbAw6DRD8/\n",
      "Fetching CDN URL for: https://www.instagram.com/p/C_5FVUuql9u/\n",
      "Fetching CDN URL for: https://www.instagram.com/p/C3ucjNlpUvk/\n",
      "Fetching CDN URL for: https://www.instagram.com/p/C63TimvpYcE/\n",
      "CDN URL obtained: https://scontent-iad3-1.cdninstagram.com/o1/v/t16/f2/m69/AQNaqjU8tfu58ONRbUiKzNKQz93j99f93r3rzUzHTydvoPzw-iSVEeGsUwnVNbnHPBu8o40wlbMAuRsGtiIX7L49.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNzIwLmJhc2VsaW5lIn0&_nc_cat=101&vs=4058245797653782_1855575107&_nc_vs=HBksFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HQXU0VUNLeTJOVjZ3bzhIQUdXa3F1RTNLUzFuYnNwVEFRQUYVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HS1lnVUNLbWl5SThmajRFQU1ydHBjTDM3SThCYnN0VEFRQUYVAgLIARIAKAAYABsAFQAAJoCIhKWV4M0%2FFQIoAkMzLBdAIZmZmZmZmhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=7eb832af80&ccb=9-4&oh=00_AfnSXMfhqu3Po_rSvpnfka1rvkOU0VkGRCQ1pRh9oX0FFQ&oe=694DD5B7&_nc_sid=10d13b\n",
      "Downloading reel 0 from: https://scontent-iad3-1.cdninstagram.com/o1/v/t16/f2/m69/AQNaqjU8tfu58ONRbUiKzNKQz93j99f93r3rzUzHTydvoPzw-iSVEeGsUwnVNbnHPBu8o40wlbMAuRsGtiIX7L49.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNzIwLmJhc2VsaW5lIn0&_nc_cat=101&vs=4058245797653782_1855575107&_nc_vs=HBksFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HQXU0VUNLeTJOVjZ3bzhIQUdXa3F1RTNLUzFuYnNwVEFRQUYVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HS1lnVUNLbWl5SThmajRFQU1ydHBjTDM3SThCYnN0VEFRQUYVAgLIARIAKAAYABsAFQAAJoCIhKWV4M0%2FFQIoAkMzLBdAIZmZmZmZmhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=7eb832af80&ccb=9-4&oh=00_AfnSXMfhqu3Po_rSvpnfka1rvkOU0VkGRCQ1pRh9oX0FFQ&oe=694DD5B7&_nc_sid=10d13b\n",
      "CDN URL obtained: https://scontent-iad3-2.cdninstagram.com/o1/v/t16/f2/m86/AQMiuAyZzTgq3RlhZK8oEBlBtbqZ1uWMN9fczbN6hCXUYb9USw_kMTT31ngVwzX_00vT8uCZ0OugCQY0PVS2oc-xEa602pG4GP4Dy04.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuMzYwLmJhc2VsaW5lIn0&_nc_cat=105&vs=3490806301219064_4117791696&_nc_vs=HBksFQIYUmlnX3hwdl9yZWVsc19wZXJtYW5lbnRfc3JfcHJvZC83QzRENzE3NkI3RTNEMDcxRTI4N0JBRThEODA1RjE4NV92aWRlb19kYXNoaW5pdC5tcDQVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HRFoyYXh0RmF1cjZmSUlFQU4tRE5XM0RUVHNSYnFfRUFBQUYVAgLIARIAKAAYABsAFQAAJq7%2F5d7J8P0%2FFQIoAkMzLBdAQK7ZFocrAhgSZGFzaF9iYXNlbGluZV8zX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=943ec5db17&ccb=9-4&oh=00_AfmCM7NORZl5aVBJdKBkveiro65vcElRAyMDzAnCSNYmsQ&oe=694DDB69&_nc_sid=10d13b\n",
      "Downloading reel 2 from: https://scontent-iad3-2.cdninstagram.com/o1/v/t16/f2/m86/AQMiuAyZzTgq3RlhZK8oEBlBtbqZ1uWMN9fczbN6hCXUYb9USw_kMTT31ngVwzX_00vT8uCZ0OugCQY0PVS2oc-xEa602pG4GP4Dy04.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuMzYwLmJhc2VsaW5lIn0&_nc_cat=105&vs=3490806301219064_4117791696&_nc_vs=HBksFQIYUmlnX3hwdl9yZWVsc19wZXJtYW5lbnRfc3JfcHJvZC83QzRENzE3NkI3RTNEMDcxRTI4N0JBRThEODA1RjE4NV92aWRlb19kYXNoaW5pdC5tcDQVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HRFoyYXh0RmF1cjZmSUlFQU4tRE5XM0RUVHNSYnFfRUFBQUYVAgLIARIAKAAYABsAFQAAJq7%2F5d7J8P0%2FFQIoAkMzLBdAQK7ZFocrAhgSZGFzaF9iYXNlbGluZV8zX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=943ec5db17&ccb=9-4&oh=00_AfmCM7NORZl5aVBJdKBkveiro65vcElRAyMDzAnCSNYmsQ&oe=694DDB69&_nc_sid=10d13b\n",
      "CDN URL obtained: https://scontent-iad3-1.cdninstagram.com/o1/v/t16/f2/m82/AQPBpF4y-on2ltgBhbvTbuEZmTZYRaDo6Q2VnAFQ_mJORJPAONIL0b-xgJBvxTamQ3Fes-tVFn33FVCwbiXCczxaL1Pp2gIUCQmTWA0.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNDgwLmJhc2VsaW5lIn0&_nc_cat=102&vs=718962230343291_3055746138&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC9FRTQyQ0FFNzNDOUVDQ0UwNzA4NEQ5MzYwOTJDQTU4Ql92aWRlb19kYXNoaW5pdC5tcDQVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HTzZoaHhsQ0lYMUgtanNEQU9Qc2luVVVzNVI5YnFfRUFBQUYVAgLIARIAKAAYABsAFQAAJvir0Oih2O9AFQIoAkMzLBdAJO6XjU%2FfOxgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=9db5aaf3ba&ccb=9-4&oh=00_Afncw4RjeKV1MwEswABZ46LQBDYQzU3Nf873dpCYDjonyg&oe=694DC74A&_nc_sid=10d13b\n",
      "Downloading reel 3 from: https://scontent-iad3-1.cdninstagram.com/o1/v/t16/f2/m82/AQPBpF4y-on2ltgBhbvTbuEZmTZYRaDo6Q2VnAFQ_mJORJPAONIL0b-xgJBvxTamQ3Fes-tVFn33FVCwbiXCczxaL1Pp2gIUCQmTWA0.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNDgwLmJhc2VsaW5lIn0&_nc_cat=102&vs=718962230343291_3055746138&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC9FRTQyQ0FFNzNDOUVDQ0UwNzA4NEQ5MzYwOTJDQTU4Ql92aWRlb19kYXNoaW5pdC5tcDQVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HTzZoaHhsQ0lYMUgtanNEQU9Qc2luVVVzNVI5YnFfRUFBQUYVAgLIARIAKAAYABsAFQAAJvir0Oih2O9AFQIoAkMzLBdAJO6XjU%2FfOxgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=9db5aaf3ba&ccb=9-4&oh=00_Afncw4RjeKV1MwEswABZ46LQBDYQzU3Nf873dpCYDjonyg&oe=694DC74A&_nc_sid=10d13b\n",
      "CDN URL obtained: https://scontent-iad3-1.cdninstagram.com/o1/v/t16/f2/m69/AQNwrHCEqqOUrdNksxW0bbOTiu-z8fva30BIM1ICWctzBGD2660enfyIyH0uG8r0-g_dKisUSMQozc_pHtA0ju4u.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNzIwLmJhc2VsaW5lIn0&_nc_cat=107&vs=1318068626740914_3367121923&_nc_vs=HBksFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HSXAzRWlOUXhwZUVqWW9HQUhtMFhlTHd4UlphYnNwVEFRQUYVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HRHIyX3lJV3Jla2gwVFVFQUpaWDBLVGNrU3dTYnN0VEFRQUYVAgLIARIAKAAYABsAFQAAJoDvpoPs7s4%2FFQIoAkMzLBdALXdLxqfvnhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=ce3ec23fac&ccb=9-4&oh=00_Afm9p0dUZ5gSYeI0r3tSvoKeQM3OvQpiwTStIJGSgbJXtQ&oe=694DD868&_nc_sid=10d13b\n",
      "Downloading reel 1 from: https://scontent-iad3-1.cdninstagram.com/o1/v/t16/f2/m69/AQNwrHCEqqOUrdNksxW0bbOTiu-z8fva30BIM1ICWctzBGD2660enfyIyH0uG8r0-g_dKisUSMQozc_pHtA0ju4u.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNzIwLmJhc2VsaW5lIn0&_nc_cat=107&vs=1318068626740914_3367121923&_nc_vs=HBksFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HSXAzRWlOUXhwZUVqWW9HQUhtMFhlTHd4UlphYnNwVEFRQUYVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HRHIyX3lJV3Jla2gwVFVFQUpaWDBLVGNrU3dTYnN0VEFRQUYVAgLIARIAKAAYABsAFQAAJoDvpoPs7s4%2FFQIoAkMzLBdALXdLxqfvnhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=ce3ec23fac&ccb=9-4&oh=00_Afm9p0dUZ5gSYeI0r3tSvoKeQM3OvQpiwTStIJGSgbJXtQ&oe=694DD868&_nc_sid=10d13b\n",
      "CDN URL obtained: https://scontent-iad3-2.cdninstagram.com/o1/v/t16/f2/m82/AQN68sldqSg5t50AkqYnZVDyXbCrSsK5_hu6RXcDDsDOOnF4ieeXTDzcuCfuGamOsRqM47yU_uPF2pgeLVC91Td2UikPTX2cCuJ4Vdg.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNzIwLmJhc2VsaW5lIn0&_nc_cat=111&vs=412702778345409_2638495776&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC80ODRGQzRFNUIwNjE2QkNBQTVBNUUyQUQ1RjQ3QjQ4MF92aWRlb19kYXNoaW5pdC5tcDQVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HRDNCQkJwTGNYaXc4YUFDQU5pYUZGZGczZDhmYnFfRUFBQUYVAgLIARIAKAAYABsAFQAAJtTivuPvjoRAFQIoAkMzLBdAJ92yLQ5WBBgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=c86799e58e&ccb=9-4&oh=00_AfkXZoXM8qQ_F-Bb8XuqjgM6W0rzp5i5HHpng6F9SJ_zng&oe=694DCF05&_nc_sid=10d13b\n",
      "Downloading reel 4 from: https://scontent-iad3-2.cdninstagram.com/o1/v/t16/f2/m82/AQN68sldqSg5t50AkqYnZVDyXbCrSsK5_hu6RXcDDsDOOnF4ieeXTDzcuCfuGamOsRqM47yU_uPF2pgeLVC91Td2UikPTX2cCuJ4Vdg.mp4?stp=dst-mp4&efg=eyJxZV9ncm91cHMiOiJbXCJpZ193ZWJfZGVsaXZlcnlfdnRzX290ZlwiXSIsInZlbmNvZGVfdGFnIjoidnRzX3ZvZF91cmxnZW4uY2xpcHMuYzIuNzIwLmJhc2VsaW5lIn0&_nc_cat=111&vs=412702778345409_2638495776&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC80ODRGQzRFNUIwNjE2QkNBQTVBNUUyQUQ1RjQ3QjQ4MF92aWRlb19kYXNoaW5pdC5tcDQVAALIARIAFQIYOnBhc3N0aHJvdWdoX2V2ZXJzdG9yZS9HRDNCQkJwTGNYaXc4YUFDQU5pYUZGZGczZDhmYnFfRUFBQUYVAgLIARIAKAAYABsAFQAAJtTivuPvjoRAFQIoAkMzLBdAJ92yLQ5WBBgSZGFzaF9iYXNlbGluZV8xX3YxEQB1%2Fgdl5p0BAA%3D%3D&_nc_rid=c86799e58e&ccb=9-4&oh=00_AfkXZoXM8qQ_F-Bb8XuqjgM6W0rzp5i5HHpng6F9SJ_zng&oe=694DCF05&_nc_sid=10d13b\n",
      " Reel 3 downloaded successfully\n",
      " Reel 0 downloaded successfully\n",
      " Reel 1 downloaded successfully\n",
      " Reel 4 downloaded successfully\n",
      " Reel 2 downloaded successfully\n",
      "    ðŸŽ™ Transcribing audio with Whisper ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ— Error during creativity metrics (cached): NameError(\"name 'hist_distance_bhattacharyya' is not defined\")\n",
      "    ðŸŽ™ Transcribing audio with Whisper ...\n",
      "    âœ— Error during creativity metrics (cached): NameError(\"name 'hist_distance_bhattacharyya' is not defined\")\n",
      "    ðŸŽ™ Transcribing audio with Whisper ...\n",
      "    âœ— Error during creativity metrics (cached): NameError(\"name 'hist_distance_bhattacharyya' is not defined\")\n",
      "    ðŸŽ™ Transcribing audio with Whisper ...\n",
      "    âœ— Error during creativity metrics (cached): NameError(\"name 'hist_distance_bhattacharyya' is not defined\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ðŸŽ™ Transcribing audio with Whisper ...\n",
      "    âœ— Error during creativity metrics (cached): NameError(\"name 'hist_distance_bhattacharyya' is not defined\")\n",
      "Done.\n",
      "df_all_reels: (5, 72)\n",
      "df_sun_frames: (4, 5)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4 â€” MAIN JOINT LOOP: CREATOR â†’ APIFY â†’ DOWNLOAD ONCE â†’ ALL METRICS\n",
    "#   âœ… Uses ONE deep-comment run per creator (official apify/instagram-comment-scraper)\n",
    "#   âœ… Keeps creator list AS-IS (no slicing here)\n",
    "#   âœ… No caching (clears known caches)\n",
    "#   âœ… Gemini timed as TOTAL only\n",
    "# =============================================================================\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Scope\n",
    "\n",
    "MAX_REELS_PER_CREATOR = 5\n",
    "MAX_DOWNLOAD_WORKERS = 10\n",
    "CREATOR_LIST = [\n",
    "    \"museumofsoum\",\n",
    "    # \"mahiekasharma\",\n",
    "    # \"riapalkar\",\n",
    "    # \"jynellefernandes\",\n",
    "    # \"reneestorymode\",\n",
    "    # \"prachi_hotchandani\",\n",
    "    # \"yashvi.bhaia\",\n",
    "    # \"freyaathakur\",\n",
    "    # \"sheenablends\",\n",
    "    # \"introvert.huyarr\",\n",
    "    # \"akankshakommirelly\",\n",
    "    # \"gaadha._\",\n",
    "    # \"50shadesofgargi\",\n",
    "    # \"badassbrownbeauty\",\n",
    "    # \"ponnu_16\",\n",
    "    # \"malavika.vjn\",\n",
    "    # \"podi.dosa\",\n",
    "    # \"alsoshweta_\",\n",
    "    # \"books_andscribbles\",\n",
    "    # \"abhishreeakolkar\",\n",
    "    # \"indira.musings\",\n",
    "    # \"an_had_fun_\",\n",
    "    # \"melissa\",\n",
    "    # \"arenavitch\",\n",
    "    # \"neytirii__\",\n",
    "    # \"tavishimukherjee\",\n",
    "    # \"chhetrisumiran\",\n",
    "    # \"nutellaonella\",\n",
    "    # \"meghaa_a.a\",\n",
    "    # \"okayaryaa\",\n",
    "    # \"vanessavnoronha\",\n",
    "    # \"blendbyneesh\",\n",
    "    # \"sirine_badri98\",\n",
    "    # \"shivangi_mishraaaa\",\n",
    "    # \"arundhati_02\",\n",
    "    # \"ananya.jayaswal\",\n",
    "    # \"nipunkapur\",\n",
    "    # \"amitasana_\",\n",
    "    # \"himanshikarmaa\",\n",
    "    # \"also_shweta\",\n",
    "    # \"archanaadas_\",\n",
    "    # \"perksofbeing_rajanna\",\n",
    "    # \"_daya._____\",\n",
    "    # \"sulaikha_ibrahim\",\n",
    "    # \"santria_s\",\n",
    "    # \"yuktha\",\n",
    "    # \"stuti26k\",\n",
    "    # \"kajoldashkar\",\n",
    "    # \"simonekadne\",\n",
    "    # \"s.ojacat\",\n",
    "    # \"viibch\",\n",
    "    # \"stitchyourmap\",\n",
    "    # \"estarishita\",\n",
    "    # \"_alisha_philip\",\n",
    "    # \"prernamasseyy\",\n",
    "    # \"_all_bymyself_\",\n",
    "    # \"krupa11._\",\n",
    "    # \"jaseeyaa\",\n",
    "    # \"manyaamishraa\",\n",
    "    # \"poorvayyy\",\n",
    "    # \"vaibhaviananya.22\",\n",
    "    # \"rithink_skin\",\n",
    "    # \"anjusha_george\",\n",
    "    # \"subikshashivakumar\",\n",
    "    # \"fizillionbucks\",\n",
    "    # \"chahat__kakkar\",\n",
    "    # \"siddhidhanawadee\",\n",
    "    # \"thebasu___\",\n",
    "    # \"urwatchingsptv_\",\n",
    "    # \"_devikaaaa_\",\n",
    "    # \"radhikachhabra_\",\n",
    "    # \"shubhra.vaity\",\n",
    "    # \"shivanishahu_curly\",\n",
    "    # \"reetuu.k\",\n",
    "    # \"taneesho\",\n",
    "    # \"kritikakalraa\",\n",
    "    # \"vedangi.x\",\n",
    "]\n",
    "# Clear any in-memory caches (optional but matches your \"no caching\" request)\n",
    "for _name in [\"_download_cache\", \"_transcript_cache\"]:\n",
    "    try:\n",
    "        globals()[_name].clear()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Fallback timers if your timing framework isn't already installed\n",
    "if \"timed_block\" not in globals():\n",
    "    from contextlib import contextmanager\n",
    "    TIMING_ROWS = []\n",
    "    def record(kind, name, duration_s, **meta):\n",
    "        TIMING_ROWS.append({\"kind\": kind, \"name\": name, \"duration_s\": duration_s, **meta})\n",
    "    @contextmanager\n",
    "    def timed_block(name, kind=\"mainloop\", **meta):\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            record(kind, name, time.perf_counter() - t0, **meta)\n",
    "\n",
    "def download_reel_uncached(reel_url: str, reel_no: int, task_id: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Uses your existing get_files_gem() but avoids any local caching wrapper.\n",
    "    Returns local video path or None.\n",
    "    \"\"\"\n",
    "    out = get_files_gem(REEL_URL=reel_url, REEL_NO=str(reel_no), task_id=task_id)\n",
    "    if not out:\n",
    "        return None\n",
    "    if isinstance(out, dict):\n",
    "        path = out.get(\"path\")\n",
    "    else:\n",
    "        path = out[0] if isinstance(out, (list, tuple)) and out else out\n",
    "    return path if path else None\n",
    "\n",
    "all_rows = []\n",
    "sun_frame_rows = []\n",
    "\n",
    "for creator in CREATOR_LIST:\n",
    "    # 1) Fetch reels (NO CACHE)\n",
    "    with timed_block(\"fetch_reels_from_apify\", creator=creator):\n",
    "        df_reels = fetch_reels_from_apify(creator, max_items=MAX_REELS_PER_CREATOR)\n",
    "\n",
    "    if df_reels is None or df_reels.empty:\n",
    "        continue\n",
    "\n",
    "    df_reels = df_reels.head(MAX_REELS_PER_CREATOR).reset_index(drop=True)\n",
    "\n",
    "    # Normalize reel URLs once for joining comments reliably\n",
    "    df_reels[\"reel_url_norm\"] = df_reels[\"reel_url\"].apply(_norm_ig_url)\n",
    "\n",
    "    # 2) Batch deep comments ONCE for this creator (timed + component timings inside function)\n",
    "    reel_urls_norm = df_reels[\"reel_url_norm\"].tolist()\n",
    "    with timed_block(\"fetch_deep_comments_apify_batch\", creator=creator, n_reels=len(reel_urls_norm)):\n",
    "        raw_comments_map = fetch_deep_comments_apify_batch(\n",
    "            reel_urls=reel_urls_norm,          # already normalized\n",
    "            max_comments_per_url=150,\n",
    "            # creator=creator,\n",
    "        )\n",
    "\n",
    "    # 3) Pre-download reels in parallel (production-like)\n",
    "    download_map = {}\n",
    "    with timed_block(\"download_batch\", creator=creator, reels=len(df_reels)):\n",
    "        with ThreadPoolExecutor(max_workers=MAX_DOWNLOAD_WORKERS) as ex:\n",
    "            futs = {}\n",
    "            for i, r in df_reels.iterrows():\n",
    "                reel_url = r[\"reel_url\"]\n",
    "                task_id = f\"joint_{creator}\"\n",
    "                fut = ex.submit(download_reel_uncached, reel_url, i, task_id)\n",
    "                futs[fut] = reel_url\n",
    "\n",
    "            for fut in as_completed(futs):\n",
    "                reel_url = futs[fut]\n",
    "                try:\n",
    "                    download_map[reel_url] = fut.result()\n",
    "                except Exception:\n",
    "                    download_map[reel_url] = None\n",
    "\n",
    "    # 4) Feature extraction per reel (timed per call)\n",
    "    # 4) Feature extraction per reel (decode ONCE, reuse)\n",
    "    for reel_idx, row in df_reels.iterrows():\n",
    "        reel_url = row[\"reel_url\"]\n",
    "        reel_url_norm = row[\"reel_url_norm\"]\n",
    "        caption = row.get(\"caption\", \"\") or \"\"\n",
    "        video_path = download_map.get(reel_url)\n",
    "\n",
    "        if not video_path or not os.path.exists(video_path):\n",
    "            continue\n",
    "\n",
    "        # --- decode once ---\n",
    "        with timed_block(\"decode_video_once\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            decoded = decode_video_once_for_all_tasks(video_path)\n",
    "\n",
    "        # transcript step unchanged\n",
    "        with timed_block(\"transcribe_reel\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            transcript = transcribe_reel(video_path, reel_url=reel_url, force=False)\n",
    "\n",
    "        with timed_block(\"english_percentage\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            eng_pct = english_percentage(transcript or \"\") if transcript else 0.0\n",
    "\n",
    "        # --- use cached frames ---\n",
    "        with timed_block(\"compute_attractiveness_for_reel_cached\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            attr = compute_attractiveness_for_reel_from_frames(decoded[\"frames16\"])\n",
    "\n",
    "        with timed_block(\"compute_eye_contact_for_reel_cached\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            eye = compute_eye_contact_for_reel_from_frames(decoded[\"eye_frames\"])\n",
    "\n",
    "        with timed_block(\"compute_creativity_for_reel_cached\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            creativity = compute_creativity_for_reel_from_frames(decoded[\"frames16\"])\n",
    "\n",
    "        with timed_block(\"compute_video_caption_flag_for_reel_cached\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            caption_flag = compute_caption_flag_from_samples(decoded[\"caption_samples\"], decoded[\"duration\"])\n",
    "\n",
    "        with timed_block(\"compute_accessories_for_reel_cached\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            accessories = compute_accessories_for_reel_from_frames(decoded[\"accessory_frames\"])\n",
    "\n",
    "        with timed_block(\"compute_sun_exposure_for_reel_cached\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            sun = compute_sun_exposure_for_reel_from_frames(decoded[\"frames5\"])\n",
    "\n",
    "        with timed_block(\"detect_series_from_text\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            series = detect_series_from_text(caption=caption, transcript=transcript)\n",
    "\n",
    "        # Gemini: TOTAL only (unchanged)\n",
    "        with timed_block(\"call_gemini_for_reel_total\", creator=creator, reel_idx=reel_idx, reel_url=reel_url):\n",
    "            gemini_raw = call_gemini_for_reel(caption, transcript, filtered_comments_for_gemini)\n",
    "\n",
    "        # Per-frame sun exposure rows (unchanged format)\n",
    "        sun_frame_rows = []\n",
    "        if isinstance(sun, dict) and \"sun_frame_scores\" in sun:\n",
    "            for j, s in enumerate(sun[\"sun_frame_scores\"]):\n",
    "                sun_frame_rows.append({\n",
    "                    \"creator\": creator,\n",
    "                    \"reel_url\": reel_url,\n",
    "                    \"reel_url_norm\": reel_url_norm,\n",
    "                    \"frame_idx\": j,\n",
    "                    \"sun_frame_score\": float(s),\n",
    "                })\n",
    "\n",
    "        # Build row_out exactly like you already do\n",
    "        out = {\n",
    "            \"creator\": creator,\n",
    "            \"reel_url\": reel_url,\n",
    "            \"reel_url_norm\": reel_url_norm,\n",
    "            \"caption\": caption,\n",
    "            \"transcript\": transcript,\n",
    "            \"english_pct\": float(eng_pct),\n",
    "            \"gemini_raw\": gemini_raw,\n",
    "        }\n",
    "\n",
    "        for name, val in [\n",
    "            (\"attr\", attr),\n",
    "            (\"eye\", eye),\n",
    "            (\"creativity\", creativity),\n",
    "            (\"caption_flag\", caption_flag),\n",
    "            (\"accessories\", accessories),\n",
    "            (\"sun\", sun),\n",
    "            (\"series\", series),\n",
    "        ]:\n",
    "            if isinstance(val, dict):\n",
    "                out.update(val)\n",
    "            else:\n",
    "                out[name] = val\n",
    "\n",
    "        all_rows.append(out)\n",
    "        # sun_frame_rows_all.extend(sun_frame_rows)\n",
    "\n",
    "\n",
    "df_all_reels = pd.DataFrame(all_rows)\n",
    "df_sun_frames = pd.DataFrame(sun_frame_rows)\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"df_all_reels:\", df_all_reels.shape)\n",
    "print(\"df_sun_frames:\", df_sun_frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef9bb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>name</th>\n",
       "      <th>calls</th>\n",
       "      <th>total_s</th>\n",
       "      <th>mean_s</th>\n",
       "      <th>p95_s</th>\n",
       "      <th>p99_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_video_caption_flag_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>136.915909</td>\n",
       "      <td>27.383182</td>\n",
       "      <td>43.343957</td>\n",
       "      <td>46.563882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_video_caption_flag_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>136.915859</td>\n",
       "      <td>27.383172</td>\n",
       "      <td>43.343948</td>\n",
       "      <td>46.563873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>block</td>\n",
       "      <td>fetch_deep_comments_apify_batch</td>\n",
       "      <td>1</td>\n",
       "      <td>84.944373</td>\n",
       "      <td>84.944373</td>\n",
       "      <td>84.944373</td>\n",
       "      <td>84.944373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>block</td>\n",
       "      <td>transcribe_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>82.575267</td>\n",
       "      <td>16.515053</td>\n",
       "      <td>29.884679</td>\n",
       "      <td>32.106721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>transcribe_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>82.575220</td>\n",
       "      <td>16.515044</td>\n",
       "      <td>29.884670</td>\n",
       "      <td>32.106713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_eye_contact_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>67.447551</td>\n",
       "      <td>13.489510</td>\n",
       "      <td>17.971850</td>\n",
       "      <td>18.164972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_eye_contact_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>67.447502</td>\n",
       "      <td>13.489500</td>\n",
       "      <td>17.971839</td>\n",
       "      <td>18.164962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_accessories_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>40.906753</td>\n",
       "      <td>8.181351</td>\n",
       "      <td>13.878826</td>\n",
       "      <td>14.737411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_accessories_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>40.906691</td>\n",
       "      <td>8.181338</td>\n",
       "      <td>13.878816</td>\n",
       "      <td>14.737403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>http</td>\n",
       "      <td>requests GET</td>\n",
       "      <td>10</td>\n",
       "      <td>28.397477</td>\n",
       "      <td>2.839748</td>\n",
       "      <td>4.240113</td>\n",
       "      <td>4.351543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_attractiveness_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>25.440475</td>\n",
       "      <td>5.088095</td>\n",
       "      <td>7.516972</td>\n",
       "      <td>7.943148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_attractiveness_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>25.440430</td>\n",
       "      <td>5.088086</td>\n",
       "      <td>7.516964</td>\n",
       "      <td>7.943141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>block</td>\n",
       "      <td>fetch_reels_from_apify</td>\n",
       "      <td>1</td>\n",
       "      <td>20.958699</td>\n",
       "      <td>20.958699</td>\n",
       "      <td>20.958699</td>\n",
       "      <td>20.958699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>fetch_reels_from_apify</td>\n",
       "      <td>1</td>\n",
       "      <td>20.958691</td>\n",
       "      <td>20.958691</td>\n",
       "      <td>20.958691</td>\n",
       "      <td>20.958691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.actor.call</td>\n",
       "      <td>1</td>\n",
       "      <td>20.179111</td>\n",
       "      <td>20.179111</td>\n",
       "      <td>20.179111</td>\n",
       "      <td>20.179111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_creativity_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>11.705302</td>\n",
       "      <td>2.341060</td>\n",
       "      <td>2.847291</td>\n",
       "      <td>2.865309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_creativity_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>11.705253</td>\n",
       "      <td>2.341051</td>\n",
       "      <td>2.847280</td>\n",
       "      <td>2.865299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>block</td>\n",
       "      <td>call_gemini_for_reel_total</td>\n",
       "      <td>5</td>\n",
       "      <td>10.383023</td>\n",
       "      <td>2.076605</td>\n",
       "      <td>2.540203</td>\n",
       "      <td>2.607510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>call_gemini_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>10.382966</td>\n",
       "      <td>2.076593</td>\n",
       "      <td>2.540190</td>\n",
       "      <td>2.607496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>http</td>\n",
       "      <td>httpx POST</td>\n",
       "      <td>5</td>\n",
       "      <td>9.557426</td>\n",
       "      <td>1.911485</td>\n",
       "      <td>2.180497</td>\n",
       "      <td>2.197587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>block</td>\n",
       "      <td>download_batch</td>\n",
       "      <td>1</td>\n",
       "      <td>9.378449</td>\n",
       "      <td>9.378449</td>\n",
       "      <td>9.378449</td>\n",
       "      <td>9.378449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_sun_exposure_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>1.344644</td>\n",
       "      <td>0.268929</td>\n",
       "      <td>0.319419</td>\n",
       "      <td>0.323795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_sun_exposure_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>1.344590</td>\n",
       "      <td>0.268918</td>\n",
       "      <td>0.319407</td>\n",
       "      <td>0.323781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.dataset.list_items</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718649</td>\n",
       "      <td>0.718649</td>\n",
       "      <td>0.718649</td>\n",
       "      <td>0.718649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>http</td>\n",
       "      <td>requests HEAD</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621792</td>\n",
       "      <td>0.621792</td>\n",
       "      <td>0.621792</td>\n",
       "      <td>0.621792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>block</td>\n",
       "      <td>english_percentage</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045059</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.042782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>english_percentage</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045035</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.035722</td>\n",
       "      <td>0.042774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>api_component</td>\n",
       "      <td>items_to_df</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.028716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>api_component</td>\n",
       "      <td>normalize_fields</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.015781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>api_component</td>\n",
       "      <td>url_filter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>api_component</td>\n",
       "      <td>flatten_comments</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>block</td>\n",
       "      <td>filter_top_comments_for_gemini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>block</td>\n",
       "      <td>detect_series_from_text</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>filter_top_comments_for_gemini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>detect_series_from_text</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>block</td>\n",
       "      <td>is_music_only_transcript</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>is_music_only_transcript</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>http_json</td>\n",
       "      <td>requests Response.json</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>block</td>\n",
       "      <td>compute_spoken_word_count</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_spoken_word_count</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>block</td>\n",
       "      <td>assign_comments_from_batch</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             kind                                 name  calls     total_s  \\\n",
       "14          block  compute_video_caption_flag_for_reel      5  136.915909   \n",
       "30     feature_fn  compute_video_caption_flag_for_reel      5  136.915859   \n",
       "18          block      fetch_deep_comments_apify_batch      1   84.944373   \n",
       "22          block                      transcribe_reel      5   82.575267   \n",
       "36     feature_fn                      transcribe_reel      5   82.575220   \n",
       "11          block         compute_eye_contact_for_reel      5   67.447551   \n",
       "27     feature_fn         compute_eye_contact_for_reel      5   67.447502   \n",
       "8           block         compute_accessories_for_reel      5   40.906753   \n",
       "24     feature_fn         compute_accessories_for_reel      5   40.906691   \n",
       "38           http                         requests GET     10   28.397477   \n",
       "9           block      compute_attractiveness_for_reel      5   25.440475   \n",
       "25     feature_fn      compute_attractiveness_for_reel      5   25.440430   \n",
       "19          block               fetch_reels_from_apify      1   20.958699   \n",
       "33     feature_fn               fetch_reels_from_apify      1   20.958691   \n",
       "0   api_component                     apify.actor.call      1   20.179111   \n",
       "10          block          compute_creativity_for_reel      5   11.705302   \n",
       "26     feature_fn          compute_creativity_for_reel      5   11.705253   \n",
       "7           block           call_gemini_for_reel_total      5   10.383023   \n",
       "23     feature_fn                 call_gemini_for_reel      5   10.382966   \n",
       "37           http                           httpx POST      5    9.557426   \n",
       "16          block                       download_batch      1    9.378449   \n",
       "13          block        compute_sun_exposure_for_reel      5    1.344644   \n",
       "29     feature_fn        compute_sun_exposure_for_reel      5    1.344590   \n",
       "1   api_component             apify.dataset.list_items      1    0.718649   \n",
       "39           http                        requests HEAD      1    0.621792   \n",
       "17          block                   english_percentage      5    0.045059   \n",
       "32     feature_fn                   english_percentage      5    0.045035   \n",
       "3   api_component                          items_to_df      1    0.028716   \n",
       "4   api_component                     normalize_fields      1    0.015781   \n",
       "5   api_component                           url_filter      1    0.004240   \n",
       "2   api_component                     flatten_comments      1    0.002939   \n",
       "20          block       filter_top_comments_for_gemini      5    0.001013   \n",
       "15          block              detect_series_from_text      5    0.000998   \n",
       "34     feature_fn       filter_top_comments_for_gemini      5    0.000980   \n",
       "31     feature_fn              detect_series_from_text      5    0.000973   \n",
       "21          block             is_music_only_transcript      5    0.000200   \n",
       "35     feature_fn             is_music_only_transcript      5    0.000184   \n",
       "40      http_json               requests Response.json      5    0.000130   \n",
       "12          block            compute_spoken_word_count      5    0.000107   \n",
       "28     feature_fn            compute_spoken_word_count      5    0.000096   \n",
       "6           block           assign_comments_from_batch      5    0.000021   \n",
       "\n",
       "       mean_s      p95_s      p99_s  \n",
       "14  27.383182  43.343957  46.563882  \n",
       "30  27.383172  43.343948  46.563873  \n",
       "18  84.944373  84.944373  84.944373  \n",
       "22  16.515053  29.884679  32.106721  \n",
       "36  16.515044  29.884670  32.106713  \n",
       "11  13.489510  17.971850  18.164972  \n",
       "27  13.489500  17.971839  18.164962  \n",
       "8    8.181351  13.878826  14.737411  \n",
       "24   8.181338  13.878816  14.737403  \n",
       "38   2.839748   4.240113   4.351543  \n",
       "9    5.088095   7.516972   7.943148  \n",
       "25   5.088086   7.516964   7.943141  \n",
       "19  20.958699  20.958699  20.958699  \n",
       "33  20.958691  20.958691  20.958691  \n",
       "0   20.179111  20.179111  20.179111  \n",
       "10   2.341060   2.847291   2.865309  \n",
       "26   2.341051   2.847280   2.865299  \n",
       "7    2.076605   2.540203   2.607510  \n",
       "23   2.076593   2.540190   2.607496  \n",
       "37   1.911485   2.180497   2.197587  \n",
       "16   9.378449   9.378449   9.378449  \n",
       "13   0.268929   0.319419   0.323795  \n",
       "29   0.268918   0.319407   0.323781  \n",
       "1    0.718649   0.718649   0.718649  \n",
       "39   0.621792   0.621792   0.621792  \n",
       "17   0.009012   0.035729   0.042782  \n",
       "32   0.009007   0.035722   0.042774  \n",
       "3    0.028716   0.028716   0.028716  \n",
       "4    0.015781   0.015781   0.015781  \n",
       "5    0.004240   0.004240   0.004240  \n",
       "2    0.002939   0.002939   0.002939  \n",
       "20   0.000203   0.000290   0.000296  \n",
       "15   0.000200   0.000476   0.000535  \n",
       "34   0.000196   0.000283   0.000290  \n",
       "31   0.000195   0.000471   0.000531  \n",
       "21   0.000040   0.000049   0.000050  \n",
       "35   0.000037   0.000045   0.000045  \n",
       "40   0.000026   0.000037   0.000039  \n",
       "12   0.000021   0.000035   0.000037  \n",
       "28   0.000019   0.000032   0.000033  \n",
       "6    0.000004   0.000005   0.000005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>name</th>\n",
       "      <th>calls</th>\n",
       "      <th>mean_s</th>\n",
       "      <th>p95_s</th>\n",
       "      <th>total_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_video_caption_flag_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>27.383172</td>\n",
       "      <td>43.343948</td>\n",
       "      <td>136.915859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>transcribe_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>16.515044</td>\n",
       "      <td>29.884670</td>\n",
       "      <td>82.575220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_eye_contact_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>13.489500</td>\n",
       "      <td>17.971839</td>\n",
       "      <td>67.447502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_accessories_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>8.181338</td>\n",
       "      <td>13.878816</td>\n",
       "      <td>40.906691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>http</td>\n",
       "      <td>requests GET</td>\n",
       "      <td>10</td>\n",
       "      <td>2.839748</td>\n",
       "      <td>4.240113</td>\n",
       "      <td>28.397477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_attractiveness_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>5.088086</td>\n",
       "      <td>7.516964</td>\n",
       "      <td>25.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>fetch_reels_from_apify</td>\n",
       "      <td>1</td>\n",
       "      <td>20.958691</td>\n",
       "      <td>20.958691</td>\n",
       "      <td>20.958691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.actor.call</td>\n",
       "      <td>1</td>\n",
       "      <td>20.179111</td>\n",
       "      <td>20.179111</td>\n",
       "      <td>20.179111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_creativity_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>2.341051</td>\n",
       "      <td>2.847280</td>\n",
       "      <td>11.705253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>call_gemini_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>2.076593</td>\n",
       "      <td>2.540190</td>\n",
       "      <td>10.382966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>http</td>\n",
       "      <td>httpx POST</td>\n",
       "      <td>5</td>\n",
       "      <td>1.911485</td>\n",
       "      <td>2.180497</td>\n",
       "      <td>9.557426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_sun_exposure_for_reel</td>\n",
       "      <td>5</td>\n",
       "      <td>0.268918</td>\n",
       "      <td>0.319407</td>\n",
       "      <td>1.344590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.dataset.list_items</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718649</td>\n",
       "      <td>0.718649</td>\n",
       "      <td>0.718649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>http</td>\n",
       "      <td>requests HEAD</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621792</td>\n",
       "      <td>0.621792</td>\n",
       "      <td>0.621792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>english_percentage</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.035722</td>\n",
       "      <td>0.045035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>api_component</td>\n",
       "      <td>items_to_df</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.028716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>api_component</td>\n",
       "      <td>normalize_fields</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.015781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>api_component</td>\n",
       "      <td>url_filter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.004240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>api_component</td>\n",
       "      <td>flatten_comments</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>filter_top_comments_for_gemini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>detect_series_from_text</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>is_music_only_transcript</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>http_json</td>\n",
       "      <td>requests Response.json</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_spoken_word_count</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             kind                                 name  calls     mean_s  \\\n",
       "13     feature_fn  compute_video_caption_flag_for_reel      5  27.383172   \n",
       "19     feature_fn                      transcribe_reel      5  16.515044   \n",
       "10     feature_fn         compute_eye_contact_for_reel      5  13.489500   \n",
       "7      feature_fn         compute_accessories_for_reel      5   8.181338   \n",
       "21           http                         requests GET     10   2.839748   \n",
       "8      feature_fn      compute_attractiveness_for_reel      5   5.088086   \n",
       "16     feature_fn               fetch_reels_from_apify      1  20.958691   \n",
       "0   api_component                     apify.actor.call      1  20.179111   \n",
       "9      feature_fn          compute_creativity_for_reel      5   2.341051   \n",
       "6      feature_fn                 call_gemini_for_reel      5   2.076593   \n",
       "20           http                           httpx POST      5   1.911485   \n",
       "12     feature_fn        compute_sun_exposure_for_reel      5   0.268918   \n",
       "1   api_component             apify.dataset.list_items      1   0.718649   \n",
       "22           http                        requests HEAD      1   0.621792   \n",
       "15     feature_fn                   english_percentage      5   0.009007   \n",
       "3   api_component                          items_to_df      1   0.028716   \n",
       "4   api_component                     normalize_fields      1   0.015781   \n",
       "5   api_component                           url_filter      1   0.004240   \n",
       "2   api_component                     flatten_comments      1   0.002939   \n",
       "17     feature_fn       filter_top_comments_for_gemini      5   0.000196   \n",
       "14     feature_fn              detect_series_from_text      5   0.000195   \n",
       "18     feature_fn             is_music_only_transcript      5   0.000037   \n",
       "23      http_json               requests Response.json      5   0.000026   \n",
       "11     feature_fn            compute_spoken_word_count      5   0.000019   \n",
       "\n",
       "        p95_s     total_s  \n",
       "13  43.343948  136.915859  \n",
       "19  29.884670   82.575220  \n",
       "10  17.971839   67.447502  \n",
       "7   13.878816   40.906691  \n",
       "21   4.240113   28.397477  \n",
       "8    7.516964   25.440430  \n",
       "16  20.958691   20.958691  \n",
       "0   20.179111   20.179111  \n",
       "9    2.847280   11.705253  \n",
       "6    2.540190   10.382966  \n",
       "20   2.180497    9.557426  \n",
       "12   0.319407    1.344590  \n",
       "1    0.718649    0.718649  \n",
       "22   0.621792    0.621792  \n",
       "15   0.035722    0.045035  \n",
       "3    0.028716    0.028716  \n",
       "4    0.015781    0.015781  \n",
       "5    0.004240    0.004240  \n",
       "2    0.002939    0.002939  \n",
       "17   0.000283    0.000980  \n",
       "14   0.000471    0.000973  \n",
       "18   0.000045    0.000184  \n",
       "23   0.000037    0.000130  \n",
       "11   0.000032    0.000096  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw = timing_report()\n",
    "\n",
    "# Optional: isolate main loop only\n",
    "df_main = df_raw[df_raw[\"kind\"].isin([\"mainloop\", \"feature_fn\", \"api_component\", \"http\", \"http_json\"])].copy()\n",
    "\n",
    "# Example: per-function mean/p95 just for main loop blocks\n",
    "if not df_main.empty:\n",
    "    def p95(x): return float(np.percentile(x, 95)) if len(x) else np.nan\n",
    "    summary = (df_main.groupby([\"kind\", \"name\"])\n",
    "                      .agg(calls=(\"duration_s\",\"count\"), mean_s=(\"duration_s\",\"mean\"), p95_s=(\"duration_s\",p95), total_s=(\"duration_s\",\"sum\"))\n",
    "                      .reset_index()\n",
    "                      .sort_values(\"total_s\", ascending=False))\n",
    "    display(summary)\n",
    "\n",
    "# Save raw if you want\n",
    "# df_raw.to_csv(\"timings_raw1.csv\", index=False)\n",
    "# print(\"Wrote timings_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5dd729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>name</th>\n",
       "      <th>calls</th>\n",
       "      <th>mean_s</th>\n",
       "      <th>p95_s</th>\n",
       "      <th>total_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.comments.actor.call</td>\n",
       "      <td>3</td>\n",
       "      <td>551.783569</td>\n",
       "      <td>929.318475</td>\n",
       "      <td>1655.350708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>transcribe_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>59.121239</td>\n",
       "      <td>214.473017</td>\n",
       "      <td>886.818589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_video_caption_flag_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>48.850336</td>\n",
       "      <td>98.785369</td>\n",
       "      <td>732.755047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_eye_contact_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>16.700554</td>\n",
       "      <td>31.283219</td>\n",
       "      <td>250.508317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_accessories_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>11.799570</td>\n",
       "      <td>32.530280</td>\n",
       "      <td>176.993556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>fetch_reels_from_apify</td>\n",
       "      <td>3</td>\n",
       "      <td>30.924049</td>\n",
       "      <td>41.085053</td>\n",
       "      <td>92.772148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.actor.call</td>\n",
       "      <td>3</td>\n",
       "      <td>30.282994</td>\n",
       "      <td>40.538792</td>\n",
       "      <td>90.848983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http</td>\n",
       "      <td>requests GET</td>\n",
       "      <td>30</td>\n",
       "      <td>2.779366</td>\n",
       "      <td>4.102409</td>\n",
       "      <td>83.380984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_creativity_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>4.745329</td>\n",
       "      <td>7.071366</td>\n",
       "      <td>71.179940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_attractiveness_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>3.955234</td>\n",
       "      <td>8.149124</td>\n",
       "      <td>59.328505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>call_gemini_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>2.070316</td>\n",
       "      <td>2.669838</td>\n",
       "      <td>31.054738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>http</td>\n",
       "      <td>httpx POST</td>\n",
       "      <td>15</td>\n",
       "      <td>2.012555</td>\n",
       "      <td>2.430053</td>\n",
       "      <td>30.188326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.comments.dataset.list_items</td>\n",
       "      <td>3</td>\n",
       "      <td>2.107191</td>\n",
       "      <td>2.975765</td>\n",
       "      <td>6.321574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_sun_exposure_for_reel</td>\n",
       "      <td>15</td>\n",
       "      <td>0.223162</td>\n",
       "      <td>0.447628</td>\n",
       "      <td>3.347428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.dataset.list_items</td>\n",
       "      <td>3</td>\n",
       "      <td>0.623103</td>\n",
       "      <td>0.780609</td>\n",
       "      <td>1.869309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>http</td>\n",
       "      <td>requests HEAD</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632937</td>\n",
       "      <td>0.632937</td>\n",
       "      <td>0.632937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>english_percentage</td>\n",
       "      <td>14</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.042676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>api_component</td>\n",
       "      <td>items_to_df</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.014076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>filter_top_comments_for_gemini</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.010578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>api_component</td>\n",
       "      <td>normalize_fields</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.009753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>compute_spoken_word_count</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.008244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>api_component</td>\n",
       "      <td>url_filter</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.005929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>api_component</td>\n",
       "      <td>flatten_comments</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.004447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>api_component</td>\n",
       "      <td>apify.comments.parse_group</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.004108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>detect_series_from_text</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feature_fn</td>\n",
       "      <td>is_music_only_transcript</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>http_json</td>\n",
       "      <td>requests Response.json</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             kind                                 name  calls      mean_s  \\\n",
       "1   api_component            apify.comments.actor.call      3  551.783569   \n",
       "22     feature_fn                      transcribe_reel     15   59.121239   \n",
       "16     feature_fn  compute_video_caption_flag_for_reel     15   48.850336   \n",
       "13     feature_fn         compute_eye_contact_for_reel     15   16.700554   \n",
       "10     feature_fn         compute_accessories_for_reel     15   11.799570   \n",
       "19     feature_fn               fetch_reels_from_apify      3   30.924049   \n",
       "0   api_component                     apify.actor.call      3   30.282994   \n",
       "24           http                         requests GET     30    2.779366   \n",
       "12     feature_fn          compute_creativity_for_reel     15    4.745329   \n",
       "11     feature_fn      compute_attractiveness_for_reel     15    3.955234   \n",
       "9      feature_fn                 call_gemini_for_reel     15    2.070316   \n",
       "23           http                           httpx POST     15    2.012555   \n",
       "2   api_component    apify.comments.dataset.list_items      3    2.107191   \n",
       "15     feature_fn        compute_sun_exposure_for_reel     15    0.223162   \n",
       "4   api_component             apify.dataset.list_items      3    0.623103   \n",
       "25           http                        requests HEAD      1    0.632937   \n",
       "18     feature_fn                   english_percentage     14    0.003048   \n",
       "6   api_component                          items_to_df      3    0.004692   \n",
       "20     feature_fn       filter_top_comments_for_gemini     15    0.000705   \n",
       "7   api_component                     normalize_fields      3    0.003251   \n",
       "14     feature_fn            compute_spoken_word_count     15    0.000550   \n",
       "8   api_component                           url_filter      3    0.001976   \n",
       "5   api_component                     flatten_comments      3    0.001482   \n",
       "3   api_component           apify.comments.parse_group      3    0.001369   \n",
       "17     feature_fn              detect_series_from_text     15    0.000161   \n",
       "21     feature_fn             is_music_only_transcript     30    0.000026   \n",
       "26      http_json               requests Response.json     15    0.000034   \n",
       "\n",
       "         p95_s      total_s  \n",
       "1   929.318475  1655.350708  \n",
       "22  214.473017   886.818589  \n",
       "16   98.785369   732.755047  \n",
       "13   31.283219   250.508317  \n",
       "10   32.530280   176.993556  \n",
       "19   41.085053    92.772148  \n",
       "0    40.538792    90.848983  \n",
       "24    4.102409    83.380984  \n",
       "12    7.071366    71.179940  \n",
       "11    8.149124    59.328505  \n",
       "9     2.669838    31.054738  \n",
       "23    2.430053    30.188326  \n",
       "2     2.975765     6.321574  \n",
       "15    0.447628     3.347428  \n",
       "4     0.780609     1.869309  \n",
       "25    0.632937     0.632937  \n",
       "18    0.014097     0.042676  \n",
       "6     0.007574     0.014076  \n",
       "20    0.002688     0.010578  \n",
       "7     0.005600     0.009753  \n",
       "14    0.002412     0.008244  \n",
       "8     0.002869     0.005929  \n",
       "5     0.001835     0.004447  \n",
       "3     0.001807     0.004108  \n",
       "17    0.000348     0.002408  \n",
       "21    0.000049     0.000778  \n",
       "26    0.000060     0.000517  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"timings_raw.csv\")\n",
    "\n",
    "# Optional: isolate main loop only\n",
    "df_main = df_raw[df_raw[\"kind\"].isin([\"mainloop\", \"feature_fn\", \"api_component\", \"http\", \"http_json\"])].copy()\n",
    "\n",
    "# Example: per-function mean/p95 just for main loop blocks\n",
    "if not df_main.empty:\n",
    "    def p95(x): return float(np.percentile(x, 95)) if len(x) else np.nan\n",
    "    summary = (df_main.groupby([\"kind\", \"name\"])\n",
    "                      .agg(calls=(\"duration_s\",\"count\"), mean_s=(\"duration_s\",\"mean\"), p95_s=(\"duration_s\",p95), total_s=(\"duration_s\",\"sum\"))\n",
    "                      .reset_index()\n",
    "                      .sort_values(\"total_s\", ascending=False))\n",
    "    display(summary)\n",
    "\n",
    "# Save raw if you want\n",
    "# df_raw.to_csv(\"timings_raw1.csv\", index=False)\n",
    "# print(\"Wrote timings_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>reel_url</th>\n",
       "      <th>caption</th>\n",
       "      <th>transcript</th>\n",
       "      <th>is_music_only</th>\n",
       "      <th>spoken_word_count</th>\n",
       "      <th>english_pct</th>\n",
       "      <th>raw_comments_full</th>\n",
       "      <th>filtered_comments_for_gemini</th>\n",
       "      <th>gemini_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>gemini_genz_word_count</th>\n",
       "      <th>gemini_is_marketing</th>\n",
       "      <th>gemini_is_educational</th>\n",
       "      <th>gemini_is_vlog</th>\n",
       "      <th>gemini_has_humour</th>\n",
       "      <th>gemini_comment_sentiment_counts.questioning</th>\n",
       "      <th>gemini_comment_sentiment_counts.agreeing</th>\n",
       "      <th>gemini_comment_sentiment_counts.appreciating</th>\n",
       "      <th>gemini_comment_sentiment_counts.negative</th>\n",
       "      <th>gemini_comment_sentiment_counts.neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>https://www.instagram.com/p/C63TimvpYcE/</td>\n",
       "      <td>idli sambar for 50yrs till you die\\n\\n.\\n\\n.\\n...</td>\n",
       "      <td>à®‡à®¨à¯à®¤à®¿à®©à¯ˆà®¯à¯à®®à¯ à®‡à®µà®³à¯ à®šà¯Šà®¨à¯à®¤à®°à®¿à®¯à¯‹ à®¤à¯†à®¯à¯à®µà®°à®®à¯ à®ªà®¯à®®à¯‹, à®‡à®©à®¿à®¯à¯‹</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[â¤ï¸, Nice ðŸŒ¹ðŸ«ðŸ‘, Perfect, Gorgeous â¤ï¸, Brahmin a...</td>\n",
       "      <td>[Nice ðŸŒ¹ðŸ«ðŸ‘, Perfect, Gorgeous â¤ï¸, Brahmin ah ?,...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>https://www.instagram.com/p/DRjbAw6DRD8/</td>\n",
       "      <td>pichodi fit check ðŸ¦”\\n\\n#fyp #fypã‚· #fypage #sou...</td>\n",
       "      <td>à®¹à¯‡à®¯à¯ à®¨à¯†à®žà¯à®šà®¿à®²à¯à®®à¯ à®¨à¯€à®šà¯à®®à¯ à®•à®£à¯à®®à®£à®¿à®©à¯ à®µà®¾à®šà®®à¯ à®•à®¾à®Ÿà¯à®Ÿà¯ à®š...</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[ðŸ’ðŸ’, â¤ï¸, So prettyy, ðŸ”¥ðŸ¤, Cute ðŸ¥°ðŸ’šðŸ–¤ðŸ’š, So ðŸ¥°, â¤ï¸ðŸ”¥ðŸ˜...</td>\n",
       "      <td>[So prettyy, Cute ðŸ¥°ðŸ’šðŸ–¤ðŸ’š, So ðŸ¥°, Looking simply a...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>https://www.instagram.com/p/DQoRSPWDewf/</td>\n",
       "      <td>riya and my marej yâ€™all are invited\\n\\n#fypã‚·â¤ï¸...</td>\n",
       "      <td>à®¤à®©à¯à®®à®£à®¿à®¯à¯‡</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[and thatâ€™s when things went south :p, ðŸ˜ðŸ˜ðŸ˜, ðŸ˜ðŸ˜...</td>\n",
       "      <td>[and thatâ€™s when things went south :p, much aw...</td>\n",
       "      <td>{\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>https://www.instagram.com/p/C_5FVUuql9u/</td>\n",
       "      <td>dancing for idli (obv)\\n\\n.\\n#onam #onamcelebr...</td>\n",
       "      <td>sulè©°</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[south indian full course meal, Ek itni slay p...</td>\n",
       "      <td>[south indian full course meal, Ek itni slay p...</td>\n",
       "      <td>{\"genz_word_count\": 1, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>museumofsoum</td>\n",
       "      <td>https://www.instagram.com/p/C3ucjNlpUvk/</td>\n",
       "      <td>my 2020 bangs era in math class \\n\\n#explore #...</td>\n",
       "      <td>Look at me I'm as helpless as a kitten up a tree</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.77</td>\n",
       "      <td>[brother casually dropped a bangerðŸ¥µ, â¤ï¸â¤ï¸â¤ï¸ðŸ”¥ðŸ”¥ðŸ”¥...</td>\n",
       "      <td>[brother casually dropped a bangerðŸ¥µ, @_.jisha....</td>\n",
       "      <td>{\"genz_word_count\": 1, \"is_marketing\": 0, \"is_...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        creator                                  reel_url  \\\n",
       "0  museumofsoum  https://www.instagram.com/p/C63TimvpYcE/   \n",
       "1  museumofsoum  https://www.instagram.com/p/DRjbAw6DRD8/   \n",
       "2  museumofsoum  https://www.instagram.com/p/DQoRSPWDewf/   \n",
       "3  museumofsoum  https://www.instagram.com/p/C_5FVUuql9u/   \n",
       "4  museumofsoum  https://www.instagram.com/p/C3ucjNlpUvk/   \n",
       "\n",
       "                                             caption  \\\n",
       "0  idli sambar for 50yrs till you die\\n\\n.\\n\\n.\\n...   \n",
       "1  pichodi fit check ðŸ¦”\\n\\n#fyp #fypã‚· #fypage #sou...   \n",
       "2  riya and my marej yâ€™all are invited\\n\\n#fypã‚·â¤ï¸...   \n",
       "3  dancing for idli (obv)\\n\\n.\\n#onam #onamcelebr...   \n",
       "4  my 2020 bangs era in math class \\n\\n#explore #...   \n",
       "\n",
       "                                          transcript  is_music_only  \\\n",
       "0    à®‡à®¨à¯à®¤à®¿à®©à¯ˆà®¯à¯à®®à¯ à®‡à®µà®³à¯ à®šà¯Šà®¨à¯à®¤à®°à®¿à®¯à¯‹ à®¤à¯†à®¯à¯à®µà®°à®®à¯ à®ªà®¯à®®à¯‹, à®‡à®©à®¿à®¯à¯‹          False   \n",
       "1  à®¹à¯‡à®¯à¯ à®¨à¯†à®žà¯à®šà®¿à®²à¯à®®à¯ à®¨à¯€à®šà¯à®®à¯ à®•à®£à¯à®®à®£à®¿à®©à¯ à®µà®¾à®šà®®à¯ à®•à®¾à®Ÿà¯à®Ÿà¯ à®š...          False   \n",
       "2                                           à®¤à®©à¯à®®à®£à®¿à®¯à¯‡           True   \n",
       "3                                               sulè©°          False   \n",
       "4   Look at me I'm as helpless as a kitten up a tree          False   \n",
       "\n",
       "   spoken_word_count  english_pct  \\\n",
       "0               16.0         0.00   \n",
       "1               49.0         0.00   \n",
       "2                3.0         0.00   \n",
       "3                1.0         0.00   \n",
       "4               13.0        30.77   \n",
       "\n",
       "                                   raw_comments_full  \\\n",
       "0  [â¤ï¸, Nice ðŸŒ¹ðŸ«ðŸ‘, Perfect, Gorgeous â¤ï¸, Brahmin a...   \n",
       "1  [ðŸ’ðŸ’, â¤ï¸, So prettyy, ðŸ”¥ðŸ¤, Cute ðŸ¥°ðŸ’šðŸ–¤ðŸ’š, So ðŸ¥°, â¤ï¸ðŸ”¥ðŸ˜...   \n",
       "2  [and thatâ€™s when things went south :p, ðŸ˜ðŸ˜ðŸ˜, ðŸ˜ðŸ˜...   \n",
       "3  [south indian full course meal, Ek itni slay p...   \n",
       "4  [brother casually dropped a bangerðŸ¥µ, â¤ï¸â¤ï¸â¤ï¸ðŸ”¥ðŸ”¥ðŸ”¥...   \n",
       "\n",
       "                        filtered_comments_for_gemini  \\\n",
       "0  [Nice ðŸŒ¹ðŸ«ðŸ‘, Perfect, Gorgeous â¤ï¸, Brahmin ah ?,...   \n",
       "1  [So prettyy, Cute ðŸ¥°ðŸ’šðŸ–¤ðŸ’š, So ðŸ¥°, Looking simply a...   \n",
       "2  [and thatâ€™s when things went south :p, much aw...   \n",
       "3  [south indian full course meal, Ek itni slay p...   \n",
       "4  [brother casually dropped a bangerðŸ¥µ, @_.jisha....   \n",
       "\n",
       "                                          gemini_raw  ...  \\\n",
       "0  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...  ...   \n",
       "1  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...  ...   \n",
       "2  {\"genz_word_count\": 0, \"is_marketing\": 0, \"is_...  ...   \n",
       "3  {\"genz_word_count\": 1, \"is_marketing\": 0, \"is_...  ...   \n",
       "4  {\"genz_word_count\": 1, \"is_marketing\": 0, \"is_...  ...   \n",
       "\n",
       "   gemini_genz_word_count  gemini_is_marketing  gemini_is_educational  \\\n",
       "0                       0                    0                      0   \n",
       "1                       0                    0                      0   \n",
       "2                       0                    0                      0   \n",
       "3                       1                    0                      0   \n",
       "4                       1                    0                      0   \n",
       "\n",
       "   gemini_is_vlog  gemini_has_humour  \\\n",
       "0               0                  1   \n",
       "1               0                  0   \n",
       "2               0                  1   \n",
       "3               0                  0   \n",
       "4               0                  1   \n",
       "\n",
       "   gemini_comment_sentiment_counts.questioning  \\\n",
       "0                                            1   \n",
       "1                                            4   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            1   \n",
       "\n",
       "   gemini_comment_sentiment_counts.agreeing  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         2   \n",
       "3                                         0   \n",
       "4                                         5   \n",
       "\n",
       "   gemini_comment_sentiment_counts.appreciating  \\\n",
       "0                                            10   \n",
       "1                                            16   \n",
       "2                                             7   \n",
       "3                                            10   \n",
       "4                                             2   \n",
       "\n",
       "   gemini_comment_sentiment_counts.negative  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   gemini_comment_sentiment_counts.neutral  \n",
       "0                                        3  \n",
       "1                                        1  \n",
       "2                                        4  \n",
       "3                                        1  \n",
       "4                                        6  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4b â€” Flatten gemini_raw into columns (per reel)\n",
    "# Run this AFTER df_all_reels is created\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd  # already imported above, but harmless to repeat\n",
    "\n",
    "def parse_gemini_raw(x):\n",
    "    \"\"\"\n",
    "    Safely parse gemini_raw (string) â†’ dict.\n",
    "    Returns {} if empty or invalid.\n",
    "    \"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    if not isinstance(x, str) or not x.strip():\n",
    "        return {}\n",
    "    try:\n",
    "        out = json.loads(x)\n",
    "        if isinstance(out, dict):\n",
    "            return out\n",
    "        return {}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# 1) Parse raw JSON objects\n",
    "parsed = df_all_reels[\"gemini_raw\"].apply(parse_gemini_raw)\n",
    "\n",
    "# 2) Flatten to columns\n",
    "gemini_flat = pd.json_normalize(parsed).add_prefix(\"gemini_\")\n",
    "\n",
    "# 3) Attach back to the reel-level dataframe\n",
    "df_gem_full = pd.concat(\n",
    "    [\n",
    "        df_all_reels.reset_index(drop=True),\n",
    "        gemini_flat.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_gem_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Creator: museumofsoum | Reel idx: 0\n",
      "URL: https://www.instagram.com/p/C63TimvpYcE/\n",
      "\n",
      "CAPTION:\n",
      "idli sambar for 50yrs till you die\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "#explorepage #explorepageâœ¨ #explore #exploremore #fyp #fypã‚· #fypage #fypã‚·â¤ï¸ðŸ’žâ¤ï¸ #reels #reelsviral #viralreels #mollywood\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "GEMINI LABELS:\n",
      "  genz_word_count   : 0\n",
      "  is_marketing      : 0\n",
      "  is_educational    : 0\n",
      "  is_vlog           : 0\n",
      "  has_humour        : 1\n",
      "\n",
      "COMMENT SENTIMENT COUNTS:\n",
      "  questioning  : 1\n",
      "  agreeing     : 0\n",
      "  appreciating : 10\n",
      "  negative     : 1\n",
      "  neutral      : 3\n",
      "\n",
      "================================================================================\n",
      "Creator: museumofsoum | Reel idx: 1\n",
      "URL: https://www.instagram.com/p/DRjbAw6DRD8/\n",
      "\n",
      "CAPTION:\n",
      "pichodi fit check ðŸ¦”\n",
      "\n",
      "#fyp #fypã‚· #fypage #southindiansarees #halfsaree #wedding #viral #viralreels \n",
      "fashion, wedding, South Indian, half saree\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "GEMINI LABELS:\n",
      "  genz_word_count   : 0\n",
      "  is_marketing      : 0\n",
      "  is_educational    : 0\n",
      "  is_vlog           : 0\n",
      "  has_humour        : 0\n",
      "\n",
      "COMMENT SENTIMENT COUNTS:\n",
      "  questioning  : 4\n",
      "  agreeing     : 0\n",
      "  appreciating : 16\n",
      "  negative     : 0\n",
      "  neutral      : 1\n",
      "\n",
      "================================================================================\n",
      "Creator: museumofsoum | Reel idx: 2\n",
      "URL: https://www.instagram.com/p/DQoRSPWDewf/\n",
      "\n",
      "CAPTION:\n",
      "riya and my marej yâ€™all are invited\n",
      "\n",
      "#fypã‚·â¤ï¸ðŸ’žâ¤ï¸ #fypreelsã‚·ã‚š #fypã‚· #viralreelsâ¤ï¸ #bestfriends\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "GEMINI LABELS:\n",
      "  genz_word_count   : 0\n",
      "  is_marketing      : 0\n",
      "  is_educational    : 0\n",
      "  is_vlog           : 0\n",
      "  has_humour        : 1\n",
      "\n",
      "COMMENT SENTIMENT COUNTS:\n",
      "  questioning  : 1\n",
      "  agreeing     : 2\n",
      "  appreciating : 7\n",
      "  negative     : 0\n",
      "  neutral      : 4\n",
      "\n",
      "================================================================================\n",
      "Creator: museumofsoum | Reel idx: 3\n",
      "URL: https://www.instagram.com/p/C_5FVUuql9u/\n",
      "\n",
      "CAPTION:\n",
      "dancing for idli (obv)\n",
      "\n",
      ".\n",
      "#onam #onamcelebration #onamspecial #nift #niftmumbai #niftian #fypã‚· #fypage #fyp #fashion #viralreels #explorepage #explorepageâœ¨ #aasakooda #reelsvideo #viral\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "GEMINI LABELS:\n",
      "  genz_word_count   : 1\n",
      "  is_marketing      : 0\n",
      "  is_educational    : 0\n",
      "  is_vlog           : 0\n",
      "  has_humour        : 0\n",
      "\n",
      "COMMENT SENTIMENT COUNTS:\n",
      "  questioning  : 1\n",
      "  agreeing     : 0\n",
      "  appreciating : 10\n",
      "  negative     : 1\n",
      "  neutral      : 1\n",
      "\n",
      "================================================================================\n",
      "Creator: museumofsoum | Reel idx: 4\n",
      "URL: https://www.instagram.com/p/C3ucjNlpUvk/\n",
      "\n",
      "CAPTION:\n",
      "my 2020 bangs era in math class \n",
      "\n",
      "#explore #explorepage #explorepageâœ¨ #viral #viralreels #fyp #fypã‚· #fypage #bangshairstyle #funnyvideos\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "TOP COMMENTS:\n",
      "\n",
      "GEMINI LABELS:\n",
      "  genz_word_count   : 1\n",
      "  is_marketing      : 0\n",
      "  is_educational    : 0\n",
      "  is_vlog           : 0\n",
      "  has_humour        : 1\n",
      "\n",
      "COMMENT SENTIMENT COUNTS:\n",
      "  questioning  : 1\n",
      "  agreeing     : 5\n",
      "  appreciating : 2\n",
      "  negative     : 0\n",
      "  neutral      : 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 4c â€” Inspect comments + Gemini labels for sanity-check\n",
    "# Run this AFTER CELL 4b (df_gem_full is available)\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "creator_to_inspect = \"museumofsoum\"  # change to any handle you want\n",
    "\n",
    "subset = df_gem_full[df_gem_full[\"creator\"] == creator_to_inspect].copy()\n",
    "\n",
    "for i, row in subset.head(5).iterrows():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Creator: {row['creator']} | Reel idx: {row.get('reel_idx', i)}\")\n",
    "    print(\"URL:\", row.get(\"reel_url\", \"\"))\n",
    "\n",
    "    print(\"\\nCAPTION:\")\n",
    "    print(row.get(\"caption\", \"\"))\n",
    "\n",
    "    print(\"\\nTOP COMMENTS:\")\n",
    "    print(\"\\nTOP COMMENTS:\")\n",
    "    comments = row.get(\"flat_comments\", [])\n",
    "    for c in comments[:10]:\n",
    "        print(\"  -\", c)\n",
    "\n",
    "    print(\"\\nGEMINI LABELS:\")\n",
    "    print(f\"  genz_word_count   : {row.get('gemini_genz_word_count')}\")\n",
    "    print(f\"  is_marketing      : {row.get('gemini_is_marketing')}\")\n",
    "    print(f\"  is_educational    : {row.get('gemini_is_educational')}\")\n",
    "    print(f\"  is_vlog           : {row.get('gemini_is_vlog')}\")\n",
    "    print(f\"  has_humour        : {row.get('gemini_has_humour')}\")\n",
    "\n",
    "    print(\"\\nCOMMENT SENTIMENT COUNTS:\")\n",
    "    print(f\"  questioning  : {row.get('gemini_comment_sentiment_counts.questioning')}\")\n",
    "    print(f\"  agreeing     : {row.get('gemini_comment_sentiment_counts.agreeing')}\")\n",
    "    print(f\"  appreciating : {row.get('gemini_comment_sentiment_counts.appreciating')}\")\n",
    "    print(f\"  negative     : {row.get('gemini_comment_sentiment_counts.negative')}\")\n",
    "    print(f\"  neutral      : {row.get('gemini_comment_sentiment_counts.neutral')}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba52b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: word_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     84\u001b[39m df_eng = (\n\u001b[32m     85\u001b[39m     df_non_music.groupby(\u001b[33m\"\u001b[39m\u001b[33mcreator\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33menglish_pct\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     86\u001b[39m       .mean()\n\u001b[32m     87\u001b[39m       .reset_index(name=\u001b[33m\"\u001b[39m\u001b[33mavg_english_pct_non_music\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m )\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# 7b) avg_words_spoken_non_music\u001b[39;00m\n\u001b[32m     91\u001b[39m df_words = (\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[43mdf_non_music\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcreator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword_count\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     93\u001b[39m       .mean()\n\u001b[32m     94\u001b[39m       .reset_index(name=\u001b[33m\"\u001b[39m\u001b[33mavg_words_spoken_non_music\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m )\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# 8) ACCESSORIES â†’ BUCKETED AVERAGES ONLY (NO PER-CLASS COUNTS)\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m \n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Make sure every accessory class has a bucket\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mACCESSORY_CLASSES\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCLASS_BUCKET\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[39m, in \u001b[36mDataFrameGroupBy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) > \u001b[32m1\u001b[39m:\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[32m   1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1950\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[39m, in \u001b[36mSelectionMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    245\u001b[39m     ndim = \u001b[38;5;28mself\u001b[39m.obj[key].ndim\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gotitem(key, ndim=ndim)\n",
      "\u001b[31mKeyError\u001b[39m: 'Column not found: word_count'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5 â€” PER-CREATOR AGGREGATION (WITH BUCKETED ACCESSORIES ONLY)\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "df = df_all_reels.copy()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 0) BASIC GROUPBY\n",
    "# -------------------------------------------------------------------------\n",
    "grp = df.groupby(\"creator\")\n",
    "\n",
    "# number of reels per creator (for accessories bucket averaging)\n",
    "if \"reel_url\" in df.columns:\n",
    "    num_reels = grp[\"reel_url\"].nunique().rename(\"num_reels\")\n",
    "else:\n",
    "    # fallback: count rows\n",
    "    num_reels = grp.size().rename(\"num_reels\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) ATTRACTIVENESS â†’ method6_full_aesthetic_0_10\n",
    "# -------------------------------------------------------------------------\n",
    "df_attr = (\n",
    "    df.groupby(\"creator\")[\"multi_cue_attr_0_10\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"method6_full_aesthetic_0_10\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) SUN EXPOSURE â†’ sun_exposure_0_10_A\n",
    "# -------------------------------------------------------------------------\n",
    "df_sun = (\n",
    "    df.groupby(\"creator\")[\"sun_exposure_0_10_A\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3) EYE CONTACT â†’ eye_contact_avg_score_0_10\n",
    "# -------------------------------------------------------------------------\n",
    "df_eye = (\n",
    "    df.groupby(\"creator\")[\"eye_contact_score_0_10\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"eye_contact_avg_score_0_10\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4) CREATIVITY â†’ mean_hist_score (hist_score_0_10 per reel)\n",
    "# -------------------------------------------------------------------------\n",
    "df_creativity = (\n",
    "    df.groupby(\"creator\")[\"hist_score_0_10\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"mean_hist_score\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5) SEQUENTIAL â†’ series_reel_mean (series_flag âˆˆ {0,1})\n",
    "# -------------------------------------------------------------------------\n",
    "df_seq = (\n",
    "    df.groupby(\"creator\")[\"series_flag\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"series_reel_mean\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 6) VIDEO CAPTIONING â†’ avg_captioned_reels\n",
    "#     has_dynamic_captions âˆˆ {0,1}\n",
    "# -------------------------------------------------------------------------\n",
    "df_caps = (\n",
    "    df.groupby(\"creator\")[\"has_dynamic_captions\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"avg_captioned_reels\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 7) ENGLISH PERCENT â†’ avg_english_pct_non_music\n",
    "#     use is_music_only_transcript(...) on the fly\n",
    "# -------------------------------------------------------------------------\n",
    "df_non_music = df[~df[\"transcript\"].apply(is_music_only_transcript)].copy()\n",
    "\n",
    "df_eng = (\n",
    "    df_non_music.groupby(\"creator\")[\"english_pct\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"avg_english_pct_non_music\")\n",
    ")\n",
    "\n",
    "# 7b) avg_words_spoken_non_music\n",
    "df_words = (\n",
    "    df_non_music.groupby(\"creator\")[\"word_count\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"avg_words_spoken_non_music\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 8) ACCESSORIES â†’ BUCKETED AVERAGES ONLY (NO PER-CLASS COUNTS)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# If you don't already have these defined in this notebook, uncomment:\n",
    "# ACCESSORY_CLASSES = [\n",
    "#     \"backpack\",\"handbag\",\"hat\",\"scarf\",\"sunglasses\",\"glasses\",\n",
    "#     \"necklace\",\"earrings\",\"watch\",\"bracelet\",\"ring\",\"wallet\",\"belt\",\n",
    "#     \"mobile_phone\",\"laptop\",\"tablet\",\"smartwatch\",\"headphones\",\"camera\",\n",
    "#     \"car\",\"sports_car\",\"motorcycle\",\"bike\",\"airplane\",\"boat\",\n",
    "#     \"suitcase\",\"luggage\",\"surfboard\",\"skis\",\"horse\",\n",
    "#     \"dress\",\"coat\",\"suit\",\"high_heels\",\n",
    "# ]\n",
    "#\n",
    "# CLASS_BUCKET = {\n",
    "#     \"backpack\":     \"travel_gear\",\n",
    "#     \"handbag\":      \"travel_gear\",\n",
    "#     \"suitcase\":     \"travel_gear\",\n",
    "#     \"luggage\":      \"travel_gear\",\n",
    "#     \"surfboard\":    \"travel_gear\",\n",
    "#     \"skis\":         \"travel_gear\",\n",
    "#\n",
    "#     \"hat\":          \"clothing\",\n",
    "#     \"scarf\":        \"clothing\",\n",
    "#     \"dress\":        \"clothing\",\n",
    "#     \"coat\":         \"clothing\",\n",
    "#     \"suit\":         \"clothing\",\n",
    "#     \"belt\":         \"clothing\",\n",
    "#     \"high_heels\":   \"clothing\",\n",
    "#     \"sunglasses\":   \"clothing\",\n",
    "#     \"glasses\":      \"clothing\",\n",
    "#\n",
    "#     \"necklace\":     \"jewellery\",\n",
    "#     \"earrings\":     \"jewellery\",\n",
    "#     \"watch\":        \"jewellery\",\n",
    "#     \"bracelet\":     \"jewellery\",\n",
    "#     \"ring\":         \"jewellery\",\n",
    "#\n",
    "#     \"mobile_phone\": \"gadgets\",\n",
    "#     \"laptop\":       \"gadgets\",\n",
    "#     \"tablet\":       \"gadgets\",\n",
    "#     \"smartwatch\":   \"gadgets\",\n",
    "#     \"headphones\":   \"gadgets\",\n",
    "#     \"camera\":       \"gadgets\",\n",
    "#\n",
    "#     \"car\":          \"vehicles\",\n",
    "#     \"sports_car\":   \"vehicles\",\n",
    "#     \"motorcycle\":   \"vehicles\",\n",
    "#     \"bike\":         \"vehicles\",\n",
    "#     \"airplane\":     \"vehicles\",\n",
    "#     \"boat\":         \"vehicles\",\n",
    "#     \"horse\":        \"vehicles\",\n",
    "# }\n",
    "\n",
    "# Make sure every accessory class has a bucket\n",
    "if \"ACCESSORY_CLASSES\" in globals() and \"CLASS_BUCKET\" in globals():\n",
    "    for cls in ACCESSORY_CLASSES:\n",
    "        CLASS_BUCKET.setdefault(cls, \"other\")\n",
    "    BUCKET_NAMES = sorted(set(CLASS_BUCKET.values()))\n",
    "else:\n",
    "    BUCKET_NAMES = []\n",
    "    ACCESSORY_CLASSES = []\n",
    "\n",
    "# group object already defined as `grp`; num_reels as above\n",
    "if ACCESSORY_CLASSES and not df.empty:\n",
    "    # only class columns that actually exist in df\n",
    "    class_cols = [c for c in ACCESSORY_CLASSES if c in df.columns]\n",
    "\n",
    "    if class_cols:\n",
    "        class_sums = grp[class_cols].sum().fillna(0)\n",
    "\n",
    "        bucket_avg_df = pd.DataFrame(index=class_sums.index)\n",
    "\n",
    "        for bucket in BUCKET_NAMES:\n",
    "            bucket_classes = [c for c in class_cols if CLASS_BUCKET.get(c) == bucket]\n",
    "            if not bucket_classes:\n",
    "                continue\n",
    "\n",
    "            bucket_sum = class_sums[bucket_classes].sum(axis=1)\n",
    "            bucket_avg = bucket_sum / num_reels\n",
    "\n",
    "            bucket_avg_df[f\"avg_{bucket}_per_reel\"] = bucket_avg\n",
    "\n",
    "        df_acc = bucket_avg_df.reset_index()\n",
    "    else:\n",
    "        df_acc = pd.DataFrame({\"creator\": df[\"creator\"].unique()})\n",
    "else:\n",
    "    df_acc = pd.DataFrame({\"creator\": df[\"creator\"].unique()})\n",
    "\n",
    "# At this point df_acc has ONLY columns:\n",
    "#   creator, avg_clothing_per_reel, avg_jewellery_per_reel, avg_gadgets_per_reel,\n",
    "#   avg_vehicles_per_reel, avg_travel_gear_per_reel, avg_other_per_reel (if any)\n",
    "\n",
    "# 9) GEMINI â†’ per-creator average of every numeric field in gemini_raw\n",
    "#    BUT only for reels that are:\n",
    "#    - not music-only\n",
    "#    - and have some English content (english_pct > 0)\n",
    "\n",
    "def parse_gemini_raw(x):\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    if not isinstance(x, str) or not x.strip():\n",
    "        return {}\n",
    "    try:\n",
    "        out = json.loads(x)\n",
    "        if isinstance(out, dict):\n",
    "            return out\n",
    "    except Exception:\n",
    "        return {}\n",
    "    return {}\n",
    "\n",
    "# -----------------------------\n",
    "# a) Filter to valid reels\n",
    "# -----------------------------\n",
    "# Assumes:\n",
    "#   - df[\"transcript\"] exists\n",
    "#   - df[\"english_pct\"] was computed via compute_english_percent_from_transcript\n",
    "mask_gem = (\n",
    "    ~df[\"transcript\"].apply(is_music_only_transcript)   # drop music-only\n",
    "    & df[\"english_pct\"].notna()                         # drop NaN (no usable text)\n",
    "    & (df[\"english_pct\"] > 0)                           # drop 0%-English reels\n",
    ")\n",
    "\n",
    "df_gem_base = df.loc[mask_gem].copy()\n",
    "\n",
    "if df_gem_base.empty:\n",
    "    # no valid reels â†’ per-creator frame with creator only (metrics will be NaN after merge)\n",
    "    df_gem_creator = pd.DataFrame({\"creator\": df[\"creator\"].unique()})\n",
    "else:\n",
    "    # -----------------------------\n",
    "    # b) Parse and flatten gemini_raw only for valid reels\n",
    "    # -----------------------------\n",
    "    parsed = df_gem_base[\"gemini_raw\"].apply(parse_gemini_raw)\n",
    "    gemini_flat = pd.json_normalize(parsed).add_prefix(\"gemini_\")\n",
    "\n",
    "    df_gem = pd.concat(\n",
    "        [\n",
    "            df_gem_base[[\"creator\"]].reset_index(drop=True),\n",
    "            gemini_flat.reset_index(drop=True),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_gem_creator = (\n",
    "        df_gem.groupby(\"creator\")\n",
    "              .mean(numeric_only=True)\n",
    "              .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 10) FINAL MERGE â€” ALL METRICS + BUCKETED ACCESSORIES ONLY\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "dfs_to_merge = [\n",
    "    df_attr,\n",
    "    df_sun,\n",
    "    df_eye,\n",
    "    df_creativity,\n",
    "    df_seq,\n",
    "    df_caps,\n",
    "    df_words,\n",
    "    df_eng,\n",
    "    df_acc,\n",
    "    df_gem_creator,\n",
    "]\n",
    "\n",
    "dfs_to_merge = [\n",
    "    d for d in dfs_to_merge\n",
    "    if isinstance(d, pd.DataFrame) and not d.empty and \"creator\" in d.columns\n",
    "]\n",
    "\n",
    "df_final = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"creator\", how=\"outer\"),\n",
    "    dfs_to_merge,\n",
    ")\n",
    "\n",
    "df_final = df_final.sort_values(\"creator\").reset_index(drop=True)\n",
    "\n",
    "# display(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59332397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Scraping up to 30 posts for 1 creators...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:42.633Z ACTOR: Pulling container image of build v0L4z0Gm7SMQIkD2y from registry.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:42.635Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:42.685Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:42.687Z ACTOR: Running under \"LIMITED_PERMISSIONS\" permission level.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:43.310Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.5.1\",\"apifyClientVersion\":\"2.19.0\",\"crawleeVersion\":\"3.15.3\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.21.1\"}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:43.424Z \u001b[32mINFO\u001b[39m  Results Limit [object Object], ACTOR_MAX_PAID_DATASET_ITEMS 89960\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:43.547Z \u001b[32mINFO\u001b[39m  Starting Apify client's scheduler\u001b[90m {\"clientName\":\"CLIENT\"}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:43.549Z \u001b[32mINFO\u001b[39m  pushDataMaxAware 89960\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:43.725Z \u001b[32mINFO\u001b[39m  [Status message]: Starting the scraper with 1 direct URL(s)\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:53:43.929Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:54:13.966Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:54:43.929Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":60157,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:54:43.935Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:54:47.175Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:55:20.365Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":3}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:55:43.929Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":120156,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:55:43.939Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:55:53.715Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":4}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:56:27.032Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":5}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:56:43.929Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":180157,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:56:43.941Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:57:00.233Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":6}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:57:33.450Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":7}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:57:43.934Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":240158,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:57:43.943Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:06.717Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":8}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.408Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Detected a session error, rotating session...\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.410Z Proxy responded with 595 ECONNRESET: 0 bytes.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.411Z\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.413Z Below is the first 100 bytes of the proxy response body:\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.415Z\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.417Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15759:21)\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Crawled 1/2 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:25.418Z     at Request._beforeError (file:///usr/src/app/dist/984.index.js:15759:21)\u001b[90m {\"id\":\"4xXzuDvXOEMFTln\",\"url\":\"https://i.instagram.com/api/v1/users/web_profile_info/?username=museumofsoum\",\"retryCount\":9}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:40.546Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked, retrying it again with different session\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:40.548Z     at handlePostDetails (file:///usr/src/app/dist/index.js:44:610651)\u001b[90m {\"id\":\"n2uPWFdvNjdY7k2\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.028Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"w0pFNv14egGmSkw\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.129Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"H05uY0sQWiZceft\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.131Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"AoPyIh1AfGCDth7\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.133Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"s95OdLcWLY9GRVQ\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.135Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"nTXiREJDx8nUVJh\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.136Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"hmfkqqfk575diPQ\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.138Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"xIkardYCQgWW18C\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.223Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"ssSbc0RZT1s7PQH\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.226Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"AqRWQBBmSA8WV6L\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.228Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"JWPQqMghf1XBK4q\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.229Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"XoJfxBBEJnl2vlG\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:41.231Z \u001b[33mWARN\u001b[39m \u001b[33m RequestQueue(ahwe9bfQpL3xnHqL8, no-name):\u001b[39m Queue head returned a request that is already in progress?!\u001b[90m {\"nextRequestId\":\"dC07jiXmCSXpvgM\",\"inProgress\":true,\"recentlyHandled\":false}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:42.419Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked, retrying it again with different session\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:42.421Z     at handlePostDetails (file:///usr/src/app/dist/index.js:44:610651)\u001b[90m {\"id\":\"dC07jiXmCSXpvgM\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:42.636Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked, retrying it again with different session\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:42.638Z     at handlePostDetails (file:///usr/src/app/dist/index.js:44:610651)\u001b[90m {\"id\":\"s95OdLcWLY9GRVQ\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:42.927Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. The HTTP/2 stream has been early terminated\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:42.928Z     at ClientRequest.<anonymous> (file:///usr/src/app/dist/984.index.js:16243:109)\u001b[90m {\"id\":\"XoJfxBBEJnl2vlG\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:43.931Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:Statistics:\u001b[39m CheerioCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":2664,\"requestsFinishedPerMinute\":4,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":53286,\"requestsTotal\":20,\"crawlerRuntimeMillis\":300158,\"retryHistogram\":[19,null,null,null,null,null,null,null,null,1]}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Crawled 20/28 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:43.945Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":3,\"desiredConcurrency\":52,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.059},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0.07},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:47.741Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request got blocked. Will retry with different session\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:47.743Z     at handlePostsFeed (file:///usr/src/app/dist/index.js:44:754143)\u001b[90m {\"id\":\"Q2swjlQTMdfYFob\",\"url\":\"https://www.instagram.com/graphql/query/?doc_id=7950326061742207&variables=%7B%22id%22%3A%225474110505%22%2C%22first%22%3A12%2C%22after%22%3A%22QVFDYS1zVFd5LTREMGpTSzhUWlhVekphaUZTdTlkLUVQUTJoY0VfTld0RUN2VmdGQkJma3R3TGFGVHdVUkNvbDhaMVA0UVRRRDVSVC1lZ191UXV1RUNNbQ%3D%3D%22%7D\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:52.397Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request got blocked. Will retry with different session\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Crawled 25/28 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:58:52.399Z     at handlePostsFeed (file:///usr/src/app/dist/index.js:44:754143)\u001b[90m {\"id\":\"Q2swjlQTMdfYFob\",\"url\":\"https://www.instagram.com/graphql/query/?doc_id=7950326061742207&variables=%7B%22id%22%3A%225474110505%22%2C%22first%22%3A12%2C%22after%22%3A%22QVFDYS1zVFd5LTREMGpTSzhUWlhVekphaUZTdTlkLUVQUTJoY0VfTld0RUN2VmdGQkJma3R3TGFGVHdVUkNvbDhaMVA0UVRRRDVSVC1lZ191UXV1RUNNbQ%3D%3D%22%7D\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:03.770Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked, retrying it again with different session\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Crawled 26/34 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:03.772Z     at handlePostDetails (file:///usr/src/app/dist/index.js:44:610651)\u001b[90m {\"id\":\"dvzd4dO1zvJxB0l\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:10.933Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"xIkardYCQgWW18C\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: RUNNING, Message: Crawled 32/34 pages, 0 failed requests, desired concurrency 52.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:11.025Z \u001b[33mWARN\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Reclaiming failed request back to the list or queue. request timed out after 30 seconds.\u001b[90m {\"id\":\"H05uY0sQWiZceft\",\"url\":\"https://www.instagram.com/api/graphql\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:16.800Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:16.927Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":34,\"requestsFailed\":0,\"retryHistogram\":[25,7,1,null,null,null,null,null,null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":2672,\"requestsFinishedPerMinute\":6,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":90860,\"requestsTotal\":34,\"crawlerRuntimeMillis\":333155}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:16.929Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Finished! Total 34 requests: 34 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:16.931Z \u001b[32mINFO\u001b[39m  [Status message]: Scraper finished\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> 2025-12-11T12:59:17.006Z \u001b[32mINFO\u001b[39m  Stopping Apify client's scheduler\u001b[90m {\"clientName\":\"CLIENT\"}\u001b[39m\n",
      "\u001b[36m[apify.instagram-scraper runId:sHwxVsj21FQCk3XbS]\u001b[0m -> Status: SUCCEEDED, Message: Scraper finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Got 30 posts across 1 creators\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'creator_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_27876\\2582448254.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m     df_final[\u001b[33m\"creator\"\u001b[39m].astype(str).str.lstrip(\u001b[33m\"@\"\u001b[39m).str.lower()\n\u001b[32m     22\u001b[39m )\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 4) Merge into df_final\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m df_final = df_final.merge(\n\u001b[32m     26\u001b[39m     df_post_ratios[\n\u001b[32m     27\u001b[39m         [\n\u001b[32m     28\u001b[39m             \u001b[38;5;66;03m# \"creator_norm\",\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10828\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m     ) -> DataFrame:\n\u001b[32m  10830\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10831\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m         return merge(\n\u001b[32m  10833\u001b[39m             self,\n\u001b[32m  10834\u001b[39m             right,\n\u001b[32m  10835\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1293\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1296\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1298\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1299\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1300\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'creator_norm'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL X â€” ADD POSTS vs REELS RATIOS INTO df_final\n",
    "#   (place this AFTER you have computed df_final)\n",
    "# =============================================================================\n",
    "\n",
    "# 1) Fetch posts for the same creators you are evaluating\n",
    "posts_by_user = fetch_all_posts_for_creators(\n",
    "    creators=CREATOR_LIST,              # same list you use in the joint loop\n",
    "    max_posts=MAX_POSTS_PER_CREATOR,    # from the module cell\n",
    ")\n",
    "\n",
    "# 2) Compute ratios\n",
    "df_post_ratios = compute_static_reel_ratios(posts_by_user)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_post_ratios cols: ['creator', 'total_posts_sampled', 'reels_sampled', 'static_posts_sampled', 'other_posts_sampled', 'reels_ratio', 'static_ratio', 'creator_norm']\n",
      "df_final cols: ['creator', 'method6_full_aesthetic_0_10', 'sun_exposure_0_10_A', 'eye_contact_avg_score_0_10', 'mean_hist_score', 'series_reel_mean', 'avg_captioned_reels', 'avg_words_spoken_non_music', 'avg_english_pct_non_music', 'avg_clothing_per_reel', 'avg_gadgets_per_reel', 'avg_jewellery_per_reel', 'avg_other_per_reel', 'avg_travel_gear_per_reel', 'avg_vehicles_per_reel', 'gemini_genz_word_count', 'gemini_is_marketing', 'gemini_is_educational', 'gemini_is_vlog', 'gemini_has_humour', 'gemini_comment_sentiment_counts.questioning', 'gemini_comment_sentiment_counts.agreeing', 'gemini_comment_sentiment_counts.appreciating', 'gemini_comment_sentiment_counts.negative', 'gemini_comment_sentiment_counts.neutral', 'total_posts_sampled_x', 'reels_sampled_x', 'static_posts_sampled_x', 'other_posts_sampled_x', 'reels_ratio_x', 'static_ratio_x', 'total_posts_sampled_y', 'reels_sampled_y', 'static_posts_sampled_y', 'other_posts_sampled_y', 'reels_ratio_y', 'static_ratio_y', 'total_posts_sampled', 'reels_sampled', 'static_posts_sampled', 'other_posts_sampled', 'reels_ratio', 'static_ratio', 'creator_norm']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'creator_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_27876\\2903766364.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# \"static_ratio\",\u001b[39;00m\n\u001b[32m     29\u001b[39m ]\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 3) Do the merge (note: creator_norm MUST be present in df_post_ratios[cols_to_merge])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m df_final = df_final.merge(\n\u001b[32m     33\u001b[39m     df_post_ratios[cols_to_merge],\n\u001b[32m     34\u001b[39m     on=\u001b[33m\"creator_norm\"\u001b[39m,\n\u001b[32m     35\u001b[39m     how=\u001b[33m\"left\"\u001b[39m,\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10828\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m     ) -> DataFrame:\n\u001b[32m  10830\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10831\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m         return merge(\n\u001b[32m  10833\u001b[39m             self,\n\u001b[32m  10834\u001b[39m             right,\n\u001b[32m  10835\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1293\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1296\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1298\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1299\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1300\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32mc:\\Users\\gaura\\Desktop\\creator-scorer\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'creator_norm'"
     ]
    }
   ],
   "source": [
    "# 1) Normalise creator names on both sides\n",
    "df_post_ratios[\"creator_norm\"] = (\n",
    "    df_post_ratios[\"creator\"]\n",
    "      .astype(str)\n",
    "      .str.lstrip(\"@\")\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "df_final[\"creator_norm\"] = (\n",
    "    df_final[\"creator\"]\n",
    "      .astype(str)\n",
    "      .str.lstrip(\"@\")\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "# Optional: quick sanity check\n",
    "print(\"df_post_ratios cols:\", df_post_ratios.columns.tolist())\n",
    "print(\"df_final cols:\", df_final.columns.tolist())\n",
    "\n",
    "# 2) Define which columns from df_post_ratios to bring into df_final\n",
    "cols_to_merge = [\n",
    "    # \"creator_norm\",\n",
    "    # \"total_posts_sampled\",\n",
    "    # \"reels_sampled\",\n",
    "    # \"static_posts_sampled\",\n",
    "    # \"other_posts_sampled\",\n",
    "    \"reels_ratio\",\n",
    "    # \"static_ratio\",\n",
    "]\n",
    "\n",
    "# 3) Do the merge (note: creator_norm MUST be present in df_post_ratios[cols_to_merge])\n",
    "df_final = df_final.merge(\n",
    "    df_post_ratios[cols_to_merge],\n",
    "    on=\"creator_norm\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# 4) Drop helper column if you donâ€™t want it in the final table\n",
    "df_final = df_final.drop(columns=[\"creator_norm\"])\n",
    "df_final.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a564dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creators in df_final: 1\n",
      "Creators with attributes: 1\n",
      "Merged rows: 1\n",
      "Metric columns: ['method6_full_aesthetic_0_10', 'sun_exposure_0_10_A', 'eye_contact_avg_score_0_10', 'mean_hist_score', 'series_reel_mean', 'avg_captioned_reels', 'avg_clothing_per_reel', 'avg_jewellery_per_reel', 'avg_gadgets_per_reel', 'avg_vehicles_per_reel', 'avg_travel_gear_per_reel', 'avg_english_pct_non_music', 'gemini_genz_word_count', 'avg_words_spoken_non_music', 'gemini_is_marketing', 'gemini_is_educational', 'gemini_is_vlog', 'gemini_has_humour', 'gemini_comment_sentiment_counts.questioning', 'gemini_comment_sentiment_counts.agreeing', 'gemini_comment_sentiment_counts.appreciating', 'gemini_comment_sentiment_counts.negative', 'gemini_comment_sentiment_counts.neutral']\n",
      "Attribute columns: ['aspirational', 'relatable', 'cool', 'credible', 'communication', 'story_telling']\n",
      "Correlation matrix (metrics Ã— attributes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspirational</th>\n",
       "      <th>relatable</th>\n",
       "      <th>cool</th>\n",
       "      <th>credible</th>\n",
       "      <th>communication</th>\n",
       "      <th>story_telling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>method6_full_aesthetic_0_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun_exposure_0_10_A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eye_contact_avg_score_0_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_hist_score</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_reel_mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_captioned_reels</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_clothing_per_reel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_jewellery_per_reel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_gadgets_per_reel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_vehicles_per_reel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_travel_gear_per_reel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_english_pct_non_music</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_genz_word_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_words_spoken_non_music</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_is_marketing</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_is_educational</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_is_vlog</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_has_humour</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_comment_sentiment_counts.questioning</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_comment_sentiment_counts.agreeing</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_comment_sentiment_counts.appreciating</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_comment_sentiment_counts.negative</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_comment_sentiment_counts.neutral</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              aspirational  relatable  cool  \\\n",
       "method6_full_aesthetic_0_10                            NaN        NaN   NaN   \n",
       "sun_exposure_0_10_A                                    NaN        NaN   NaN   \n",
       "eye_contact_avg_score_0_10                             NaN        NaN   NaN   \n",
       "mean_hist_score                                        NaN        NaN   NaN   \n",
       "series_reel_mean                                       NaN        NaN   NaN   \n",
       "avg_captioned_reels                                    NaN        NaN   NaN   \n",
       "avg_clothing_per_reel                                  NaN        NaN   NaN   \n",
       "avg_jewellery_per_reel                                 NaN        NaN   NaN   \n",
       "avg_gadgets_per_reel                                   NaN        NaN   NaN   \n",
       "avg_vehicles_per_reel                                  NaN        NaN   NaN   \n",
       "avg_travel_gear_per_reel                               NaN        NaN   NaN   \n",
       "avg_english_pct_non_music                              NaN        NaN   NaN   \n",
       "gemini_genz_word_count                                 NaN        NaN   NaN   \n",
       "avg_words_spoken_non_music                             NaN        NaN   NaN   \n",
       "gemini_is_marketing                                    NaN        NaN   NaN   \n",
       "gemini_is_educational                                  NaN        NaN   NaN   \n",
       "gemini_is_vlog                                         NaN        NaN   NaN   \n",
       "gemini_has_humour                                      NaN        NaN   NaN   \n",
       "gemini_comment_sentiment_counts.questioning            NaN        NaN   NaN   \n",
       "gemini_comment_sentiment_counts.agreeing               NaN        NaN   NaN   \n",
       "gemini_comment_sentiment_counts.appreciating           NaN        NaN   NaN   \n",
       "gemini_comment_sentiment_counts.negative               NaN        NaN   NaN   \n",
       "gemini_comment_sentiment_counts.neutral                NaN        NaN   NaN   \n",
       "\n",
       "                                              credible  communication  \\\n",
       "method6_full_aesthetic_0_10                        NaN            NaN   \n",
       "sun_exposure_0_10_A                                NaN            NaN   \n",
       "eye_contact_avg_score_0_10                         NaN            NaN   \n",
       "mean_hist_score                                    NaN            NaN   \n",
       "series_reel_mean                                   NaN            NaN   \n",
       "avg_captioned_reels                                NaN            NaN   \n",
       "avg_clothing_per_reel                              NaN            NaN   \n",
       "avg_jewellery_per_reel                             NaN            NaN   \n",
       "avg_gadgets_per_reel                               NaN            NaN   \n",
       "avg_vehicles_per_reel                              NaN            NaN   \n",
       "avg_travel_gear_per_reel                           NaN            NaN   \n",
       "avg_english_pct_non_music                          NaN            NaN   \n",
       "gemini_genz_word_count                             NaN            NaN   \n",
       "avg_words_spoken_non_music                         NaN            NaN   \n",
       "gemini_is_marketing                                NaN            NaN   \n",
       "gemini_is_educational                              NaN            NaN   \n",
       "gemini_is_vlog                                     NaN            NaN   \n",
       "gemini_has_humour                                  NaN            NaN   \n",
       "gemini_comment_sentiment_counts.questioning        NaN            NaN   \n",
       "gemini_comment_sentiment_counts.agreeing           NaN            NaN   \n",
       "gemini_comment_sentiment_counts.appreciating       NaN            NaN   \n",
       "gemini_comment_sentiment_counts.negative           NaN            NaN   \n",
       "gemini_comment_sentiment_counts.neutral            NaN            NaN   \n",
       "\n",
       "                                              story_telling  \n",
       "method6_full_aesthetic_0_10                             NaN  \n",
       "sun_exposure_0_10_A                                     NaN  \n",
       "eye_contact_avg_score_0_10                              NaN  \n",
       "mean_hist_score                                         NaN  \n",
       "series_reel_mean                                        NaN  \n",
       "avg_captioned_reels                                     NaN  \n",
       "avg_clothing_per_reel                                   NaN  \n",
       "avg_jewellery_per_reel                                  NaN  \n",
       "avg_gadgets_per_reel                                    NaN  \n",
       "avg_vehicles_per_reel                                   NaN  \n",
       "avg_travel_gear_per_reel                                NaN  \n",
       "avg_english_pct_non_music                               NaN  \n",
       "gemini_genz_word_count                                  NaN  \n",
       "avg_words_spoken_non_music                              NaN  \n",
       "gemini_is_marketing                                     NaN  \n",
       "gemini_is_educational                                   NaN  \n",
       "gemini_is_vlog                                          NaN  \n",
       "gemini_has_humour                                       NaN  \n",
       "gemini_comment_sentiment_counts.questioning             NaN  \n",
       "gemini_comment_sentiment_counts.agreeing                NaN  \n",
       "gemini_comment_sentiment_counts.appreciating            NaN  \n",
       "gemini_comment_sentiment_counts.negative                NaN  \n",
       "gemini_comment_sentiment_counts.neutral                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 0) Inputs\n",
    "# ---------------------------------------------------------\n",
    "ATTR_CSV_PATH = \"train_data.csv\"   # <-- change to your file (e.g. \"test_data.csv\")\n",
    "CREATOR_COL   = \"creator\"                  # column name for creator in BOTH df_final & CSV\n",
    "\n",
    "# df_final is assumed to already exist and have one row per creator,\n",
    "# with all your metrics (aesthetic, sun_exposure, accessories buckets, etc.).\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) Read attributes CSV & keep only creators in df_final\n",
    "# ---------------------------------------------------------\n",
    "df_attr = pd.read_csv(ATTR_CSV_PATH)\n",
    "\n",
    "# If CSV may have multiple rows per creator, collapse to mean first\n",
    "df_attr_agg = (\n",
    "    df_attr.groupby(CREATOR_COL)\n",
    "           .mean(numeric_only=True)\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "creators_in_final = df_final[CREATOR_COL].unique()\n",
    "df_attr_agg = df_attr_agg[df_attr_agg[CREATOR_COL].isin(creators_in_final)].copy()\n",
    "\n",
    "print(\"Creators in df_final:\", len(creators_in_final))\n",
    "print(\"Creators with attributes:\", df_attr_agg[CREATOR_COL].nunique())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) Merge metrics (df_final) + attributes (df_attr_agg)\n",
    "# ---------------------------------------------------------\n",
    "df_merged = pd.merge(\n",
    "    df_final,\n",
    "    df_attr_agg,\n",
    "    on=CREATOR_COL,\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"\", \"_attr\"),\n",
    ")\n",
    "\n",
    "print(\"Merged rows:\", len(df_merged))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Decide which columns are metrics vs attributes\n",
    "# ---------------------------------------------------------\n",
    "# Example metric columns from df_final (edit this to match your df_final)\n",
    "metric_cols = [\n",
    "    \"method6_full_aesthetic_0_10\",\n",
    "    \"sun_exposure_0_10_A\",\n",
    "    \"eye_contact_avg_score_0_10\",\n",
    "    \"mean_hist_score\",\n",
    "    \"series_reel_mean\",\n",
    "    \"avg_captioned_reels\",\n",
    "    \"avg_clothing_per_reel\",\n",
    "    \"avg_jewellery_per_reel\",\n",
    "    \"avg_gadgets_per_reel\",\n",
    "    \"avg_vehicles_per_reel\",\n",
    "    \"avg_travel_gear_per_reel\",\n",
    "    \"avg_english_pct_non_music\",\n",
    "    \"gemini_genz_word_count\",\n",
    "    \"avg_words_spoken_non_music\",\n",
    "\"gemini_is_marketing\",\n",
    "\"gemini_is_educational\",\n",
    "\"gemini_is_vlog\",\n",
    "\"gemini_has_humour\",\n",
    "\"gemini_comment_sentiment_counts.questioning\",\n",
    "\"gemini_comment_sentiment_counts.agreeing\",\n",
    "\"gemini_comment_sentiment_counts.appreciating\",\n",
    "\"gemini_comment_sentiment_counts.negative\",\n",
    "\"gemini_comment_sentiment_counts.neutral\",\n",
    "]\n",
    "\n",
    "# Attribute columns = all numeric cols that came from the CSV\n",
    "# (i.e. in df_attr_agg but not the creator id)\n",
    "attribute_cols = [\n",
    "    c for c in df_attr_agg.columns\n",
    "    if c != CREATOR_COL\n",
    "]\n",
    "\n",
    "# Keep only columns that actually exist\n",
    "metric_cols    = [c for c in metric_cols if c in df_merged.columns]\n",
    "attribute_cols = [c for c in attribute_cols if c in df_merged.columns]\n",
    "\n",
    "print(\"Metric columns:\", metric_cols)\n",
    "print(\"Attribute columns:\", attribute_cols)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) Correlation matrix: metrics (rows) Ã— attributes (cols)\n",
    "# ---------------------------------------------------------\n",
    "corr_full = df_merged[metric_cols + attribute_cols].corr(method=\"spearman\")\n",
    "corr_metrics_vs_attrs = corr_full.loc[metric_cols, attribute_cols]\n",
    "\n",
    "print(\"Correlation matrix (metrics Ã— attributes):\")\n",
    "display(corr_metrics_vs_attrs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd1c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1976316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81622cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>museumofsoum</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.243035</td>\n",
       "      <td>0.727612</td>\n",
       "      <td>2.323161</td>\n",
       "      <td>2.736664</td>\n",
       "      <td>3.250077</td>\n",
       "      <td>3.889485</td>\n",
       "      <td>4.015789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std       min       25%       50%  \\\n",
       "creator                                                                 \n",
       "museumofsoum    5.0  3.243035  0.727612  2.323161  2.736664  3.250077   \n",
       "\n",
       "                   75%       max  \n",
       "creator                           \n",
       "museumofsoum  3.889485  4.015789  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary stats per creator\n",
    "creator_frame_stats = (\n",
    "    df_sun_frames\n",
    "    .groupby(\"creator\")[\"sun_exposure_raw_A\"]\n",
    "    .describe()\n",
    ")\n",
    "\n",
    "creator_frame_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     3.243035\n",
       "std      0.727612\n",
       "min      2.323161\n",
       "25%      2.736664\n",
       "50%      3.250077\n",
       "75%      3.889485\n",
       "max      4.015789\n",
       "Name: sun_exposure_raw_A, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_stats = df_sun_frames[\"sun_exposure_raw_A\"].describe()\n",
    "global_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure we don't have NaNs\n",
    "frame_vals = df_sun_frames[\"sun_exposure_raw_A\"].dropna()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(frame_vals, bins=40)\n",
    "plt.xlabel(\"Frame-level sun_exposure_raw_A\")\n",
    "plt.ylabel(\"Number of frames\")\n",
    "plt.title(\"Global distribution of frame-level sun exposure\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5539b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Order creators by median frame-level sun exposure\n",
    "creator_medians = (\n",
    "    df_sun_frames.groupby(\"creator\")[\"sun_exposure_raw_A\"]\n",
    "    .median()\n",
    "    .sort_values()\n",
    ")\n",
    "ordered_creators = creator_medians.index.tolist()\n",
    "\n",
    "df_sun_frames_sorted = (\n",
    "    df_sun_frames\n",
    "    .set_index(\"creator\")\n",
    "    .loc[ordered_creators]\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(max(10, len(ordered_creators) * 0.4), 5))\n",
    "df_sun_frames_sorted.boxplot(\n",
    "    column=\"sun_exposure_raw_A\",\n",
    "    by=\"creator\",\n",
    "    showfliers=False,\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Creator\")\n",
    "plt.ylabel(\"Frame-level sun_exposure_raw_A\")\n",
    "plt.title(\"Per-creator distribution of frame-level sun exposure\")\n",
    "plt.suptitle(\"\")  # suppress pandas' default super-title\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21beb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
